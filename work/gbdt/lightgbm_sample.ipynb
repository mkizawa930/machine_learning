{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0d7a39-d235-4ced-babf-f649c4385e53",
   "metadata": {},
   "source": [
    "# Lightgbmを用いた学習サンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d97c93f1-786a-4a4a-8ed6-7e51a21a2907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightbgm version: 4.1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  y\n",
       "0                5.1               3.5                1.4               0.2  0\n",
       "1                4.9               3.0                1.4               0.2  0\n",
       "2                4.7               3.2                1.3               0.2  0\n",
       "3                4.6               3.1                1.5               0.2  0\n",
       "4                5.0               3.6                1.4               0.2  0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f'lightbgm version: {lgb.__version__}')\n",
    "\n",
    "np.random.seed(123) # seed\n",
    "\n",
    "# irisデータセットを使用\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
    "df['y']= pd.Series(iris.target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm APIを使用する例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.910991\tValid's multi_logloss: 0.952315\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.769602\tValid's multi_logloss: 0.818361\n",
      "[3]\tTrain's multi_logloss: 0.656618\tValid's multi_logloss: 0.71228\n",
      "[4]\tTrain's multi_logloss: 0.564489\tValid's multi_logloss: 0.626541\n",
      "[5]\tTrain's multi_logloss: 0.486651\tValid's multi_logloss: 0.55866\n",
      "[6]\tTrain's multi_logloss: 0.421556\tValid's multi_logloss: 0.5028\n",
      "[7]\tTrain's multi_logloss: 0.366666\tValid's multi_logloss: 0.456558\n",
      "[8]\tTrain's multi_logloss: 0.320078\tValid's multi_logloss: 0.418111\n",
      "[9]\tTrain's multi_logloss: 0.280331\tValid's multi_logloss: 0.386092\n",
      "[10]\tTrain's multi_logloss: 0.245625\tValid's multi_logloss: 0.358716\n",
      "[11]\tTrain's multi_logloss: 0.214268\tValid's multi_logloss: 0.336613\n",
      "[12]\tTrain's multi_logloss: 0.187693\tValid's multi_logloss: 0.318848\n",
      "[13]\tTrain's multi_logloss: 0.164672\tValid's multi_logloss: 0.304352\n",
      "[14]\tTrain's multi_logloss: 0.144297\tValid's multi_logloss: 0.288635\n",
      "[15]\tTrain's multi_logloss: 0.126877\tValid's multi_logloss: 0.279493\n",
      "[16]\tTrain's multi_logloss: 0.111335\tValid's multi_logloss: 0.268916\n",
      "[17]\tTrain's multi_logloss: 0.0979605\tValid's multi_logloss: 0.2638\n",
      "[18]\tTrain's multi_logloss: 0.0863162\tValid's multi_logloss: 0.260264\n",
      "[19]\tTrain's multi_logloss: 0.0758846\tValid's multi_logloss: 0.255487\n",
      "[20]\tTrain's multi_logloss: 0.0670286\tValid's multi_logloss: 0.254353\n",
      "[21]\tTrain's multi_logloss: 0.0592865\tValid's multi_logloss: 0.254275\n",
      "[22]\tTrain's multi_logloss: 0.0523105\tValid's multi_logloss: 0.252167\n",
      "[23]\tTrain's multi_logloss: 0.0458099\tValid's multi_logloss: 0.255984\n",
      "[24]\tTrain's multi_logloss: 0.0406669\tValid's multi_logloss: 0.253121\n",
      "[25]\tTrain's multi_logloss: 0.0356521\tValid's multi_logloss: 0.258473\n",
      "[26]\tTrain's multi_logloss: 0.0313444\tValid's multi_logloss: 0.263948\n",
      "[27]\tTrain's multi_logloss: 0.0275018\tValid's multi_logloss: 0.270494\n",
      "[28]\tTrain's multi_logloss: 0.0243717\tValid's multi_logloss: 0.275214\n",
      "[29]\tTrain's multi_logloss: 0.0216176\tValid's multi_logloss: 0.278815\n",
      "[30]\tTrain's multi_logloss: 0.0191641\tValid's multi_logloss: 0.284224\n",
      "[31]\tTrain's multi_logloss: 0.0169347\tValid's multi_logloss: 0.289233\n",
      "[32]\tTrain's multi_logloss: 0.0150106\tValid's multi_logloss: 0.295306\n",
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's multi_logloss: 0.0523105\tValid's multi_logloss: 0.252167\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/3.9.16/lib/python3.9/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1480f6190>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練データ、検証データ、テストデータに分割\n",
    "train, val = train_test_split(df, test_size=0.3, shuffle=True, random_state=123)\n",
    "\n",
    "feature_cols = iris['feature_names']\n",
    "target_col = 'y'\n",
    "train_X, train_y = train[feature_cols], train[target_col]\n",
    "val_X, val_y = val[feature_cols], val[target_col]\n",
    "\n",
    "# 学習データセット\n",
    "lgb_train = lgb.Dataset(train_X, train_y)\n",
    "lgb_val = lgb.Dataset(val_X, val_y, reference=lgb_train)\n",
    "\n",
    "# ハイパーパラメタ\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt', # 学習アルゴリズム \n",
    "    'objective': 'multiclass', # 目的\n",
    "    'metric': {'multi_logloss'}, # 損失関数\n",
    "    'num_class': 3, # 分類クラス数\n",
    "    'learning_rate': 0.1, # 学習率\n",
    "    'num_leaves': 21, # ノード数\n",
    "    'min_data_in_leaf': 3, # 最小ノード数\n",
    "    'num_iteration': 100, # 繰り返し階数,\n",
    "    'verbosity': -1, # ロガー出力が邪魔なときは-1を与える\n",
    "} \n",
    "\n",
    "lgb_results = {}\n",
    "\n",
    "callbacks = [\n",
    "    lgb.early_stopping(10),\n",
    "    lgb.log_evaluation(1), # 繰り返し毎に評価結果を表示する\n",
    "    lgb.record_evaluation(lgb_results),\n",
    "]\n",
    "model = lgb.train(\n",
    "    params=params,\n",
    "    train_set = lgb_train,\n",
    "    valid_sets = [lgb_train, lgb_val],\n",
    "    valid_names = ['Train', 'Valid'],\n",
    "    num_boost_round=100,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n",
    "# 学習結果を表示する\n",
    "loss_train = lgb_results['Train']['multi_logloss']\n",
    "loss_test = lgb_results['Valid']['multi_logloss']\n",
    "best_iteration = model.best_iteration\n",
    "print(best_iteration)\n",
    "\n",
    "plt.plot(loss_train, label=\"train loss\")\n",
    "plt.plot(loss_test, label=\"val loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df3f9356-4a07-4c0b-95ef-a9d8827e8973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length (cm)</th>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal width (cm)</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   importance\n",
       "sepal length (cm)         266\n",
       "sepal width (cm)          235\n",
       "petal length (cm)         395\n",
       "petal width (cm)          180"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特徴量重要度\n",
    "importance = pd.DataFrame(model.feature_importance(), \n",
    "                          index=feature_cols, \n",
    "                          columns=['importance'])\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn APIを使用する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.923791\tValid's multi_logloss: 0.950617\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.792246\tValid's multi_logloss: 0.814756\n",
      "[3]\tTrain's multi_logloss: 0.685845\tValid's multi_logloss: 0.703937\n",
      "[4]\tTrain's multi_logloss: 0.597764\tValid's multi_logloss: 0.617236\n",
      "[5]\tTrain's multi_logloss: 0.525146\tValid's multi_logloss: 0.54197\n",
      "[6]\tTrain's multi_logloss: 0.463093\tValid's multi_logloss: 0.480099\n",
      "[7]\tTrain's multi_logloss: 0.411048\tValid's multi_logloss: 0.427178\n",
      "[8]\tTrain's multi_logloss: 0.364928\tValid's multi_logloss: 0.38555\n",
      "[9]\tTrain's multi_logloss: 0.326164\tValid's multi_logloss: 0.348096\n",
      "[10]\tTrain's multi_logloss: 0.29225\tValid's multi_logloss: 0.317095\n",
      "[11]\tTrain's multi_logloss: 0.263021\tValid's multi_logloss: 0.28988\n",
      "[12]\tTrain's multi_logloss: 0.237813\tValid's multi_logloss: 0.264959\n",
      "[13]\tTrain's multi_logloss: 0.215527\tValid's multi_logloss: 0.246822\n",
      "[14]\tTrain's multi_logloss: 0.195645\tValid's multi_logloss: 0.231158\n",
      "[15]\tTrain's multi_logloss: 0.179272\tValid's multi_logloss: 0.217504\n",
      "[16]\tTrain's multi_logloss: 0.163834\tValid's multi_logloss: 0.205667\n",
      "[17]\tTrain's multi_logloss: 0.150844\tValid's multi_logloss: 0.195103\n",
      "[18]\tTrain's multi_logloss: 0.139315\tValid's multi_logloss: 0.185907\n",
      "[19]\tTrain's multi_logloss: 0.127718\tValid's multi_logloss: 0.179792\n",
      "[20]\tTrain's multi_logloss: 0.118526\tValid's multi_logloss: 0.174433\n",
      "[21]\tTrain's multi_logloss: 0.110405\tValid's multi_logloss: 0.170129\n",
      "[22]\tTrain's multi_logloss: 0.10198\tValid's multi_logloss: 0.167508\n",
      "[23]\tTrain's multi_logloss: 0.0950915\tValid's multi_logloss: 0.163611\n",
      "[24]\tTrain's multi_logloss: 0.087915\tValid's multi_logloss: 0.160446\n",
      "[25]\tTrain's multi_logloss: 0.0831383\tValid's multi_logloss: 0.155361\n",
      "[26]\tTrain's multi_logloss: 0.077283\tValid's multi_logloss: 0.155005\n",
      "[27]\tTrain's multi_logloss: 0.0714718\tValid's multi_logloss: 0.153945\n",
      "[28]\tTrain's multi_logloss: 0.0669098\tValid's multi_logloss: 0.152955\n",
      "[29]\tTrain's multi_logloss: 0.063051\tValid's multi_logloss: 0.152839\n",
      "[30]\tTrain's multi_logloss: 0.0593657\tValid's multi_logloss: 0.152479\n",
      "[31]\tTrain's multi_logloss: 0.0559217\tValid's multi_logloss: 0.152762\n",
      "[32]\tTrain's multi_logloss: 0.0519727\tValid's multi_logloss: 0.153571\n",
      "[33]\tTrain's multi_logloss: 0.0491581\tValid's multi_logloss: 0.15407\n",
      "[34]\tTrain's multi_logloss: 0.046504\tValid's multi_logloss: 0.155204\n",
      "[35]\tTrain's multi_logloss: 0.0431554\tValid's multi_logloss: 0.156544\n",
      "[36]\tTrain's multi_logloss: 0.0411358\tValid's multi_logloss: 0.157325\n",
      "[37]\tTrain's multi_logloss: 0.0393475\tValid's multi_logloss: 0.158304\n",
      "[38]\tTrain's multi_logloss: 0.0377391\tValid's multi_logloss: 0.159415\n",
      "[39]\tTrain's multi_logloss: 0.0350791\tValid's multi_logloss: 0.162399\n",
      "[40]\tTrain's multi_logloss: 0.0337273\tValid's multi_logloss: 0.162962\n",
      "Early stopping, best iteration is:\n",
      "[30]\tTrain's multi_logloss: 0.0593657\tValid's multi_logloss: 0.152479\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbosity=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(verbosity=-1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier(verbosity=-1)\n",
    "model.fit(train_X, train_y, \n",
    "          eval_set=[(train_X, train_y), (val_X, val_y),],\n",
    "          eval_names=['Train', 'Valid'],\n",
    "          callbacks=callbacks\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1fc35-496b-4edd-a8ad-cb72b81e49f0",
   "metadata": {},
   "source": [
    "## oputunaによるハイパーパラメタ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faee0976-28f6-42e4-bb47-b7d3748e31e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb11b192-4327-4470-a289-ad23b1ed9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class': 3,\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ce873ba-d294-40db-b2cb-cceeb01a908a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-05 17:55:41,501]\u001b[0m A new study created in memory with name: no-name-18127808-d641-4ddd-91f9-32fad586c0f9\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.136300:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:41,597]\u001b[0m Trial 0 finished with value: 0.13630024727182344 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.13630024727182344.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.136300:  14%|#4        | 1/7 [00:00<00:00, 10.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.128760:  14%|#4        | 1/7 [00:00<00:00,  6.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.128760:  29%|##8       | 2/7 [00:00<00:00, 13.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:41,657]\u001b[0m Trial 1 finished with value: 0.12876009081719522 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.12876009081719522.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.128760:  29%|##8       | 2/7 [00:00<00:00, 13.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  29%|##8       | 2/7 [00:00<00:00, 13.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:41,711]\u001b[0m Trial 2 finished with value: 0.12675327949894835 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  43%|####2     | 3/7 [00:00<00:00, 13.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.961597\tTest's multi_logloss: 0.994312\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.82657\tTest's multi_logloss: 0.869771\n",
      "[3]\tTrain's multi_logloss: 0.715814\tTest's multi_logloss: 0.758378\n",
      "[4]\tTrain's multi_logloss: 0.626373\tTest's multi_logloss: 0.670365\n",
      "[5]\tTrain's multi_logloss: 0.566571\tTest's multi_logloss: 0.608839\n",
      "[6]\tTrain's multi_logloss: 0.514784\tTest's multi_logloss: 0.561541\n",
      "[7]\tTrain's multi_logloss: 0.456686\tTest's multi_logloss: 0.496802\n",
      "[8]\tTrain's multi_logloss: 0.420051\tTest's multi_logloss: 0.46401\n",
      "[9]\tTrain's multi_logloss: 0.385858\tTest's multi_logloss: 0.43665\n",
      "[10]\tTrain's multi_logloss: 0.347809\tTest's multi_logloss: 0.403835\n",
      "[11]\tTrain's multi_logloss: 0.313607\tTest's multi_logloss: 0.363108\n",
      "[12]\tTrain's multi_logloss: 0.290177\tTest's multi_logloss: 0.340111\n",
      "[13]\tTrain's multi_logloss: 0.265488\tTest's multi_logloss: 0.31311\n",
      "[14]\tTrain's multi_logloss: 0.248911\tTest's multi_logloss: 0.298196\n",
      "[15]\tTrain's multi_logloss: 0.229827\tTest's multi_logloss: 0.280269\n",
      "[16]\tTrain's multi_logloss: 0.211773\tTest's multi_logloss: 0.255451\n",
      "[17]\tTrain's multi_logloss: 0.195954\tTest's multi_logloss: 0.240592\n",
      "[18]\tTrain's multi_logloss: 0.182668\tTest's multi_logloss: 0.22671\n",
      "[19]\tTrain's multi_logloss: 0.170646\tTest's multi_logloss: 0.219177\n",
      "[20]\tTrain's multi_logloss: 0.161731\tTest's multi_logloss: 0.214893\n",
      "[21]\tTrain's multi_logloss: 0.153417\tTest's multi_logloss: 0.208581\n",
      "[22]\tTrain's multi_logloss: 0.144143\tTest's multi_logloss: 0.194057\n",
      "[23]\tTrain's multi_logloss: 0.13648\tTest's multi_logloss: 0.190746\n",
      "[24]\tTrain's multi_logloss: 0.129993\tTest's multi_logloss: 0.185824\n",
      "[25]\tTrain's multi_logloss: 0.123323\tTest's multi_logloss: 0.177586\n",
      "[26]\tTrain's multi_logloss: 0.118997\tTest's multi_logloss: 0.170772\n",
      "[27]\tTrain's multi_logloss: 0.113525\tTest's multi_logloss: 0.164119\n",
      "[28]\tTrain's multi_logloss: 0.110106\tTest's multi_logloss: 0.162068\n",
      "[29]\tTrain's multi_logloss: 0.105133\tTest's multi_logloss: 0.161532\n",
      "[30]\tTrain's multi_logloss: 0.102213\tTest's multi_logloss: 0.160426\n",
      "[31]\tTrain's multi_logloss: 0.098912\tTest's multi_logloss: 0.158445\n",
      "[32]\tTrain's multi_logloss: 0.0954246\tTest's multi_logloss: 0.155993\n",
      "[33]\tTrain's multi_logloss: 0.0921324\tTest's multi_logloss: 0.154868\n",
      "[34]\tTrain's multi_logloss: 0.088959\tTest's multi_logloss: 0.150955\n",
      "[35]\tTrain's multi_logloss: 0.0852397\tTest's multi_logloss: 0.150193\n",
      "[36]\tTrain's multi_logloss: 0.0826988\tTest's multi_logloss: 0.14559\n",
      "[37]\tTrain's multi_logloss: 0.0797853\tTest's multi_logloss: 0.142958\n",
      "[38]\tTrain's multi_logloss: 0.0774425\tTest's multi_logloss: 0.142516\n",
      "[39]\tTrain's multi_logloss: 0.0740158\tTest's multi_logloss: 0.142976\n",
      "[40]\tTrain's multi_logloss: 0.0722294\tTest's multi_logloss: 0.14191\n",
      "[41]\tTrain's multi_logloss: 0.0697293\tTest's multi_logloss: 0.14042\n",
      "[42]\tTrain's multi_logloss: 0.0673221\tTest's multi_logloss: 0.139878\n",
      "[43]\tTrain's multi_logloss: 0.0643631\tTest's multi_logloss: 0.137324\n",
      "[44]\tTrain's multi_logloss: 0.0630391\tTest's multi_logloss: 0.137418\n",
      "[45]\tTrain's multi_logloss: 0.0611069\tTest's multi_logloss: 0.136671\n",
      "[46]\tTrain's multi_logloss: 0.0589755\tTest's multi_logloss: 0.136634\n",
      "[47]\tTrain's multi_logloss: 0.0569364\tTest's multi_logloss: 0.137439\n",
      "[48]\tTrain's multi_logloss: 0.0557758\tTest's multi_logloss: 0.1363\n",
      "[49]\tTrain's multi_logloss: 0.0536169\tTest's multi_logloss: 0.138153\n",
      "[50]\tTrain's multi_logloss: 0.0526113\tTest's multi_logloss: 0.137915\n",
      "[51]\tTrain's multi_logloss: 0.0508405\tTest's multi_logloss: 0.139318\n",
      "[52]\tTrain's multi_logloss: 0.0493186\tTest's multi_logloss: 0.140921\n",
      "[53]\tTrain's multi_logloss: 0.0471275\tTest's multi_logloss: 0.142641\n",
      "[54]\tTrain's multi_logloss: 0.046089\tTest's multi_logloss: 0.140969\n",
      "[55]\tTrain's multi_logloss: 0.0449321\tTest's multi_logloss: 0.13938\n",
      "[56]\tTrain's multi_logloss: 0.0439133\tTest's multi_logloss: 0.137954\n",
      "[57]\tTrain's multi_logloss: 0.0424745\tTest's multi_logloss: 0.139004\n",
      "[58]\tTrain's multi_logloss: 0.0416517\tTest's multi_logloss: 0.137916\n",
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's multi_logloss: 0.0557758\tTest's multi_logloss: 0.1363\n",
      "[1]\tTrain's multi_logloss: 0.925029\tTest's multi_logloss: 0.957643\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.792848\tTest's multi_logloss: 0.834214\n",
      "[3]\tTrain's multi_logloss: 0.686425\tTest's multi_logloss: 0.718427\n",
      "[4]\tTrain's multi_logloss: 0.599149\tTest's multi_logloss: 0.632551\n",
      "[5]\tTrain's multi_logloss: 0.526685\tTest's multi_logloss: 0.56148\n",
      "[6]\tTrain's multi_logloss: 0.465752\tTest's multi_logloss: 0.500644\n",
      "[7]\tTrain's multi_logloss: 0.414182\tTest's multi_logloss: 0.450326\n",
      "[8]\tTrain's multi_logloss: 0.369942\tTest's multi_logloss: 0.411673\n",
      "[9]\tTrain's multi_logloss: 0.331933\tTest's multi_logloss: 0.37397\n",
      "[10]\tTrain's multi_logloss: 0.298203\tTest's multi_logloss: 0.338175\n",
      "[11]\tTrain's multi_logloss: 0.269614\tTest's multi_logloss: 0.313597\n",
      "[12]\tTrain's multi_logloss: 0.245641\tTest's multi_logloss: 0.29511\n",
      "[13]\tTrain's multi_logloss: 0.224892\tTest's multi_logloss: 0.271996\n",
      "[14]\tTrain's multi_logloss: 0.206458\tTest's multi_logloss: 0.25823\n",
      "[15]\tTrain's multi_logloss: 0.190063\tTest's multi_logloss: 0.247577\n",
      "[16]\tTrain's multi_logloss: 0.17575\tTest's multi_logloss: 0.238699\n",
      "[17]\tTrain's multi_logloss: 0.163178\tTest's multi_logloss: 0.224985\n",
      "[18]\tTrain's multi_logloss: 0.152172\tTest's multi_logloss: 0.213062\n",
      "[19]\tTrain's multi_logloss: 0.141389\tTest's multi_logloss: 0.201308\n",
      "[20]\tTrain's multi_logloss: 0.132353\tTest's multi_logloss: 0.19688\n",
      "[21]\tTrain's multi_logloss: 0.124353\tTest's multi_logloss: 0.19286\n",
      "[22]\tTrain's multi_logloss: 0.117561\tTest's multi_logloss: 0.18582\n",
      "[23]\tTrain's multi_logloss: 0.11116\tTest's multi_logloss: 0.183109\n",
      "[24]\tTrain's multi_logloss: 0.105713\tTest's multi_logloss: 0.177183\n",
      "[25]\tTrain's multi_logloss: 0.0998492\tTest's multi_logloss: 0.175005\n",
      "[26]\tTrain's multi_logloss: 0.095429\tTest's multi_logloss: 0.170193\n",
      "[27]\tTrain's multi_logloss: 0.0907971\tTest's multi_logloss: 0.165668\n",
      "[28]\tTrain's multi_logloss: 0.0866447\tTest's multi_logloss: 0.161797\n",
      "[29]\tTrain's multi_logloss: 0.0830961\tTest's multi_logloss: 0.159077\n",
      "[30]\tTrain's multi_logloss: 0.0793845\tTest's multi_logloss: 0.156725\n",
      "[31]\tTrain's multi_logloss: 0.0751743\tTest's multi_logloss: 0.152452\n",
      "[32]\tTrain's multi_logloss: 0.0713612\tTest's multi_logloss: 0.148684\n",
      "[33]\tTrain's multi_logloss: 0.0678982\tTest's multi_logloss: 0.145355\n",
      "[34]\tTrain's multi_logloss: 0.0655086\tTest's multi_logloss: 0.144007\n",
      "[35]\tTrain's multi_logloss: 0.0625307\tTest's multi_logloss: 0.14128\n",
      "[36]\tTrain's multi_logloss: 0.0595269\tTest's multi_logloss: 0.140127\n",
      "[37]\tTrain's multi_logloss: 0.0568601\tTest's multi_logloss: 0.139042\n",
      "[38]\tTrain's multi_logloss: 0.0538614\tTest's multi_logloss: 0.138224\n",
      "[39]\tTrain's multi_logloss: 0.0514197\tTest's multi_logloss: 0.137361\n",
      "[40]\tTrain's multi_logloss: 0.0486454\tTest's multi_logloss: 0.134557\n",
      "[41]\tTrain's multi_logloss: 0.0465244\tTest's multi_logloss: 0.134092\n",
      "[42]\tTrain's multi_logloss: 0.0444652\tTest's multi_logloss: 0.133208\n",
      "[43]\tTrain's multi_logloss: 0.0428997\tTest's multi_logloss: 0.129684\n",
      "[44]\tTrain's multi_logloss: 0.0410149\tTest's multi_logloss: 0.12876\n",
      "[45]\tTrain's multi_logloss: 0.0393861\tTest's multi_logloss: 0.129199\n",
      "[46]\tTrain's multi_logloss: 0.0380524\tTest's multi_logloss: 0.131289\n",
      "[47]\tTrain's multi_logloss: 0.0362467\tTest's multi_logloss: 0.133832\n",
      "[48]\tTrain's multi_logloss: 0.0352432\tTest's multi_logloss: 0.136962\n",
      "[49]\tTrain's multi_logloss: 0.0342413\tTest's multi_logloss: 0.138258\n",
      "[50]\tTrain's multi_logloss: 0.033495\tTest's multi_logloss: 0.138775\n",
      "[51]\tTrain's multi_logloss: 0.0325976\tTest's multi_logloss: 0.138232\n",
      "[52]\tTrain's multi_logloss: 0.0317377\tTest's multi_logloss: 0.135627\n",
      "[53]\tTrain's multi_logloss: 0.0309578\tTest's multi_logloss: 0.13878\n",
      "[54]\tTrain's multi_logloss: 0.0301317\tTest's multi_logloss: 0.140169\n",
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's multi_logloss: 0.0410149\tTest's multi_logloss: 0.12876\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.961597\tTest's multi_logloss: 0.994312\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  43%|####2     | 3/7 [00:00<00:00, 13.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  57%|#####7    | 4/7 [00:00<00:00, 15.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:41,770]\u001b[0m Trial 3 finished with value: 0.13630024727182344 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  57%|#####7    | 4/7 [00:00<00:00, 15.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  57%|#####7    | 4/7 [00:00<00:00, 15.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:41,825]\u001b[0m Trial 4 finished with value: 0.12675327949894835 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  71%|#######1  | 5/7 [00:00<00:00, 15.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  71%|#######1  | 5/7 [00:00<00:00, 15.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  86%|########5 | 6/7 [00:00<00:00, 16.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:41,882]\u001b[0m Trial 5 finished with value: 0.12876009081719522 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  86%|########5 | 6/7 [00:00<00:00, 16.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tTrain's multi_logloss: 0.82657\tTest's multi_logloss: 0.869771\n",
      "[3]\tTrain's multi_logloss: 0.715814\tTest's multi_logloss: 0.758378\n",
      "[4]\tTrain's multi_logloss: 0.626373\tTest's multi_logloss: 0.670365\n",
      "[5]\tTrain's multi_logloss: 0.566571\tTest's multi_logloss: 0.608839\n",
      "[6]\tTrain's multi_logloss: 0.514784\tTest's multi_logloss: 0.561541\n",
      "[7]\tTrain's multi_logloss: 0.456686\tTest's multi_logloss: 0.496802\n",
      "[8]\tTrain's multi_logloss: 0.420051\tTest's multi_logloss: 0.46401\n",
      "[9]\tTrain's multi_logloss: 0.385858\tTest's multi_logloss: 0.43665\n",
      "[10]\tTrain's multi_logloss: 0.347809\tTest's multi_logloss: 0.403835\n",
      "[11]\tTrain's multi_logloss: 0.313607\tTest's multi_logloss: 0.363108\n",
      "[12]\tTrain's multi_logloss: 0.290177\tTest's multi_logloss: 0.340111\n",
      "[13]\tTrain's multi_logloss: 0.265488\tTest's multi_logloss: 0.31311\n",
      "[14]\tTrain's multi_logloss: 0.248911\tTest's multi_logloss: 0.298196\n",
      "[15]\tTrain's multi_logloss: 0.229827\tTest's multi_logloss: 0.280269\n",
      "[16]\tTrain's multi_logloss: 0.211773\tTest's multi_logloss: 0.255451\n",
      "[17]\tTrain's multi_logloss: 0.195954\tTest's multi_logloss: 0.240592\n",
      "[18]\tTrain's multi_logloss: 0.182668\tTest's multi_logloss: 0.22671\n",
      "[19]\tTrain's multi_logloss: 0.170646\tTest's multi_logloss: 0.219177\n",
      "[20]\tTrain's multi_logloss: 0.161731\tTest's multi_logloss: 0.214893\n",
      "[21]\tTrain's multi_logloss: 0.153417\tTest's multi_logloss: 0.208581\n",
      "[22]\tTrain's multi_logloss: 0.144143\tTest's multi_logloss: 0.194057\n",
      "[23]\tTrain's multi_logloss: 0.13648\tTest's multi_logloss: 0.190746\n",
      "[24]\tTrain's multi_logloss: 0.129993\tTest's multi_logloss: 0.185824\n",
      "[25]\tTrain's multi_logloss: 0.123323\tTest's multi_logloss: 0.177586\n",
      "[26]\tTrain's multi_logloss: 0.118997\tTest's multi_logloss: 0.170772\n",
      "[27]\tTrain's multi_logloss: 0.113525\tTest's multi_logloss: 0.164119\n",
      "[28]\tTrain's multi_logloss: 0.110106\tTest's multi_logloss: 0.162068\n",
      "[29]\tTrain's multi_logloss: 0.105133\tTest's multi_logloss: 0.161532\n",
      "[30]\tTrain's multi_logloss: 0.102213\tTest's multi_logloss: 0.160426\n",
      "[31]\tTrain's multi_logloss: 0.098912\tTest's multi_logloss: 0.158445\n",
      "[32]\tTrain's multi_logloss: 0.0954246\tTest's multi_logloss: 0.155993\n",
      "[33]\tTrain's multi_logloss: 0.0921324\tTest's multi_logloss: 0.154868\n",
      "[34]\tTrain's multi_logloss: 0.088959\tTest's multi_logloss: 0.150955\n",
      "[35]\tTrain's multi_logloss: 0.0852397\tTest's multi_logloss: 0.150193\n",
      "[36]\tTrain's multi_logloss: 0.0826988\tTest's multi_logloss: 0.14559\n",
      "[37]\tTrain's multi_logloss: 0.0797853\tTest's multi_logloss: 0.142958\n",
      "[38]\tTrain's multi_logloss: 0.0774425\tTest's multi_logloss: 0.142516\n",
      "[39]\tTrain's multi_logloss: 0.0740158\tTest's multi_logloss: 0.142976\n",
      "[40]\tTrain's multi_logloss: 0.0722294\tTest's multi_logloss: 0.14191\n",
      "[41]\tTrain's multi_logloss: 0.0697293\tTest's multi_logloss: 0.14042\n",
      "[42]\tTrain's multi_logloss: 0.0673221\tTest's multi_logloss: 0.139878\n",
      "[43]\tTrain's multi_logloss: 0.0643631\tTest's multi_logloss: 0.137324\n",
      "[44]\tTrain's multi_logloss: 0.0630391\tTest's multi_logloss: 0.137418\n",
      "[45]\tTrain's multi_logloss: 0.0611069\tTest's multi_logloss: 0.136671\n",
      "[46]\tTrain's multi_logloss: 0.0589755\tTest's multi_logloss: 0.136634\n",
      "[47]\tTrain's multi_logloss: 0.0569364\tTest's multi_logloss: 0.137439\n",
      "[48]\tTrain's multi_logloss: 0.0557758\tTest's multi_logloss: 0.1363\n",
      "[49]\tTrain's multi_logloss: 0.0536169\tTest's multi_logloss: 0.138153\n",
      "[50]\tTrain's multi_logloss: 0.0526113\tTest's multi_logloss: 0.137915\n",
      "[51]\tTrain's multi_logloss: 0.0508405\tTest's multi_logloss: 0.139318\n",
      "[52]\tTrain's multi_logloss: 0.0493186\tTest's multi_logloss: 0.140921\n",
      "[53]\tTrain's multi_logloss: 0.0471275\tTest's multi_logloss: 0.142641\n",
      "[54]\tTrain's multi_logloss: 0.046089\tTest's multi_logloss: 0.140969\n",
      "[55]\tTrain's multi_logloss: 0.0449321\tTest's multi_logloss: 0.13938\n",
      "[56]\tTrain's multi_logloss: 0.0439133\tTest's multi_logloss: 0.137954\n",
      "[57]\tTrain's multi_logloss: 0.0424745\tTest's multi_logloss: 0.139004\n",
      "[58]\tTrain's multi_logloss: 0.0416517\tTest's multi_logloss: 0.137916\n",
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's multi_logloss: 0.0557758\tTest's multi_logloss: 0.1363\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.925029\tTest's multi_logloss: 0.957643\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.792848\tTest's multi_logloss: 0.834214\n",
      "[3]\tTrain's multi_logloss: 0.686425\tTest's multi_logloss: 0.718427\n",
      "[4]\tTrain's multi_logloss: 0.599149\tTest's multi_logloss: 0.632551\n",
      "[5]\tTrain's multi_logloss: 0.526685\tTest's multi_logloss: 0.56148\n",
      "[6]\tTrain's multi_logloss: 0.465752\tTest's multi_logloss: 0.500644\n",
      "[7]\tTrain's multi_logloss: 0.414182\tTest's multi_logloss: 0.450326\n",
      "[8]\tTrain's multi_logloss: 0.369942\tTest's multi_logloss: 0.411673\n",
      "[9]\tTrain's multi_logloss: 0.331933\tTest's multi_logloss: 0.37397\n",
      "[10]\tTrain's multi_logloss: 0.298203\tTest's multi_logloss: 0.338175\n",
      "[11]\tTrain's multi_logloss: 0.269614\tTest's multi_logloss: 0.313597\n",
      "[12]\tTrain's multi_logloss: 0.245641\tTest's multi_logloss: 0.29511\n",
      "[13]\tTrain's multi_logloss: 0.224892\tTest's multi_logloss: 0.271996\n",
      "[14]\tTrain's multi_logloss: 0.206458\tTest's multi_logloss: 0.25823\n",
      "[15]\tTrain's multi_logloss: 0.190063\tTest's multi_logloss: 0.247577\n",
      "[16]\tTrain's multi_logloss: 0.17575\tTest's multi_logloss: 0.238699\n",
      "[17]\tTrain's multi_logloss: 0.163178\tTest's multi_logloss: 0.224985\n",
      "[18]\tTrain's multi_logloss: 0.152172\tTest's multi_logloss: 0.213062\n",
      "[19]\tTrain's multi_logloss: 0.141389\tTest's multi_logloss: 0.201308\n",
      "[20]\tTrain's multi_logloss: 0.132353\tTest's multi_logloss: 0.19688\n",
      "[21]\tTrain's multi_logloss: 0.124353\tTest's multi_logloss: 0.19286\n",
      "[22]\tTrain's multi_logloss: 0.117561\tTest's multi_logloss: 0.18582\n",
      "[23]\tTrain's multi_logloss: 0.11116\tTest's multi_logloss: 0.183109\n",
      "[24]\tTrain's multi_logloss: 0.105713\tTest's multi_logloss: 0.177183\n",
      "[25]\tTrain's multi_logloss: 0.0998492\tTest's multi_logloss: 0.175005\n",
      "[26]\tTrain's multi_logloss: 0.095429\tTest's multi_logloss: 0.170193\n",
      "[27]\tTrain's multi_logloss: 0.0907971\tTest's multi_logloss: 0.165668\n",
      "[28]\tTrain's multi_logloss: 0.0866447\tTest's multi_logloss: 0.161797\n",
      "[29]\tTrain's multi_logloss: 0.0830961\tTest's multi_logloss: 0.159077\n",
      "[30]\tTrain's multi_logloss: 0.0793845\tTest's multi_logloss: 0.156725\n",
      "[31]\tTrain's multi_logloss: 0.0751743\tTest's multi_logloss: 0.152452\n",
      "[32]\tTrain's multi_logloss: 0.0713612\tTest's multi_logloss: 0.148684\n",
      "[33]\tTrain's multi_logloss: 0.0678982\tTest's multi_logloss: 0.145355\n",
      "[34]\tTrain's multi_logloss: 0.0655086\tTest's multi_logloss: 0.144007\n",
      "[35]\tTrain's multi_logloss: 0.0625307\tTest's multi_logloss: 0.14128\n",
      "[36]\tTrain's multi_logloss: 0.0595269\tTest's multi_logloss: 0.140127\n",
      "[37]\tTrain's multi_logloss: 0.0568601\tTest's multi_logloss: 0.139042\n",
      "[38]\tTrain's multi_logloss: 0.0538614\tTest's multi_logloss: 0.138224\n",
      "[39]\tTrain's multi_logloss: 0.0514197\tTest's multi_logloss: 0.137361\n",
      "[40]\tTrain's multi_logloss: 0.0486454\tTest's multi_logloss: 0.134557\n",
      "[41]\tTrain's multi_logloss: 0.0465244\tTest's multi_logloss: 0.134092\n",
      "[42]\tTrain's multi_logloss: 0.0444652\tTest's multi_logloss: 0.133208\n",
      "[43]\tTrain's multi_logloss: 0.0428997\tTest's multi_logloss: 0.129684\n",
      "[44]\tTrain's multi_logloss: 0.0410149\tTest's multi_logloss: 0.12876\n",
      "[45]\tTrain's multi_logloss: 0.0393861\tTest's multi_logloss: 0.129199\n",
      "[46]\tTrain's multi_logloss: 0.0380524\tTest's multi_logloss: 0.131289\n",
      "[47]\tTrain's multi_logloss: 0.0362467\tTest's multi_logloss: 0.133832\n",
      "[48]\tTrain's multi_logloss: 0.0352432\tTest's multi_logloss: 0.136962\n",
      "[49]\tTrain's multi_logloss: 0.0342413\tTest's multi_logloss: 0.138258\n",
      "[50]\tTrain's multi_logloss: 0.033495\tTest's multi_logloss: 0.138775\n",
      "[51]\tTrain's multi_logloss: 0.0325976\tTest's multi_logloss: 0.138232\n",
      "[52]\tTrain's multi_logloss: 0.0317377\tTest's multi_logloss: 0.135627\n",
      "[53]\tTrain's multi_logloss: 0.0309578\tTest's multi_logloss: 0.13878\n",
      "[54]\tTrain's multi_logloss: 0.0301317\tTest's multi_logloss: 0.140169\n",
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's multi_logloss: 0.0410149\tTest's multi_logloss: 0.12876\n",
      "[1]\tTrain's multi_logloss: 0.961597\tTest's multi_logloss: 0.994312\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.82657\tTest's multi_logloss: 0.869771\n",
      "[3]\tTrain's multi_logloss: 0.715814\tTest's multi_logloss: 0.758378\n",
      "[4]\tTrain's multi_logloss: 0.626373\tTest's multi_logloss: 0.670365\n",
      "[5]\tTrain's multi_logloss: 0.566571\tTest's multi_logloss: 0.608839\n",
      "[6]\tTrain's multi_logloss: 0.514784\tTest's multi_logloss: 0.561541\n",
      "[7]\tTrain's multi_logloss: 0.456686\tTest's multi_logloss: 0.496802\n",
      "[8]\tTrain's multi_logloss: 0.420051\tTest's multi_logloss: 0.46401\n",
      "[9]\tTrain's multi_logloss: 0.385858\tTest's multi_logloss: 0.43665\n",
      "[10]\tTrain's multi_logloss: 0.347809\tTest's multi_logloss: 0.403835\n",
      "[11]\tTrain's multi_logloss: 0.313607\tTest's multi_logloss: 0.363108\n",
      "[12]\tTrain's multi_logloss: 0.290177\tTest's multi_logloss: 0.340111\n",
      "[13]\tTrain's multi_logloss: 0.265488\tTest's multi_logloss: 0.31311\n",
      "[14]\tTrain's multi_logloss: 0.248911\tTest's multi_logloss: 0.298196\n",
      "[15]\tTrain's multi_logloss: 0.229827\tTest's multi_logloss: 0.280269\n",
      "[16]\tTrain's multi_logloss: 0.211773\tTest's multi_logloss: 0.255451\n",
      "[17]\tTrain's multi_logloss: 0.195954\tTest's multi_logloss: 0.240592\n",
      "[18]\tTrain's multi_logloss: 0.182668\tTest's multi_logloss: 0.22671\n",
      "[19]\tTrain's multi_logloss: 0.170646\tTest's multi_logloss: 0.219177\n",
      "[20]\tTrain's multi_logloss: 0.161731\tTest's multi_logloss: 0.214893\n",
      "[21]\tTrain's multi_logloss: 0.153417\tTest's multi_logloss: 0.208581\n",
      "[22]\tTrain's multi_logloss: 0.144143\tTest's multi_logloss: 0.194057\n",
      "[23]\tTrain's multi_logloss: 0.13648\tTest's multi_logloss: 0.190746\n",
      "[24]\tTrain's multi_logloss: 0.129993\tTest's multi_logloss: 0.185824\n",
      "[25]\tTrain's multi_logloss: 0.123323\tTest's multi_logloss: 0.177586\n",
      "[26]\tTrain's multi_logloss: 0.118997\tTest's multi_logloss: 0.170772\n",
      "[27]\tTrain's multi_logloss: 0.113525\tTest's multi_logloss: 0.164119\n",
      "[28]\tTrain's multi_logloss: 0.110106\tTest's multi_logloss: 0.162068\n",
      "[29]\tTrain's multi_logloss: 0.105133\tTest's multi_logloss: 0.161532\n",
      "[30]\tTrain's multi_logloss: 0.102213\tTest's multi_logloss: 0.160426\n",
      "[31]\tTrain's multi_logloss: 0.098912\tTest's multi_logloss: 0.158445\n",
      "[32]\tTrain's multi_logloss: 0.0954246\tTest's multi_logloss: 0.155993\n",
      "[33]\tTrain's multi_logloss: 0.0921324\tTest's multi_logloss: 0.154868\n",
      "[34]\tTrain's multi_logloss: 0.088959\tTest's multi_logloss: 0.150955\n",
      "[35]\tTrain's multi_logloss: 0.0852397\tTest's multi_logloss: 0.150193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.126753:  86%|########5 | 6/7 [00:00<00:00, 16.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:41,944]\u001b[0m Trial 6 finished with value: 0.13630024727182344 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.12675327949894835.\u001b[0m\n",
      "feature_fraction, val_score: 0.126753: 100%|##########| 7/7 [00:00<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36]\tTrain's multi_logloss: 0.0826988\tTest's multi_logloss: 0.14559\n",
      "[37]\tTrain's multi_logloss: 0.0797853\tTest's multi_logloss: 0.142958\n",
      "[38]\tTrain's multi_logloss: 0.0774425\tTest's multi_logloss: 0.142516\n",
      "[39]\tTrain's multi_logloss: 0.0740158\tTest's multi_logloss: 0.142976\n",
      "[40]\tTrain's multi_logloss: 0.0722294\tTest's multi_logloss: 0.14191\n",
      "[41]\tTrain's multi_logloss: 0.0697293\tTest's multi_logloss: 0.14042\n",
      "[42]\tTrain's multi_logloss: 0.0673221\tTest's multi_logloss: 0.139878\n",
      "[43]\tTrain's multi_logloss: 0.0643631\tTest's multi_logloss: 0.137324\n",
      "[44]\tTrain's multi_logloss: 0.0630391\tTest's multi_logloss: 0.137418\n",
      "[45]\tTrain's multi_logloss: 0.0611069\tTest's multi_logloss: 0.136671\n",
      "[46]\tTrain's multi_logloss: 0.0589755\tTest's multi_logloss: 0.136634\n",
      "[47]\tTrain's multi_logloss: 0.0569364\tTest's multi_logloss: 0.137439\n",
      "[48]\tTrain's multi_logloss: 0.0557758\tTest's multi_logloss: 0.1363\n",
      "[49]\tTrain's multi_logloss: 0.0536169\tTest's multi_logloss: 0.138153\n",
      "[50]\tTrain's multi_logloss: 0.0526113\tTest's multi_logloss: 0.137915\n",
      "[51]\tTrain's multi_logloss: 0.0508405\tTest's multi_logloss: 0.139318\n",
      "[52]\tTrain's multi_logloss: 0.0493186\tTest's multi_logloss: 0.140921\n",
      "[53]\tTrain's multi_logloss: 0.0471275\tTest's multi_logloss: 0.142641\n",
      "[54]\tTrain's multi_logloss: 0.046089\tTest's multi_logloss: 0.140969\n",
      "[55]\tTrain's multi_logloss: 0.0449321\tTest's multi_logloss: 0.13938\n",
      "[56]\tTrain's multi_logloss: 0.0439133\tTest's multi_logloss: 0.137954\n",
      "[57]\tTrain's multi_logloss: 0.0424745\tTest's multi_logloss: 0.139004\n",
      "[58]\tTrain's multi_logloss: 0.0416517\tTest's multi_logloss: 0.137916\n",
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's multi_logloss: 0.0557758\tTest's multi_logloss: 0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,002]\u001b[0m Trial 7 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 114}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:   5%|5         | 1/20 [00:00<00:01, 17.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:   5%|5         | 1/20 [00:00<00:02,  9.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  10%|#         | 2/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,057]\u001b[0m Trial 8 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 193}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  10%|#         | 2/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  10%|#         | 2/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,116]\u001b[0m Trial 9 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 7}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  15%|#5        | 3/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  15%|#5        | 3/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  20%|##        | 4/20 [00:00<00:00, 17.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,172]\u001b[0m Trial 10 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 54}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  20%|##        | 4/20 [00:00<00:00, 17.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  20%|##        | 4/20 [00:00<00:00, 17.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,241]\u001b[0m Trial 11 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 128}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  25%|##5       | 5/20 [00:00<00:00, 17.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  25%|##5       | 5/20 [00:00<00:00, 17.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  30%|###       | 6/20 [00:00<00:00, 16.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,299]\u001b[0m Trial 12 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 70}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  30%|###       | 6/20 [00:00<00:00, 16.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  30%|###       | 6/20 [00:00<00:00, 16.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,358]\u001b[0m Trial 13 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 234}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  35%|###5      | 7/20 [00:00<00:00, 16.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  35%|###5      | 7/20 [00:00<00:00, 16.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  40%|####      | 8/20 [00:00<00:00, 16.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,415]\u001b[0m Trial 14 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 238}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  40%|####      | 8/20 [00:00<00:00, 16.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  40%|####      | 8/20 [00:00<00:00, 16.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,470]\u001b[0m Trial 15 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 10}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  45%|####5     | 9/20 [00:00<00:00, 16.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  45%|####5     | 9/20 [00:00<00:00, 16.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  50%|#####     | 10/20 [00:00<00:00, 17.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,525]\u001b[0m Trial 16 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 39}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  50%|#####     | 10/20 [00:00<00:00, 17.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  50%|#####     | 10/20 [00:00<00:00, 17.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,585]\u001b[0m Trial 17 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 146}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  55%|#####5    | 11/20 [00:00<00:00, 17.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  55%|#####5    | 11/20 [00:00<00:00, 17.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  60%|######    | 12/20 [00:00<00:00, 17.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,645]\u001b[0m Trial 18 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 165}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  60%|######    | 12/20 [00:00<00:00, 17.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  60%|######    | 12/20 [00:00<00:00, 17.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,703]\u001b[0m Trial 19 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 184}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  65%|######5   | 13/20 [00:00<00:00, 17.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  65%|######5   | 13/20 [00:00<00:00, 17.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  70%|#######   | 14/20 [00:00<00:00, 15.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,788]\u001b[0m Trial 20 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 104}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  70%|#######   | 14/20 [00:00<00:00, 15.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  70%|#######   | 14/20 [00:00<00:00, 15.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,851]\u001b[0m Trial 21 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 195}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  75%|#######5  | 15/20 [00:00<00:00, 15.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  75%|#######5  | 15/20 [00:00<00:00, 15.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  80%|########  | 16/20 [00:00<00:00, 16.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,906]\u001b[0m Trial 22 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 99}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  80%|########  | 16/20 [00:00<00:00, 16.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  80%|########  | 16/20 [00:01<00:00, 16.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:42,964]\u001b[0m Trial 23 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 203}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  85%|########5 | 17/20 [00:01<00:00, 16.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  85%|########5 | 17/20 [00:01<00:00, 16.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  90%|######### | 18/20 [00:01<00:00, 16.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,021]\u001b[0m Trial 24 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 256}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  90%|######### | 18/20 [00:01<00:00, 16.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  90%|######### | 18/20 [00:01<00:00, 16.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,077]\u001b[0m Trial 25 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 88}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  95%|#########5| 19/20 [00:01<00:00, 16.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753:  95%|#########5| 19/20 [00:01<00:00, 16.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.126753: 100%|##########| 20/20 [00:01<00:00, 17.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,131]\u001b[0m Trial 26 finished with value: 0.12675327949894835 and parameters: {'num_leaves': 130}. Best is trial 7 with value: 0.12675327949894835.\u001b[0m\n",
      "num_leaves, val_score: 0.126753: 100%|##########| 20/20 [00:01<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[1]\tTrain's multi_logloss: 0.927324\tTest's multi_logloss: 0.949367\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79351\tTest's multi_logloss: 0.82415\n",
      "[3]\tTrain's multi_logloss: 0.686698\tTest's multi_logloss: 0.725249\n",
      "[4]\tTrain's multi_logloss: 0.59991\tTest's multi_logloss: 0.631974\n",
      "[5]\tTrain's multi_logloss: 0.528016\tTest's multi_logloss: 0.554335\n",
      "[6]\tTrain's multi_logloss: 0.4674\tTest's multi_logloss: 0.500966\n",
      "[7]\tTrain's multi_logloss: 0.415194\tTest's multi_logloss: 0.44998\n",
      "[8]\tTrain's multi_logloss: 0.370911\tTest's multi_logloss: 0.399967\n",
      "[9]\tTrain's multi_logloss: 0.332114\tTest's multi_logloss: 0.366134\n",
      "[10]\tTrain's multi_logloss: 0.29883\tTest's multi_logloss: 0.337421\n",
      "[11]\tTrain's multi_logloss: 0.269882\tTest's multi_logloss: 0.312309\n",
      "[12]\tTrain's multi_logloss: 0.247175\tTest's multi_logloss: 0.285542\n",
      "[13]\tTrain's multi_logloss: 0.225009\tTest's multi_logloss: 0.26654\n",
      "[14]\tTrain's multi_logloss: 0.206272\tTest's multi_logloss: 0.252381\n",
      "[15]\tTrain's multi_logloss: 0.189592\tTest's multi_logloss: 0.241508\n",
      "[16]\tTrain's multi_logloss: 0.175048\tTest's multi_logloss: 0.232463\n",
      "[17]\tTrain's multi_logloss: 0.163848\tTest's multi_logloss: 0.22118\n",
      "[18]\tTrain's multi_logloss: 0.152757\tTest's multi_logloss: 0.209017\n",
      "[19]\tTrain's multi_logloss: 0.142937\tTest's multi_logloss: 0.197875\n",
      "[20]\tTrain's multi_logloss: 0.134309\tTest's multi_logloss: 0.18818\n",
      "[21]\tTrain's multi_logloss: 0.126552\tTest's multi_logloss: 0.180021\n",
      "[22]\tTrain's multi_logloss: 0.119454\tTest's multi_logloss: 0.177221\n",
      "[23]\tTrain's multi_logloss: 0.113466\tTest's multi_logloss: 0.170702\n",
      "[24]\tTrain's multi_logloss: 0.107232\tTest's multi_logloss: 0.164947\n",
      "[25]\tTrain's multi_logloss: 0.10247\tTest's multi_logloss: 0.16005\n",
      "[26]\tTrain's multi_logloss: 0.097363\tTest's multi_logloss: 0.155505\n",
      "[27]\tTrain's multi_logloss: 0.0927729\tTest's multi_logloss: 0.154641\n",
      "[28]\tTrain's multi_logloss: 0.0875114\tTest's multi_logloss: 0.15146\n",
      "[29]\tTrain's multi_logloss: 0.0832195\tTest's multi_logloss: 0.148367\n",
      "[30]\tTrain's multi_logloss: 0.0795366\tTest's multi_logloss: 0.146087\n",
      "[31]\tTrain's multi_logloss: 0.0754866\tTest's multi_logloss: 0.144371\n",
      "[32]\tTrain's multi_logloss: 0.0712451\tTest's multi_logloss: 0.141056\n",
      "[33]\tTrain's multi_logloss: 0.0674222\tTest's multi_logloss: 0.138191\n",
      "[34]\tTrain's multi_logloss: 0.0643148\tTest's multi_logloss: 0.136377\n",
      "[35]\tTrain's multi_logloss: 0.0610447\tTest's multi_logloss: 0.134868\n",
      "[36]\tTrain's multi_logloss: 0.0584059\tTest's multi_logloss: 0.132889\n",
      "[37]\tTrain's multi_logloss: 0.0562902\tTest's multi_logloss: 0.132162\n",
      "[38]\tTrain's multi_logloss: 0.0537451\tTest's multi_logloss: 0.131279\n",
      "[39]\tTrain's multi_logloss: 0.0513125\tTest's multi_logloss: 0.129852\n",
      "[40]\tTrain's multi_logloss: 0.0491261\tTest's multi_logloss: 0.128686\n",
      "[41]\tTrain's multi_logloss: 0.0476096\tTest's multi_logloss: 0.127116\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n",
      "[43]\tTrain's multi_logloss: 0.0436874\tTest's multi_logloss: 0.127349\n",
      "[44]\tTrain's multi_logloss: 0.0424208\tTest's multi_logloss: 0.127473\n",
      "[45]\tTrain's multi_logloss: 0.0407001\tTest's multi_logloss: 0.127993\n",
      "[46]\tTrain's multi_logloss: 0.0395981\tTest's multi_logloss: 0.128274\n",
      "[47]\tTrain's multi_logloss: 0.0386548\tTest's multi_logloss: 0.130795\n",
      "[48]\tTrain's multi_logloss: 0.0374471\tTest's multi_logloss: 0.129735\n",
      "[49]\tTrain's multi_logloss: 0.0359066\tTest's multi_logloss: 0.132316\n",
      "[50]\tTrain's multi_logloss: 0.0350791\tTest's multi_logloss: 0.132584\n",
      "[51]\tTrain's multi_logloss: 0.0335025\tTest's multi_logloss: 0.133517\n",
      "[52]\tTrain's multi_logloss: 0.0322575\tTest's multi_logloss: 0.134951\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0455774\tTest's multi_logloss: 0.126753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.126753:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.970983\tTest's multi_logloss: 1.00473\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.865363\tTest's multi_logloss: 0.896098\n",
      "[3]\tTrain's multi_logloss: 0.782923\tTest's multi_logloss: 0.810542\n",
      "[4]\tTrain's multi_logloss: 0.713989\tTest's multi_logloss: 0.739446\n",
      "[5]\tTrain's multi_logloss: 0.644474\tTest's multi_logloss: 0.670015\n",
      "[6]\tTrain's multi_logloss: 0.587688\tTest's multi_logloss: 0.612283\n",
      "[7]\tTrain's multi_logloss: 0.537786\tTest's multi_logloss: 0.560803\n",
      "[8]\tTrain's multi_logloss: 0.496073\tTest's multi_logloss: 0.514067\n",
      "[9]\tTrain's multi_logloss: 0.454813\tTest's multi_logloss: 0.475046\n",
      "[10]\tTrain's multi_logloss: 0.421013\tTest's multi_logloss: 0.439304\n",
      "[11]\tTrain's multi_logloss: 0.391768\tTest's multi_logloss: 0.419348\n",
      "[12]\tTrain's multi_logloss: 0.365787\tTest's multi_logloss: 0.390073\n",
      "[13]\tTrain's multi_logloss: 0.341967\tTest's multi_logloss: 0.361657\n",
      "[14]\tTrain's multi_logloss: 0.322282\tTest's multi_logloss: 0.337288\n",
      "[15]\tTrain's multi_logloss: 0.299247\tTest's multi_logloss: 0.315273\n",
      "[16]\tTrain's multi_logloss: 0.278797\tTest's multi_logloss: 0.2957\n",
      "[17]\tTrain's multi_logloss: 0.264578\tTest's multi_logloss: 0.281875\n",
      "[18]\tTrain's multi_logloss: 0.250773\tTest's multi_logloss: 0.270743\n",
      "[19]\tTrain's multi_logloss: 0.236099\tTest's multi_logloss: 0.259925\n",
      "[20]\tTrain's multi_logloss: 0.224874\tTest's multi_logloss: 0.249912\n",
      "[21]\tTrain's multi_logloss: 0.211746\tTest's multi_logloss: 0.237192\n",
      "[22]\tTrain's multi_logloss: 0.199348\tTest's multi_logloss: 0.226399\n",
      "[23]\tTrain's multi_logloss: 0.191353\tTest's multi_logloss: 0.215773\n",
      "[24]\tTrain's multi_logloss: 0.18283\tTest's multi_logloss: 0.209891\n",
      "[25]\tTrain's multi_logloss: 0.176213\tTest's multi_logloss: 0.198856\n",
      "[26]\tTrain's multi_logloss: 0.170439\tTest's multi_logloss: 0.190024\n",
      "[27]\tTrain's multi_logloss: 0.164018\tTest's multi_logloss: 0.180336\n",
      "[28]\tTrain's multi_logloss: 0.157454\tTest's multi_logloss: 0.17066\n",
      "[29]\tTrain's multi_logloss: 0.148828\tTest's multi_logloss: 0.164601\n",
      "[30]\tTrain's multi_logloss: 0.144316\tTest's multi_logloss: 0.160979\n",
      "[31]\tTrain's multi_logloss: 0.140202\tTest's multi_logloss: 0.156946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.109963:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,187]\u001b[0m Trial 27 finished with value: 0.1099633474021663 and parameters: {'bagging_fraction': 0.4990811362077932, 'bagging_freq': 2}. Best is trial 27 with value: 0.1099633474021663.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.109963:  10%|#         | 1/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.109963:  10%|#         | 1/10 [00:00<00:00,  9.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.109963:  20%|##        | 2/10 [00:00<00:00, 19.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,235]\u001b[0m Trial 28 finished with value: 0.126235519957207 and parameters: {'bagging_fraction': 0.6820416099053855, 'bagging_freq': 3}. Best is trial 27 with value: 0.1099633474021663.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.109963:  20%|##        | 2/10 [00:00<00:00, 19.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.103246:  20%|##        | 2/10 [00:00<00:00, 19.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,286]\u001b[0m Trial 29 finished with value: 0.10324579112002029 and parameters: {'bagging_fraction': 0.6165057728546038, 'bagging_freq': 7}. Best is trial 29 with value: 0.10324579112002029.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.103246:  30%|###       | 3/10 [00:00<00:00, 19.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32]\tTrain's multi_logloss: 0.13644\tTest's multi_logloss: 0.151872\n",
      "[33]\tTrain's multi_logloss: 0.133003\tTest's multi_logloss: 0.146903\n",
      "[34]\tTrain's multi_logloss: 0.130044\tTest's multi_logloss: 0.14244\n",
      "[35]\tTrain's multi_logloss: 0.124945\tTest's multi_logloss: 0.138283\n",
      "[36]\tTrain's multi_logloss: 0.121177\tTest's multi_logloss: 0.135396\n",
      "[37]\tTrain's multi_logloss: 0.118879\tTest's multi_logloss: 0.133152\n",
      "[38]\tTrain's multi_logloss: 0.116572\tTest's multi_logloss: 0.130617\n",
      "[39]\tTrain's multi_logloss: 0.11407\tTest's multi_logloss: 0.130478\n",
      "[40]\tTrain's multi_logloss: 0.111441\tTest's multi_logloss: 0.129886\n",
      "[41]\tTrain's multi_logloss: 0.109607\tTest's multi_logloss: 0.124875\n",
      "[42]\tTrain's multi_logloss: 0.108318\tTest's multi_logloss: 0.120658\n",
      "[43]\tTrain's multi_logloss: 0.107083\tTest's multi_logloss: 0.118698\n",
      "[44]\tTrain's multi_logloss: 0.106074\tTest's multi_logloss: 0.117098\n",
      "[45]\tTrain's multi_logloss: 0.103851\tTest's multi_logloss: 0.114\n",
      "[46]\tTrain's multi_logloss: 0.101098\tTest's multi_logloss: 0.111963\n",
      "[47]\tTrain's multi_logloss: 0.0982028\tTest's multi_logloss: 0.111709\n",
      "[48]\tTrain's multi_logloss: 0.0960287\tTest's multi_logloss: 0.111888\n",
      "[49]\tTrain's multi_logloss: 0.0932028\tTest's multi_logloss: 0.112654\n",
      "[50]\tTrain's multi_logloss: 0.0922559\tTest's multi_logloss: 0.114391\n",
      "[51]\tTrain's multi_logloss: 0.0886403\tTest's multi_logloss: 0.114014\n",
      "[52]\tTrain's multi_logloss: 0.0858814\tTest's multi_logloss: 0.114463\n",
      "[53]\tTrain's multi_logloss: 0.0850321\tTest's multi_logloss: 0.114329\n",
      "[54]\tTrain's multi_logloss: 0.0842029\tTest's multi_logloss: 0.111727\n",
      "[55]\tTrain's multi_logloss: 0.0832429\tTest's multi_logloss: 0.111845\n",
      "[56]\tTrain's multi_logloss: 0.0825345\tTest's multi_logloss: 0.109963\n",
      "[57]\tTrain's multi_logloss: 0.0811816\tTest's multi_logloss: 0.110693\n",
      "[58]\tTrain's multi_logloss: 0.0803098\tTest's multi_logloss: 0.111555\n",
      "[59]\tTrain's multi_logloss: 0.0798765\tTest's multi_logloss: 0.11368\n",
      "[60]\tTrain's multi_logloss: 0.0792706\tTest's multi_logloss: 0.116682\n",
      "[61]\tTrain's multi_logloss: 0.0787496\tTest's multi_logloss: 0.114733\n",
      "[62]\tTrain's multi_logloss: 0.0785379\tTest's multi_logloss: 0.114702\n",
      "[63]\tTrain's multi_logloss: 0.0763996\tTest's multi_logloss: 0.115891\n",
      "[64]\tTrain's multi_logloss: 0.0755137\tTest's multi_logloss: 0.11697\n",
      "[65]\tTrain's multi_logloss: 0.073729\tTest's multi_logloss: 0.117888\n",
      "[66]\tTrain's multi_logloss: 0.0729099\tTest's multi_logloss: 0.116988\n",
      "Early stopping, best iteration is:\n",
      "[56]\tTrain's multi_logloss: 0.0825345\tTest's multi_logloss: 0.109963\n",
      "[1]\tTrain's multi_logloss: 0.930395\tTest's multi_logloss: 0.965764\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.79692\tTest's multi_logloss: 0.830955\n",
      "[3]\tTrain's multi_logloss: 0.689805\tTest's multi_logloss: 0.722991\n",
      "[4]\tTrain's multi_logloss: 0.604031\tTest's multi_logloss: 0.630856\n",
      "[5]\tTrain's multi_logloss: 0.531564\tTest's multi_logloss: 0.55995\n",
      "[6]\tTrain's multi_logloss: 0.471147\tTest's multi_logloss: 0.49581\n",
      "[7]\tTrain's multi_logloss: 0.420632\tTest's multi_logloss: 0.447937\n",
      "[8]\tTrain's multi_logloss: 0.377421\tTest's multi_logloss: 0.398882\n",
      "[9]\tTrain's multi_logloss: 0.341099\tTest's multi_logloss: 0.357033\n",
      "[10]\tTrain's multi_logloss: 0.310321\tTest's multi_logloss: 0.325202\n",
      "[11]\tTrain's multi_logloss: 0.284607\tTest's multi_logloss: 0.297231\n",
      "[12]\tTrain's multi_logloss: 0.261946\tTest's multi_logloss: 0.276167\n",
      "[13]\tTrain's multi_logloss: 0.240686\tTest's multi_logloss: 0.256689\n",
      "[14]\tTrain's multi_logloss: 0.223043\tTest's multi_logloss: 0.238646\n",
      "[15]\tTrain's multi_logloss: 0.206382\tTest's multi_logloss: 0.22261\n",
      "[16]\tTrain's multi_logloss: 0.193039\tTest's multi_logloss: 0.209657\n",
      "[17]\tTrain's multi_logloss: 0.182094\tTest's multi_logloss: 0.202056\n",
      "[18]\tTrain's multi_logloss: 0.171187\tTest's multi_logloss: 0.190925\n",
      "[19]\tTrain's multi_logloss: 0.160845\tTest's multi_logloss: 0.18175\n",
      "[20]\tTrain's multi_logloss: 0.153176\tTest's multi_logloss: 0.172791\n",
      "[21]\tTrain's multi_logloss: 0.143653\tTest's multi_logloss: 0.166182\n",
      "[22]\tTrain's multi_logloss: 0.135498\tTest's multi_logloss: 0.161756\n",
      "[23]\tTrain's multi_logloss: 0.129357\tTest's multi_logloss: 0.154779\n",
      "[24]\tTrain's multi_logloss: 0.122512\tTest's multi_logloss: 0.15189\n",
      "[25]\tTrain's multi_logloss: 0.119519\tTest's multi_logloss: 0.149785\n",
      "[26]\tTrain's multi_logloss: 0.115704\tTest's multi_logloss: 0.1472\n",
      "[27]\tTrain's multi_logloss: 0.113015\tTest's multi_logloss: 0.14612\n",
      "[28]\tTrain's multi_logloss: 0.108318\tTest's multi_logloss: 0.14354\n",
      "[29]\tTrain's multi_logloss: 0.103895\tTest's multi_logloss: 0.142014\n",
      "[30]\tTrain's multi_logloss: 0.0996993\tTest's multi_logloss: 0.140162\n",
      "[31]\tTrain's multi_logloss: 0.0967091\tTest's multi_logloss: 0.137105\n",
      "[32]\tTrain's multi_logloss: 0.0928357\tTest's multi_logloss: 0.131323\n",
      "[33]\tTrain's multi_logloss: 0.0895458\tTest's multi_logloss: 0.126236\n",
      "[34]\tTrain's multi_logloss: 0.0857621\tTest's multi_logloss: 0.126864\n",
      "[35]\tTrain's multi_logloss: 0.0834864\tTest's multi_logloss: 0.127149\n",
      "[36]\tTrain's multi_logloss: 0.0818392\tTest's multi_logloss: 0.127352\n",
      "[37]\tTrain's multi_logloss: 0.0800546\tTest's multi_logloss: 0.128121\n",
      "[38]\tTrain's multi_logloss: 0.0786637\tTest's multi_logloss: 0.12927\n",
      "[39]\tTrain's multi_logloss: 0.0773714\tTest's multi_logloss: 0.13061\n",
      "[40]\tTrain's multi_logloss: 0.0751298\tTest's multi_logloss: 0.131252\n",
      "[41]\tTrain's multi_logloss: 0.0727216\tTest's multi_logloss: 0.128145\n",
      "[42]\tTrain's multi_logloss: 0.0705718\tTest's multi_logloss: 0.127609\n",
      "[43]\tTrain's multi_logloss: 0.0663511\tTest's multi_logloss: 0.132542\n",
      "Early stopping, best iteration is:\n",
      "[33]\tTrain's multi_logloss: 0.0895458\tTest's multi_logloss: 0.126236\n",
      "[1]\tTrain's multi_logloss: 0.931228\tTest's multi_logloss: 0.966279\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.798085\tTest's multi_logloss: 0.8318\n",
      "[3]\tTrain's multi_logloss: 0.69117\tTest's multi_logloss: 0.724039\n",
      "[4]\tTrain's multi_logloss: 0.617754\tTest's multi_logloss: 0.653053\n",
      "[5]\tTrain's multi_logloss: 0.556479\tTest's multi_logloss: 0.593165\n",
      "[6]\tTrain's multi_logloss: 0.49975\tTest's multi_logloss: 0.534612\n",
      "[7]\tTrain's multi_logloss: 0.448957\tTest's multi_logloss: 0.482388\n",
      "[8]\tTrain's multi_logloss: 0.399937\tTest's multi_logloss: 0.433874\n",
      "[9]\tTrain's multi_logloss: 0.358192\tTest's multi_logloss: 0.392409\n",
      "[10]\tTrain's multi_logloss: 0.325253\tTest's multi_logloss: 0.359906\n",
      "[11]\tTrain's multi_logloss: 0.294424\tTest's multi_logloss: 0.324468\n",
      "[12]\tTrain's multi_logloss: 0.269735\tTest's multi_logloss: 0.300589\n",
      "[13]\tTrain's multi_logloss: 0.247474\tTest's multi_logloss: 0.272587\n",
      "[14]\tTrain's multi_logloss: 0.229275\tTest's multi_logloss: 0.250099\n",
      "[15]\tTrain's multi_logloss: 0.21287\tTest's multi_logloss: 0.229202\n",
      "[16]\tTrain's multi_logloss: 0.199724\tTest's multi_logloss: 0.213407\n",
      "[17]\tTrain's multi_logloss: 0.189848\tTest's multi_logloss: 0.204678\n",
      "[18]\tTrain's multi_logloss: 0.179747\tTest's multi_logloss: 0.191793\n",
      "[19]\tTrain's multi_logloss: 0.171034\tTest's multi_logloss: 0.18035\n",
      "[20]\tTrain's multi_logloss: 0.163519\tTest's multi_logloss: 0.169271\n",
      "[21]\tTrain's multi_logloss: 0.156999\tTest's multi_logloss: 0.160079\n",
      "[22]\tTrain's multi_logloss: 0.146069\tTest's multi_logloss: 0.15282\n",
      "[23]\tTrain's multi_logloss: 0.140939\tTest's multi_logloss: 0.146636\n",
      "[24]\tTrain's multi_logloss: 0.131527\tTest's multi_logloss: 0.140275\n",
      "[25]\tTrain's multi_logloss: 0.127187\tTest's multi_logloss: 0.135744\n",
      "[26]\tTrain's multi_logloss: 0.123786\tTest's multi_logloss: 0.131676\n",
      "[27]\tTrain's multi_logloss: 0.120061\tTest's multi_logloss: 0.128493\n",
      "[28]\tTrain's multi_logloss: 0.113532\tTest's multi_logloss: 0.125447\n",
      "[29]\tTrain's multi_logloss: 0.108365\tTest's multi_logloss: 0.121243\n",
      "[30]\tTrain's multi_logloss: 0.104627\tTest's multi_logloss: 0.118339\n",
      "[31]\tTrain's multi_logloss: 0.100096\tTest's multi_logloss: 0.117004\n",
      "[32]\tTrain's multi_logloss: 0.0968054\tTest's multi_logloss: 0.116177\n",
      "[33]\tTrain's multi_logloss: 0.093252\tTest's multi_logloss: 0.115876\n",
      "[34]\tTrain's multi_logloss: 0.0896356\tTest's multi_logloss: 0.116438\n",
      "[35]\tTrain's multi_logloss: 0.0873117\tTest's multi_logloss: 0.116302\n",
      "[36]\tTrain's multi_logloss: 0.0850581\tTest's multi_logloss: 0.114901\n",
      "[37]\tTrain's multi_logloss: 0.0834512\tTest's multi_logloss: 0.112974\n",
      "[38]\tTrain's multi_logloss: 0.0815145\tTest's multi_logloss: 0.112032\n",
      "[39]\tTrain's multi_logloss: 0.0797164\tTest's multi_logloss: 0.112142\n",
      "[40]\tTrain's multi_logloss: 0.0785665\tTest's multi_logloss: 0.111445\n",
      "[41]\tTrain's multi_logloss: 0.0778244\tTest's multi_logloss: 0.109503\n",
      "[42]\tTrain's multi_logloss: 0.0767843\tTest's multi_logloss: 0.110312\n",
      "[43]\tTrain's multi_logloss: 0.0754628\tTest's multi_logloss: 0.11027\n",
      "[44]\tTrain's multi_logloss: 0.0744489\tTest's multi_logloss: 0.107732\n",
      "[45]\tTrain's multi_logloss: 0.0732627\tTest's multi_logloss: 0.106508\n",
      "[46]\tTrain's multi_logloss: 0.0724517\tTest's multi_logloss: 0.104263\n",
      "[47]\tTrain's multi_logloss: 0.0718348\tTest's multi_logloss: 0.103246\n",
      "[48]\tTrain's multi_logloss: 0.0711714\tTest's multi_logloss: 0.103438\n",
      "[49]\tTrain's multi_logloss: 0.0703792\tTest's multi_logloss: 0.103701\n",
      "[50]\tTrain's multi_logloss: 0.0692601\tTest's multi_logloss: 0.104639\n",
      "[51]\tTrain's multi_logloss: 0.0686606\tTest's multi_logloss: 0.104788\n",
      "[52]\tTrain's multi_logloss: 0.0682538\tTest's multi_logloss: 0.105116\n",
      "[53]\tTrain's multi_logloss: 0.0680186\tTest's multi_logloss: 0.105598\n",
      "[54]\tTrain's multi_logloss: 0.0677055\tTest's multi_logloss: 0.105736\n",
      "[55]\tTrain's multi_logloss: 0.067256\tTest's multi_logloss: 0.106738\n",
      "[56]\tTrain's multi_logloss: 0.0671485\tTest's multi_logloss: 0.1083\n",
      "[57]\tTrain's multi_logloss: 0.0657531\tTest's multi_logloss: 0.109152\n",
      "Early stopping, best iteration is:\n",
      "[47]\tTrain's multi_logloss: 0.0718348\tTest's multi_logloss: 0.103246\n",
      "[1]\tTrain's multi_logloss: 0.93081\tTest's multi_logloss: 0.957949\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.798184\tTest's multi_logloss: 0.818041\n",
      "[3]\tTrain's multi_logloss: 0.688266\tTest's multi_logloss: 0.713907\n",
      "[4]\tTrain's multi_logloss: 0.600844\tTest's multi_logloss: 0.625517\n",
      "[5]\tTrain's multi_logloss: 0.526031\tTest's multi_logloss: 0.544942\n",
      "[6]\tTrain's multi_logloss: 0.467146\tTest's multi_logloss: 0.490515\n",
      "[7]\tTrain's multi_logloss: 0.415902\tTest's multi_logloss: 0.447308\n",
      "[8]\tTrain's multi_logloss: 0.372236\tTest's multi_logloss: 0.396226\n",
      "[9]\tTrain's multi_logloss: 0.335665\tTest's multi_logloss: 0.363305\n",
      "[10]\tTrain's multi_logloss: 0.302712\tTest's multi_logloss: 0.329839\n",
      "[11]\tTrain's multi_logloss: 0.275189\tTest's multi_logloss: 0.30829\n",
      "[12]\tTrain's multi_logloss: 0.251469\tTest's multi_logloss: 0.283207\n",
      "[13]\tTrain's multi_logloss: 0.230609\tTest's multi_logloss: 0.26206\n",
      "[14]\tTrain's multi_logloss: 0.211921\tTest's multi_logloss: 0.248162\n",
      "[15]\tTrain's multi_logloss: 0.195553\tTest's multi_logloss: 0.232974\n",
      "[16]\tTrain's multi_logloss: 0.181238\tTest's multi_logloss: 0.219449\n",
      "[17]\tTrain's multi_logloss: 0.169213\tTest's multi_logloss: 0.210608\n",
      "[18]\tTrain's multi_logloss: 0.158693\tTest's multi_logloss: 0.200575\n",
      "[19]\tTrain's multi_logloss: 0.147921\tTest's multi_logloss: 0.19362\n",
      "[20]\tTrain's multi_logloss: 0.140296\tTest's multi_logloss: 0.186815\n",
      "[21]\tTrain's multi_logloss: 0.132524\tTest's multi_logloss: 0.174121\n",
      "[22]\tTrain's multi_logloss: 0.125862\tTest's multi_logloss: 0.165179\n",
      "[23]\tTrain's multi_logloss: 0.120235\tTest's multi_logloss: 0.161057\n",
      "[24]\tTrain's multi_logloss: 0.113748\tTest's multi_logloss: 0.156992\n",
      "[25]\tTrain's multi_logloss: 0.109798\tTest's multi_logloss: 0.154633\n",
      "[26]\tTrain's multi_logloss: 0.106255\tTest's multi_logloss: 0.151972\n",
      "[27]\tTrain's multi_logloss: 0.102118\tTest's multi_logloss: 0.144655\n",
      "[28]\tTrain's multi_logloss: 0.0963125\tTest's multi_logloss: 0.143124\n",
      "[29]\tTrain's multi_logloss: 0.092667\tTest's multi_logloss: 0.143786\n",
      "[30]\tTrain's multi_logloss: 0.0901651\tTest's multi_logloss: 0.142978\n",
      "[31]\tTrain's multi_logloss: 0.0863996\tTest's multi_logloss: 0.139358\n",
      "[32]\tTrain's multi_logloss: 0.0837555\tTest's multi_logloss: 0.137966\n",
      "[33]\tTrain's multi_logloss: 0.079166\tTest's multi_logloss: 0.137814\n",
      "[34]\tTrain's multi_logloss: 0.0749955\tTest's multi_logloss: 0.1401\n",
      "[35]\tTrain's multi_logloss: 0.0715573\tTest's multi_logloss: 0.138661\n",
      "[36]\tTrain's multi_logloss: 0.0694909\tTest's multi_logloss: 0.135075\n",
      "[37]\tTrain's multi_logloss: 0.0677423\tTest's multi_logloss: 0.133709\n",
      "[38]\tTrain's multi_logloss: 0.0649575\tTest's multi_logloss: 0.132294\n",
      "[39]\tTrain's multi_logloss: 0.0616663\tTest's multi_logloss: 0.1312\n",
      "[40]\tTrain's multi_logloss: 0.0592512\tTest's multi_logloss: 0.130387\n",
      "[41]\tTrain's multi_logloss: 0.057915\tTest's multi_logloss: 0.125219\n",
      "[42]\tTrain's multi_logloss: 0.0564963\tTest's multi_logloss: 0.120658\n",
      "[43]\tTrain's multi_logloss: 0.0537749\tTest's multi_logloss: 0.122278\n",
      "[44]\tTrain's multi_logloss: 0.0525299\tTest's multi_logloss: 0.122268\n",
      "[45]\tTrain's multi_logloss: 0.0511587\tTest's multi_logloss: 0.122852\n",
      "[46]\tTrain's multi_logloss: 0.0498396\tTest's multi_logloss: 0.120404\n",
      "[47]\tTrain's multi_logloss: 0.0485882\tTest's multi_logloss: 0.120563\n",
      "[48]\tTrain's multi_logloss: 0.0477811\tTest's multi_logloss: 0.120831\n",
      "[49]\tTrain's multi_logloss: 0.0452857\tTest's multi_logloss: 0.123786\n",
      "[50]\tTrain's multi_logloss: 0.044588\tTest's multi_logloss: 0.123843\n",
      "[51]\tTrain's multi_logloss: 0.043217\tTest's multi_logloss: 0.12648\n",
      "[52]\tTrain's multi_logloss: 0.0418199\tTest's multi_logloss: 0.129445\n",
      "[53]\tTrain's multi_logloss: 0.0412487\tTest's multi_logloss: 0.129706\n",
      "[54]\tTrain's multi_logloss: 0.0406182\tTest's multi_logloss: 0.128491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.103246:  30%|###       | 3/10 [00:00<00:00, 19.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.103246:  40%|####      | 4/10 [00:00<00:00, 18.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,343]\u001b[0m Trial 30 finished with value: 0.12040370428541156 and parameters: {'bagging_fraction': 0.7888309629614069, 'bagging_freq': 2}. Best is trial 29 with value: 0.10324579112002029.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.103246:  40%|####      | 4/10 [00:00<00:00, 18.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\tTrain's multi_logloss: 0.0400285\tTest's multi_logloss: 0.128787\n",
      "[56]\tTrain's multi_logloss: 0.0387414\tTest's multi_logloss: 0.127935\n",
      "Early stopping, best iteration is:\n",
      "[46]\tTrain's multi_logloss: 0.0498396\tTest's multi_logloss: 0.120404\n",
      "[1]\tTrain's multi_logloss: 0.93081\tTest's multi_logloss: 0.957949\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.798184\tTest's multi_logloss: 0.818041\n",
      "[3]\tTrain's multi_logloss: 0.688582\tTest's multi_logloss: 0.714116\n",
      "[4]\tTrain's multi_logloss: 0.601638\tTest's multi_logloss: 0.626247\n",
      "[5]\tTrain's multi_logloss: 0.52699\tTest's multi_logloss: 0.545814\n",
      "[6]\tTrain's multi_logloss: 0.468274\tTest's multi_logloss: 0.491675\n",
      "[7]\tTrain's multi_logloss: 0.416862\tTest's multi_logloss: 0.44832\n",
      "[8]\tTrain's multi_logloss: 0.376628\tTest's multi_logloss: 0.403093\n",
      "[9]\tTrain's multi_logloss: 0.34005\tTest's multi_logloss: 0.369852\n",
      "[10]\tTrain's multi_logloss: 0.309723\tTest's multi_logloss: 0.338542\n",
      "[11]\tTrain's multi_logloss: 0.28342\tTest's multi_logloss: 0.310866\n",
      "[12]\tTrain's multi_logloss: 0.260029\tTest's multi_logloss: 0.287349\n",
      "[13]\tTrain's multi_logloss: 0.238398\tTest's multi_logloss: 0.265303\n",
      "[14]\tTrain's multi_logloss: 0.219687\tTest's multi_logloss: 0.249009\n",
      "[15]\tTrain's multi_logloss: 0.202649\tTest's multi_logloss: 0.233369\n",
      "[16]\tTrain's multi_logloss: 0.187772\tTest's multi_logloss: 0.219235\n",
      "[17]\tTrain's multi_logloss: 0.173306\tTest's multi_logloss: 0.208164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.103246:  40%|####      | 4/10 [00:00<00:00, 18.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,402]\u001b[0m Trial 31 finished with value: 0.11830729855377409 and parameters: {'bagging_fraction': 0.7638660850213541, 'bagging_freq': 2}. Best is trial 29 with value: 0.10324579112002029.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.103246:  50%|#####     | 5/10 [00:00<00:00, 18.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.101244:  50%|#####     | 5/10 [00:00<00:00, 18.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.101244:  60%|######    | 6/10 [00:00<00:00, 17.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,467]\u001b[0m Trial 32 finished with value: 0.10124440640086942 and parameters: {'bagging_fraction': 0.41783118517876444, 'bagging_freq': 2}. Best is trial 32 with value: 0.10124440640086942.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.101244:  60%|######    | 6/10 [00:00<00:00, 17.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754:  60%|######    | 6/10 [00:00<00:00, 17.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,520]\u001b[0m Trial 33 finished with value: 0.09675416222275754 and parameters: {'bagging_fraction': 0.43530149594535855, 'bagging_freq': 6}. Best is trial 33 with value: 0.09675416222275754.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754:  70%|#######   | 7/10 [00:00<00:00, 17.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\tTrain's multi_logloss: 0.16254\tTest's multi_logloss: 0.198043\n",
      "[19]\tTrain's multi_logloss: 0.151596\tTest's multi_logloss: 0.190624\n",
      "[20]\tTrain's multi_logloss: 0.143874\tTest's multi_logloss: 0.183809\n",
      "[21]\tTrain's multi_logloss: 0.135868\tTest's multi_logloss: 0.170361\n",
      "[22]\tTrain's multi_logloss: 0.129775\tTest's multi_logloss: 0.162385\n",
      "[23]\tTrain's multi_logloss: 0.123566\tTest's multi_logloss: 0.157518\n",
      "[24]\tTrain's multi_logloss: 0.117066\tTest's multi_logloss: 0.153852\n",
      "[25]\tTrain's multi_logloss: 0.113011\tTest's multi_logloss: 0.151597\n",
      "[26]\tTrain's multi_logloss: 0.109927\tTest's multi_logloss: 0.148823\n",
      "[27]\tTrain's multi_logloss: 0.105795\tTest's multi_logloss: 0.14435\n",
      "[28]\tTrain's multi_logloss: 0.100281\tTest's multi_logloss: 0.140552\n",
      "[29]\tTrain's multi_logloss: 0.0966344\tTest's multi_logloss: 0.140862\n",
      "[30]\tTrain's multi_logloss: 0.0940158\tTest's multi_logloss: 0.139371\n",
      "[31]\tTrain's multi_logloss: 0.0905803\tTest's multi_logloss: 0.136022\n",
      "[32]\tTrain's multi_logloss: 0.087477\tTest's multi_logloss: 0.13311\n",
      "[33]\tTrain's multi_logloss: 0.0828555\tTest's multi_logloss: 0.133381\n",
      "[34]\tTrain's multi_logloss: 0.0785094\tTest's multi_logloss: 0.134744\n",
      "[35]\tTrain's multi_logloss: 0.0747288\tTest's multi_logloss: 0.134504\n",
      "[36]\tTrain's multi_logloss: 0.072736\tTest's multi_logloss: 0.134303\n",
      "[37]\tTrain's multi_logloss: 0.0706995\tTest's multi_logloss: 0.132792\n",
      "[38]\tTrain's multi_logloss: 0.0681514\tTest's multi_logloss: 0.131394\n",
      "[39]\tTrain's multi_logloss: 0.0650464\tTest's multi_logloss: 0.130128\n",
      "[40]\tTrain's multi_logloss: 0.0617406\tTest's multi_logloss: 0.128114\n",
      "[41]\tTrain's multi_logloss: 0.0605767\tTest's multi_logloss: 0.1253\n",
      "[42]\tTrain's multi_logloss: 0.0596607\tTest's multi_logloss: 0.120291\n",
      "[43]\tTrain's multi_logloss: 0.058655\tTest's multi_logloss: 0.120245\n",
      "[44]\tTrain's multi_logloss: 0.0580328\tTest's multi_logloss: 0.119313\n",
      "[45]\tTrain's multi_logloss: 0.0568975\tTest's multi_logloss: 0.120092\n",
      "[46]\tTrain's multi_logloss: 0.0557566\tTest's multi_logloss: 0.118307\n",
      "[47]\tTrain's multi_logloss: 0.0535913\tTest's multi_logloss: 0.119696\n",
      "[48]\tTrain's multi_logloss: 0.0521304\tTest's multi_logloss: 0.120359\n",
      "[49]\tTrain's multi_logloss: 0.0497879\tTest's multi_logloss: 0.122305\n",
      "[50]\tTrain's multi_logloss: 0.0488778\tTest's multi_logloss: 0.12264\n",
      "[51]\tTrain's multi_logloss: 0.0457123\tTest's multi_logloss: 0.12814\n",
      "[52]\tTrain's multi_logloss: 0.0437209\tTest's multi_logloss: 0.131857\n",
      "[53]\tTrain's multi_logloss: 0.0432825\tTest's multi_logloss: 0.132694\n",
      "[54]\tTrain's multi_logloss: 0.0427639\tTest's multi_logloss: 0.133097\n",
      "[55]\tTrain's multi_logloss: 0.0420521\tTest's multi_logloss: 0.133818\n",
      "[56]\tTrain's multi_logloss: 0.0415061\tTest's multi_logloss: 0.13426\n",
      "Early stopping, best iteration is:\n",
      "[46]\tTrain's multi_logloss: 0.0557566\tTest's multi_logloss: 0.118307\n",
      "[1]\tTrain's multi_logloss: 0.997954\tTest's multi_logloss: 1.03823\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.914091\tTest's multi_logloss: 0.955622\n",
      "[3]\tTrain's multi_logloss: 0.829794\tTest's multi_logloss: 0.865031\n",
      "[4]\tTrain's multi_logloss: 0.767581\tTest's multi_logloss: 0.798963\n",
      "[5]\tTrain's multi_logloss: 0.707674\tTest's multi_logloss: 0.745116\n",
      "[6]\tTrain's multi_logloss: 0.657743\tTest's multi_logloss: 0.694401\n",
      "[7]\tTrain's multi_logloss: 0.657743\tTest's multi_logloss: 0.694401\n",
      "[8]\tTrain's multi_logloss: 0.606058\tTest's multi_logloss: 0.637222\n",
      "[9]\tTrain's multi_logloss: 0.560929\tTest's multi_logloss: 0.589392\n",
      "[10]\tTrain's multi_logloss: 0.533711\tTest's multi_logloss: 0.56726\n",
      "[11]\tTrain's multi_logloss: 0.508987\tTest's multi_logloss: 0.548341\n",
      "[12]\tTrain's multi_logloss: 0.474342\tTest's multi_logloss: 0.508398\n",
      "[13]\tTrain's multi_logloss: 0.44355\tTest's multi_logloss: 0.470945\n",
      "[14]\tTrain's multi_logloss: 0.421649\tTest's multi_logloss: 0.444852\n",
      "[15]\tTrain's multi_logloss: 0.399863\tTest's multi_logloss: 0.42037\n",
      "[16]\tTrain's multi_logloss: 0.399863\tTest's multi_logloss: 0.42037\n",
      "[17]\tTrain's multi_logloss: 0.399863\tTest's multi_logloss: 0.42037\n",
      "[18]\tTrain's multi_logloss: 0.373715\tTest's multi_logloss: 0.387888\n",
      "[19]\tTrain's multi_logloss: 0.350639\tTest's multi_logloss: 0.360692\n",
      "[20]\tTrain's multi_logloss: 0.330622\tTest's multi_logloss: 0.338671\n",
      "[21]\tTrain's multi_logloss: 0.310909\tTest's multi_logloss: 0.32475\n",
      "[22]\tTrain's multi_logloss: 0.310909\tTest's multi_logloss: 0.32475\n",
      "[23]\tTrain's multi_logloss: 0.296361\tTest's multi_logloss: 0.308318\n",
      "[24]\tTrain's multi_logloss: 0.280698\tTest's multi_logloss: 0.294426\n",
      "[25]\tTrain's multi_logloss: 0.272008\tTest's multi_logloss: 0.28939\n",
      "[26]\tTrain's multi_logloss: 0.261253\tTest's multi_logloss: 0.280017\n",
      "[27]\tTrain's multi_logloss: 0.253368\tTest's multi_logloss: 0.27297\n",
      "[28]\tTrain's multi_logloss: 0.246777\tTest's multi_logloss: 0.265663\n",
      "[29]\tTrain's multi_logloss: 0.233753\tTest's multi_logloss: 0.253201\n",
      "[30]\tTrain's multi_logloss: 0.227934\tTest's multi_logloss: 0.245566\n",
      "[31]\tTrain's multi_logloss: 0.222355\tTest's multi_logloss: 0.237673\n",
      "[32]\tTrain's multi_logloss: 0.216642\tTest's multi_logloss: 0.229181\n",
      "[33]\tTrain's multi_logloss: 0.21077\tTest's multi_logloss: 0.221043\n",
      "[34]\tTrain's multi_logloss: 0.204534\tTest's multi_logloss: 0.212624\n",
      "[35]\tTrain's multi_logloss: 0.196008\tTest's multi_logloss: 0.199864\n",
      "[36]\tTrain's multi_logloss: 0.189106\tTest's multi_logloss: 0.190037\n",
      "[37]\tTrain's multi_logloss: 0.182366\tTest's multi_logloss: 0.180478\n",
      "[38]\tTrain's multi_logloss: 0.174179\tTest's multi_logloss: 0.172376\n",
      "[39]\tTrain's multi_logloss: 0.171488\tTest's multi_logloss: 0.169988\n",
      "[40]\tTrain's multi_logloss: 0.167946\tTest's multi_logloss: 0.166898\n",
      "[41]\tTrain's multi_logloss: 0.16218\tTest's multi_logloss: 0.1613\n",
      "[42]\tTrain's multi_logloss: 0.158107\tTest's multi_logloss: 0.154988\n",
      "[43]\tTrain's multi_logloss: 0.153965\tTest's multi_logloss: 0.151416\n",
      "[44]\tTrain's multi_logloss: 0.154185\tTest's multi_logloss: 0.151476\n",
      "[45]\tTrain's multi_logloss: 0.153082\tTest's multi_logloss: 0.150425\n",
      "[46]\tTrain's multi_logloss: 0.149829\tTest's multi_logloss: 0.148101\n",
      "[47]\tTrain's multi_logloss: 0.146589\tTest's multi_logloss: 0.143094\n",
      "[48]\tTrain's multi_logloss: 0.143915\tTest's multi_logloss: 0.138988\n",
      "[49]\tTrain's multi_logloss: 0.138751\tTest's multi_logloss: 0.135137\n",
      "[50]\tTrain's multi_logloss: 0.138112\tTest's multi_logloss: 0.1339\n",
      "[51]\tTrain's multi_logloss: 0.137642\tTest's multi_logloss: 0.133396\n",
      "[52]\tTrain's multi_logloss: 0.137456\tTest's multi_logloss: 0.133325\n",
      "[53]\tTrain's multi_logloss: 0.137456\tTest's multi_logloss: 0.133325\n",
      "[54]\tTrain's multi_logloss: 0.13692\tTest's multi_logloss: 0.132436\n",
      "[55]\tTrain's multi_logloss: 0.13478\tTest's multi_logloss: 0.131859\n",
      "[56]\tTrain's multi_logloss: 0.128972\tTest's multi_logloss: 0.126817\n",
      "[57]\tTrain's multi_logloss: 0.123802\tTest's multi_logloss: 0.122474\n",
      "[58]\tTrain's multi_logloss: 0.120964\tTest's multi_logloss: 0.121013\n",
      "[59]\tTrain's multi_logloss: 0.115999\tTest's multi_logloss: 0.119177\n",
      "[60]\tTrain's multi_logloss: 0.114014\tTest's multi_logloss: 0.117244\n",
      "[61]\tTrain's multi_logloss: 0.113221\tTest's multi_logloss: 0.116265\n",
      "[62]\tTrain's multi_logloss: 0.113221\tTest's multi_logloss: 0.116265\n",
      "[63]\tTrain's multi_logloss: 0.10933\tTest's multi_logloss: 0.113314\n",
      "[64]\tTrain's multi_logloss: 0.107417\tTest's multi_logloss: 0.110658\n",
      "[65]\tTrain's multi_logloss: 0.106518\tTest's multi_logloss: 0.11056\n",
      "[66]\tTrain's multi_logloss: 0.106177\tTest's multi_logloss: 0.110839\n",
      "[67]\tTrain's multi_logloss: 0.106177\tTest's multi_logloss: 0.110839\n",
      "[68]\tTrain's multi_logloss: 0.105725\tTest's multi_logloss: 0.109629\n",
      "[69]\tTrain's multi_logloss: 0.105452\tTest's multi_logloss: 0.109137\n",
      "[70]\tTrain's multi_logloss: 0.104172\tTest's multi_logloss: 0.112418\n",
      "[71]\tTrain's multi_logloss: 0.102082\tTest's multi_logloss: 0.112181\n",
      "[72]\tTrain's multi_logloss: 0.101321\tTest's multi_logloss: 0.111835\n",
      "[73]\tTrain's multi_logloss: 0.100151\tTest's multi_logloss: 0.110572\n",
      "[74]\tTrain's multi_logloss: 0.0987334\tTest's multi_logloss: 0.109445\n",
      "[75]\tTrain's multi_logloss: 0.0988077\tTest's multi_logloss: 0.108623\n",
      "[76]\tTrain's multi_logloss: 0.0988077\tTest's multi_logloss: 0.108623\n",
      "[77]\tTrain's multi_logloss: 0.0979285\tTest's multi_logloss: 0.107527\n",
      "[78]\tTrain's multi_logloss: 0.0972697\tTest's multi_logloss: 0.106737\n",
      "[79]\tTrain's multi_logloss: 0.0972697\tTest's multi_logloss: 0.106737\n",
      "[80]\tTrain's multi_logloss: 0.0972697\tTest's multi_logloss: 0.106737\n",
      "[81]\tTrain's multi_logloss: 0.0973222\tTest's multi_logloss: 0.106808\n",
      "[82]\tTrain's multi_logloss: 0.0973754\tTest's multi_logloss: 0.106881\n",
      "[83]\tTrain's multi_logloss: 0.0966058\tTest's multi_logloss: 0.100923\n",
      "[84]\tTrain's multi_logloss: 0.0962855\tTest's multi_logloss: 0.0981543\n",
      "[85]\tTrain's multi_logloss: 0.0961509\tTest's multi_logloss: 0.0979253\n",
      "[86]\tTrain's multi_logloss: 0.0969258\tTest's multi_logloss: 0.0987238\n",
      "[87]\tTrain's multi_logloss: 0.0952309\tTest's multi_logloss: 0.100185\n",
      "[88]\tTrain's multi_logloss: 0.0932984\tTest's multi_logloss: 0.100593\n",
      "[89]\tTrain's multi_logloss: 0.0894523\tTest's multi_logloss: 0.098291\n",
      "[90]\tTrain's multi_logloss: 0.0872212\tTest's multi_logloss: 0.0970918\n",
      "[91]\tTrain's multi_logloss: 0.084305\tTest's multi_logloss: 0.0976434\n",
      "[92]\tTrain's multi_logloss: 0.0821784\tTest's multi_logloss: 0.0985129\n",
      "[93]\tTrain's multi_logloss: 0.0821611\tTest's multi_logloss: 0.0985415\n",
      "[94]\tTrain's multi_logloss: 0.0816372\tTest's multi_logloss: 0.0979048\n",
      "[95]\tTrain's multi_logloss: 0.0794741\tTest's multi_logloss: 0.0995378\n",
      "[96]\tTrain's multi_logloss: 0.0784092\tTest's multi_logloss: 0.101281\n",
      "[97]\tTrain's multi_logloss: 0.0784092\tTest's multi_logloss: 0.101281\n",
      "[98]\tTrain's multi_logloss: 0.0784055\tTest's multi_logloss: 0.101135\n",
      "[99]\tTrain's multi_logloss: 0.0784088\tTest's multi_logloss: 0.102344\n",
      "[100]\tTrain's multi_logloss: 0.0775006\tTest's multi_logloss: 0.101244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's multi_logloss: 0.0775006\tTest's multi_logloss: 0.101244\n",
      "[1]\tTrain's multi_logloss: 0.983222\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88597\tTest's multi_logloss: 0.923548\n",
      "[3]\tTrain's multi_logloss: 0.806014\tTest's multi_logloss: 0.840006\n",
      "[4]\tTrain's multi_logloss: 0.738065\tTest's multi_logloss: 0.767251\n",
      "[5]\tTrain's multi_logloss: 0.673282\tTest's multi_logloss: 0.698602\n",
      "[6]\tTrain's multi_logloss: 0.617878\tTest's multi_logloss: 0.643634\n",
      "[7]\tTrain's multi_logloss: 0.57934\tTest's multi_logloss: 0.602583\n",
      "[8]\tTrain's multi_logloss: 0.541765\tTest's multi_logloss: 0.560331\n",
      "[9]\tTrain's multi_logloss: 0.50884\tTest's multi_logloss: 0.523347\n",
      "[10]\tTrain's multi_logloss: 0.479527\tTest's multi_logloss: 0.490092\n",
      "[11]\tTrain's multi_logloss: 0.451586\tTest's multi_logloss: 0.457504\n",
      "[12]\tTrain's multi_logloss: 0.419615\tTest's multi_logloss: 0.426636\n",
      "[13]\tTrain's multi_logloss: 0.386908\tTest's multi_logloss: 0.3914\n",
      "[14]\tTrain's multi_logloss: 0.359833\tTest's multi_logloss: 0.360838\n",
      "[15]\tTrain's multi_logloss: 0.335844\tTest's multi_logloss: 0.337177\n",
      "[16]\tTrain's multi_logloss: 0.314675\tTest's multi_logloss: 0.31581\n",
      "[17]\tTrain's multi_logloss: 0.29616\tTest's multi_logloss: 0.298323\n",
      "[18]\tTrain's multi_logloss: 0.279269\tTest's multi_logloss: 0.277604\n",
      "[19]\tTrain's multi_logloss: 0.276059\tTest's multi_logloss: 0.274574\n",
      "[20]\tTrain's multi_logloss: 0.271726\tTest's multi_logloss: 0.272045\n",
      "[21]\tTrain's multi_logloss: 0.269129\tTest's multi_logloss: 0.269575\n",
      "[22]\tTrain's multi_logloss: 0.262998\tTest's multi_logloss: 0.263206\n",
      "[23]\tTrain's multi_logloss: 0.259571\tTest's multi_logloss: 0.261599\n",
      "[24]\tTrain's multi_logloss: 0.258693\tTest's multi_logloss: 0.262103\n",
      "[25]\tTrain's multi_logloss: 0.247252\tTest's multi_logloss: 0.245584\n",
      "[26]\tTrain's multi_logloss: 0.236045\tTest's multi_logloss: 0.230916\n",
      "[27]\tTrain's multi_logloss: 0.226512\tTest's multi_logloss: 0.216599\n",
      "[28]\tTrain's multi_logloss: 0.216354\tTest's multi_logloss: 0.205554\n",
      "[29]\tTrain's multi_logloss: 0.206152\tTest's multi_logloss: 0.195255\n",
      "[30]\tTrain's multi_logloss: 0.199206\tTest's multi_logloss: 0.184972\n",
      "[31]\tTrain's multi_logloss: 0.195468\tTest's multi_logloss: 0.182073\n",
      "[32]\tTrain's multi_logloss: 0.191326\tTest's multi_logloss: 0.178801\n",
      "[33]\tTrain's multi_logloss: 0.182914\tTest's multi_logloss: 0.173068\n",
      "[34]\tTrain's multi_logloss: 0.17542\tTest's multi_logloss: 0.167818\n",
      "[35]\tTrain's multi_logloss: 0.168744\tTest's multi_logloss: 0.163168\n",
      "[36]\tTrain's multi_logloss: 0.164981\tTest's multi_logloss: 0.161201\n",
      "[37]\tTrain's multi_logloss: 0.159243\tTest's multi_logloss: 0.152001\n",
      "[38]\tTrain's multi_logloss: 0.155178\tTest's multi_logloss: 0.147804\n",
      "[39]\tTrain's multi_logloss: 0.151789\tTest's multi_logloss: 0.14432\n",
      "[40]\tTrain's multi_logloss: 0.149042\tTest's multi_logloss: 0.14164\n",
      "[41]\tTrain's multi_logloss: 0.145128\tTest's multi_logloss: 0.135229\n",
      "[42]\tTrain's multi_logloss: 0.141753\tTest's multi_logloss: 0.129721\n",
      "[43]\tTrain's multi_logloss: 0.14036\tTest's multi_logloss: 0.127913\n",
      "[44]\tTrain's multi_logloss: 0.139153\tTest's multi_logloss: 0.126336\n",
      "[45]\tTrain's multi_logloss: 0.138039\tTest's multi_logloss: 0.124835\n",
      "[46]\tTrain's multi_logloss: 0.137074\tTest's multi_logloss: 0.123565\n",
      "[47]\tTrain's multi_logloss: 0.136801\tTest's multi_logloss: 0.122718\n",
      "[48]\tTrain's multi_logloss: 0.135769\tTest's multi_logloss: 0.121612\n",
      "[49]\tTrain's multi_logloss: 0.13365\tTest's multi_logloss: 0.120226\n",
      "[50]\tTrain's multi_logloss: 0.131747\tTest's multi_logloss: 0.119013\n",
      "[51]\tTrain's multi_logloss: 0.129082\tTest's multi_logloss: 0.117172\n",
      "[52]\tTrain's multi_logloss: 0.127766\tTest's multi_logloss: 0.116754\n",
      "[53]\tTrain's multi_logloss: 0.127466\tTest's multi_logloss: 0.11798\n",
      "[54]\tTrain's multi_logloss: 0.126004\tTest's multi_logloss: 0.117093\n",
      "[55]\tTrain's multi_logloss: 0.1231\tTest's multi_logloss: 0.116191\n",
      "[56]\tTrain's multi_logloss: 0.121516\tTest's multi_logloss: 0.116173\n",
      "[57]\tTrain's multi_logloss: 0.120061\tTest's multi_logloss: 0.11627\n",
      "[58]\tTrain's multi_logloss: 0.120197\tTest's multi_logloss: 0.116856\n",
      "[59]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[60]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[61]\tTrain's multi_logloss: 0.118679\tTest's multi_logloss: 0.117309\n",
      "[62]\tTrain's multi_logloss: 0.116474\tTest's multi_logloss: 0.113988\n",
      "[63]\tTrain's multi_logloss: 0.11442\tTest's multi_logloss: 0.111441\n",
      "[64]\tTrain's multi_logloss: 0.112302\tTest's multi_logloss: 0.106502\n",
      "[65]\tTrain's multi_logloss: 0.110531\tTest's multi_logloss: 0.102165\n",
      "[66]\tTrain's multi_logloss: 0.108849\tTest's multi_logloss: 0.100404\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[68]\tTrain's multi_logloss: 0.106835\tTest's multi_logloss: 0.0980864\n",
      "[69]\tTrain's multi_logloss: 0.106358\tTest's multi_logloss: 0.0995676\n",
      "[70]\tTrain's multi_logloss: 0.106068\tTest's multi_logloss: 0.100975\n",
      "[71]\tTrain's multi_logloss: 0.104974\tTest's multi_logloss: 0.10047\n",
      "[72]\tTrain's multi_logloss: 0.104922\tTest's multi_logloss: 0.10199\n",
      "[73]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[74]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[75]\tTrain's multi_logloss: 0.102982\tTest's multi_logloss: 0.100988\n",
      "[76]\tTrain's multi_logloss: 0.101918\tTest's multi_logloss: 0.100274\n",
      "[77]\tTrain's multi_logloss: 0.102118\tTest's multi_logloss: 0.0978103\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[1]\tTrain's multi_logloss: 0.927523\tTest's multi_logloss: 0.949491\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.794972\tTest's multi_logloss: 0.825985\n",
      "[3]\tTrain's multi_logloss: 0.686948\tTest's multi_logloss: 0.717873\n",
      "[4]\tTrain's multi_logloss: 0.601168\tTest's multi_logloss: 0.624438\n",
      "[5]\tTrain's multi_logloss: 0.528697\tTest's multi_logloss: 0.551672\n",
      "[6]\tTrain's multi_logloss: 0.465883\tTest's multi_logloss: 0.496193\n",
      "[7]\tTrain's multi_logloss: 0.413779\tTest's multi_logloss: 0.444473\n",
      "[8]\tTrain's multi_logloss: 0.370312\tTest's multi_logloss: 0.396082\n",
      "[9]\tTrain's multi_logloss: 0.331231\tTest's multi_logloss: 0.36242\n",
      "[10]\tTrain's multi_logloss: 0.297486\tTest's multi_logloss: 0.333163\n",
      "[11]\tTrain's multi_logloss: 0.269817\tTest's multi_logloss: 0.311307\n",
      "[12]\tTrain's multi_logloss: 0.247411\tTest's multi_logloss: 0.284666\n",
      "[13]\tTrain's multi_logloss: 0.225984\tTest's multi_logloss: 0.268146\n",
      "[14]\tTrain's multi_logloss: 0.207328\tTest's multi_logloss: 0.253988\n",
      "[15]\tTrain's multi_logloss: 0.191111\tTest's multi_logloss: 0.242422\n",
      "[16]\tTrain's multi_logloss: 0.176807\tTest's multi_logloss: 0.232017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\tTrain's multi_logloss: 0.165525\tTest's multi_logloss: 0.219456\n",
      "[18]\tTrain's multi_logloss: 0.154412\tTest's multi_logloss: 0.207581\n",
      "[19]\tTrain's multi_logloss: 0.14473\tTest's multi_logloss: 0.197461\n",
      "[20]\tTrain's multi_logloss: 0.135923\tTest's multi_logloss: 0.187234\n",
      "[21]\tTrain's multi_logloss: 0.12707\tTest's multi_logloss: 0.178675\n",
      "[22]\tTrain's multi_logloss: 0.119504\tTest's multi_logloss: 0.17569\n",
      "[23]\tTrain's multi_logloss: 0.113785\tTest's multi_logloss: 0.172246\n",
      "[24]\tTrain's multi_logloss: 0.107772\tTest's multi_logloss: 0.167316\n",
      "[25]\tTrain's multi_logloss: 0.102108\tTest's multi_logloss: 0.164243\n",
      "[26]\tTrain's multi_logloss: 0.0981135\tTest's multi_logloss: 0.155023\n",
      "[27]\tTrain's multi_logloss: 0.0947196\tTest's multi_logloss: 0.152903\n",
      "[28]\tTrain's multi_logloss: 0.0895174\tTest's multi_logloss: 0.150121\n",
      "[29]\tTrain's multi_logloss: 0.0847641\tTest's multi_logloss: 0.149999\n",
      "[30]\tTrain's multi_logloss: 0.0807569\tTest's multi_logloss: 0.147478\n",
      "[31]\tTrain's multi_logloss: 0.0766824\tTest's multi_logloss: 0.1459\n",
      "[32]\tTrain's multi_logloss: 0.0720059\tTest's multi_logloss: 0.143472\n",
      "[33]\tTrain's multi_logloss: 0.0684199\tTest's multi_logloss: 0.141658\n",
      "[34]\tTrain's multi_logloss: 0.0652484\tTest's multi_logloss: 0.139668\n",
      "[35]\tTrain's multi_logloss: 0.0618637\tTest's multi_logloss: 0.140335\n",
      "[36]\tTrain's multi_logloss: 0.0596283\tTest's multi_logloss: 0.137964\n",
      "[37]\tTrain's multi_logloss: 0.0560244\tTest's multi_logloss: 0.139817\n",
      "[38]\tTrain's multi_logloss: 0.0536929\tTest's multi_logloss: 0.137875\n",
      "[39]\tTrain's multi_logloss: 0.0512686\tTest's multi_logloss: 0.135532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754:  70%|#######   | 7/10 [00:00<00:00, 17.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754:  80%|########  | 8/10 [00:00<00:00, 17.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,587]\u001b[0m Trial 34 finished with value: 0.12946376315311306 and parameters: {'bagging_fraction': 0.9356520254663123, 'bagging_freq': 1}. Best is trial 33 with value: 0.09675416222275754.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754:  80%|########  | 8/10 [00:00<00:00, 17.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754:  80%|########  | 8/10 [00:00<00:00, 17.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,632]\u001b[0m Trial 35 finished with value: 0.13216336538228354 and parameters: {'bagging_fraction': 0.8651580238289466, 'bagging_freq': 4}. Best is trial 33 with value: 0.09675416222275754.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754:  90%|######### | 9/10 [00:00<00:00, 17.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754:  90%|######### | 9/10 [00:00<00:00, 17.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.096754: 100%|##########| 10/10 [00:00<00:00, 18.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,688]\u001b[0m Trial 36 finished with value: 0.12090419861906973 and parameters: {'bagging_fraction': 0.8382686328347552, 'bagging_freq': 3}. Best is trial 33 with value: 0.09675416222275754.\u001b[0m\n",
      "bagging, val_score: 0.096754: 100%|##########| 10/10 [00:00<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\tTrain's multi_logloss: 0.0493662\tTest's multi_logloss: 0.134755\n",
      "[41]\tTrain's multi_logloss: 0.0479244\tTest's multi_logloss: 0.134771\n",
      "[42]\tTrain's multi_logloss: 0.0457913\tTest's multi_logloss: 0.132151\n",
      "[43]\tTrain's multi_logloss: 0.0443701\tTest's multi_logloss: 0.129538\n",
      "[44]\tTrain's multi_logloss: 0.0429293\tTest's multi_logloss: 0.129641\n",
      "[45]\tTrain's multi_logloss: 0.0412328\tTest's multi_logloss: 0.130026\n",
      "[46]\tTrain's multi_logloss: 0.0400501\tTest's multi_logloss: 0.130254\n",
      "[47]\tTrain's multi_logloss: 0.0383691\tTest's multi_logloss: 0.129464\n",
      "[48]\tTrain's multi_logloss: 0.0370071\tTest's multi_logloss: 0.130503\n",
      "[49]\tTrain's multi_logloss: 0.0352938\tTest's multi_logloss: 0.132098\n",
      "[50]\tTrain's multi_logloss: 0.0344215\tTest's multi_logloss: 0.132203\n",
      "[51]\tTrain's multi_logloss: 0.0327552\tTest's multi_logloss: 0.136444\n",
      "[52]\tTrain's multi_logloss: 0.0316424\tTest's multi_logloss: 0.13931\n",
      "[53]\tTrain's multi_logloss: 0.0303736\tTest's multi_logloss: 0.138647\n",
      "[54]\tTrain's multi_logloss: 0.0297428\tTest's multi_logloss: 0.137633\n",
      "[55]\tTrain's multi_logloss: 0.0288831\tTest's multi_logloss: 0.136473\n",
      "[56]\tTrain's multi_logloss: 0.0280678\tTest's multi_logloss: 0.13742\n",
      "[57]\tTrain's multi_logloss: 0.0271124\tTest's multi_logloss: 0.136648\n",
      "Early stopping, best iteration is:\n",
      "[47]\tTrain's multi_logloss: 0.0383691\tTest's multi_logloss: 0.129464\n",
      "[1]\tTrain's multi_logloss: 0.928484\tTest's multi_logloss: 0.950691\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.796134\tTest's multi_logloss: 0.818636\n",
      "[3]\tTrain's multi_logloss: 0.689828\tTest's multi_logloss: 0.712772\n",
      "[4]\tTrain's multi_logloss: 0.604109\tTest's multi_logloss: 0.620728\n",
      "[5]\tTrain's multi_logloss: 0.532158\tTest's multi_logloss: 0.542045\n",
      "[6]\tTrain's multi_logloss: 0.469623\tTest's multi_logloss: 0.486538\n",
      "[7]\tTrain's multi_logloss: 0.416813\tTest's multi_logloss: 0.432583\n",
      "[8]\tTrain's multi_logloss: 0.373772\tTest's multi_logloss: 0.384995\n",
      "[9]\tTrain's multi_logloss: 0.334574\tTest's multi_logloss: 0.340392\n",
      "[10]\tTrain's multi_logloss: 0.301858\tTest's multi_logloss: 0.302377\n",
      "[11]\tTrain's multi_logloss: 0.272006\tTest's multi_logloss: 0.277149\n",
      "[12]\tTrain's multi_logloss: 0.249231\tTest's multi_logloss: 0.251404\n",
      "[13]\tTrain's multi_logloss: 0.227651\tTest's multi_logloss: 0.232021\n",
      "[14]\tTrain's multi_logloss: 0.209064\tTest's multi_logloss: 0.215612\n",
      "[15]\tTrain's multi_logloss: 0.191037\tTest's multi_logloss: 0.202447\n",
      "[16]\tTrain's multi_logloss: 0.175496\tTest's multi_logloss: 0.191619\n",
      "[17]\tTrain's multi_logloss: 0.163578\tTest's multi_logloss: 0.182982\n",
      "[18]\tTrain's multi_logloss: 0.153897\tTest's multi_logloss: 0.172646\n",
      "[19]\tTrain's multi_logloss: 0.144903\tTest's multi_logloss: 0.166434\n",
      "[20]\tTrain's multi_logloss: 0.137481\tTest's multi_logloss: 0.160984\n",
      "[21]\tTrain's multi_logloss: 0.128534\tTest's multi_logloss: 0.155947\n",
      "[22]\tTrain's multi_logloss: 0.120838\tTest's multi_logloss: 0.150954\n",
      "[23]\tTrain's multi_logloss: 0.115159\tTest's multi_logloss: 0.147859\n",
      "[24]\tTrain's multi_logloss: 0.110153\tTest's multi_logloss: 0.141978\n",
      "[25]\tTrain's multi_logloss: 0.106109\tTest's multi_logloss: 0.139539\n",
      "[26]\tTrain's multi_logloss: 0.102333\tTest's multi_logloss: 0.137002\n",
      "[27]\tTrain's multi_logloss: 0.0988126\tTest's multi_logloss: 0.13487\n",
      "[28]\tTrain's multi_logloss: 0.0933811\tTest's multi_logloss: 0.135789\n",
      "[29]\tTrain's multi_logloss: 0.0884732\tTest's multi_logloss: 0.133647\n",
      "[30]\tTrain's multi_logloss: 0.0852121\tTest's multi_logloss: 0.132163\n",
      "[31]\tTrain's multi_logloss: 0.081071\tTest's multi_logloss: 0.133772\n",
      "[32]\tTrain's multi_logloss: 0.0771472\tTest's multi_logloss: 0.133052\n",
      "[33]\tTrain's multi_logloss: 0.0735366\tTest's multi_logloss: 0.134131\n",
      "[34]\tTrain's multi_logloss: 0.0698233\tTest's multi_logloss: 0.13416\n",
      "[35]\tTrain's multi_logloss: 0.0674405\tTest's multi_logloss: 0.133954\n",
      "[36]\tTrain's multi_logloss: 0.0655264\tTest's multi_logloss: 0.132485\n",
      "[37]\tTrain's multi_logloss: 0.0623562\tTest's multi_logloss: 0.133195\n",
      "[38]\tTrain's multi_logloss: 0.0572878\tTest's multi_logloss: 0.142558\n",
      "[39]\tTrain's multi_logloss: 0.0536682\tTest's multi_logloss: 0.149299\n",
      "[40]\tTrain's multi_logloss: 0.0503889\tTest's multi_logloss: 0.151239\n",
      "Early stopping, best iteration is:\n",
      "[30]\tTrain's multi_logloss: 0.0852121\tTest's multi_logloss: 0.132163\n",
      "[1]\tTrain's multi_logloss: 0.929814\tTest's multi_logloss: 0.957605\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.796924\tTest's multi_logloss: 0.81755\n",
      "[3]\tTrain's multi_logloss: 0.691532\tTest's multi_logloss: 0.706488\n",
      "[4]\tTrain's multi_logloss: 0.603361\tTest's multi_logloss: 0.617221\n",
      "[5]\tTrain's multi_logloss: 0.530359\tTest's multi_logloss: 0.543448\n",
      "[6]\tTrain's multi_logloss: 0.466751\tTest's multi_logloss: 0.486043\n",
      "[7]\tTrain's multi_logloss: 0.412893\tTest's multi_logloss: 0.431838\n",
      "[8]\tTrain's multi_logloss: 0.369732\tTest's multi_logloss: 0.384759\n",
      "[9]\tTrain's multi_logloss: 0.330622\tTest's multi_logloss: 0.339696\n",
      "[10]\tTrain's multi_logloss: 0.296042\tTest's multi_logloss: 0.308784\n",
      "[11]\tTrain's multi_logloss: 0.267237\tTest's multi_logloss: 0.280193\n",
      "[12]\tTrain's multi_logloss: 0.243476\tTest's multi_logloss: 0.255669\n",
      "[13]\tTrain's multi_logloss: 0.223273\tTest's multi_logloss: 0.237774\n",
      "[14]\tTrain's multi_logloss: 0.206474\tTest's multi_logloss: 0.221571\n",
      "[15]\tTrain's multi_logloss: 0.18982\tTest's multi_logloss: 0.209369\n",
      "[16]\tTrain's multi_logloss: 0.173936\tTest's multi_logloss: 0.19873\n",
      "[17]\tTrain's multi_logloss: 0.16181\tTest's multi_logloss: 0.19075\n",
      "[18]\tTrain's multi_logloss: 0.151366\tTest's multi_logloss: 0.179222\n",
      "[19]\tTrain's multi_logloss: 0.141381\tTest's multi_logloss: 0.173675\n",
      "[20]\tTrain's multi_logloss: 0.134188\tTest's multi_logloss: 0.167639\n",
      "[21]\tTrain's multi_logloss: 0.12593\tTest's multi_logloss: 0.163675\n",
      "[22]\tTrain's multi_logloss: 0.120112\tTest's multi_logloss: 0.156291\n",
      "[23]\tTrain's multi_logloss: 0.115091\tTest's multi_logloss: 0.148156\n",
      "[24]\tTrain's multi_logloss: 0.108878\tTest's multi_logloss: 0.147425\n",
      "[25]\tTrain's multi_logloss: 0.104174\tTest's multi_logloss: 0.143622\n",
      "[26]\tTrain's multi_logloss: 0.10025\tTest's multi_logloss: 0.140927\n",
      "[27]\tTrain's multi_logloss: 0.0967717\tTest's multi_logloss: 0.138544\n",
      "[28]\tTrain's multi_logloss: 0.0894274\tTest's multi_logloss: 0.140476\n",
      "[29]\tTrain's multi_logloss: 0.0821256\tTest's multi_logloss: 0.141957\n",
      "[30]\tTrain's multi_logloss: 0.0788345\tTest's multi_logloss: 0.139013\n",
      "[31]\tTrain's multi_logloss: 0.0754983\tTest's multi_logloss: 0.136371\n",
      "[32]\tTrain's multi_logloss: 0.0729639\tTest's multi_logloss: 0.130698\n",
      "[33]\tTrain's multi_logloss: 0.070058\tTest's multi_logloss: 0.129286\n",
      "[34]\tTrain's multi_logloss: 0.0666045\tTest's multi_logloss: 0.129161\n",
      "[35]\tTrain's multi_logloss: 0.0645672\tTest's multi_logloss: 0.126994\n",
      "[36]\tTrain's multi_logloss: 0.0627496\tTest's multi_logloss: 0.125132\n",
      "[37]\tTrain's multi_logloss: 0.0612967\tTest's multi_logloss: 0.124909\n",
      "[38]\tTrain's multi_logloss: 0.058815\tTest's multi_logloss: 0.125894\n",
      "[39]\tTrain's multi_logloss: 0.0565876\tTest's multi_logloss: 0.127106\n",
      "[40]\tTrain's multi_logloss: 0.0537107\tTest's multi_logloss: 0.125363\n",
      "[41]\tTrain's multi_logloss: 0.0520811\tTest's multi_logloss: 0.121893\n",
      "[42]\tTrain's multi_logloss: 0.0498059\tTest's multi_logloss: 0.120904\n",
      "[43]\tTrain's multi_logloss: 0.0462018\tTest's multi_logloss: 0.123552\n",
      "[44]\tTrain's multi_logloss: 0.045091\tTest's multi_logloss: 0.125881\n",
      "[45]\tTrain's multi_logloss: 0.0435175\tTest's multi_logloss: 0.129217\n",
      "[46]\tTrain's multi_logloss: 0.04244\tTest's multi_logloss: 0.130013\n",
      "[47]\tTrain's multi_logloss: 0.0414504\tTest's multi_logloss: 0.130572\n",
      "[48]\tTrain's multi_logloss: 0.0405152\tTest's multi_logloss: 0.131119\n",
      "[49]\tTrain's multi_logloss: 0.0391605\tTest's multi_logloss: 0.133319\n",
      "[50]\tTrain's multi_logloss: 0.0387142\tTest's multi_logloss: 0.135881\n",
      "[51]\tTrain's multi_logloss: 0.0380521\tTest's multi_logloss: 0.136546\n",
      "[52]\tTrain's multi_logloss: 0.0372064\tTest's multi_logloss: 0.136579\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's multi_logloss: 0.0498059\tTest's multi_logloss: 0.120904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.983222\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88597\tTest's multi_logloss: 0.923548\n",
      "[3]\tTrain's multi_logloss: 0.806014\tTest's multi_logloss: 0.840006\n",
      "[4]\tTrain's multi_logloss: 0.738065\tTest's multi_logloss: 0.767251\n",
      "[5]\tTrain's multi_logloss: 0.673282\tTest's multi_logloss: 0.698602\n",
      "[6]\tTrain's multi_logloss: 0.617878\tTest's multi_logloss: 0.643634\n",
      "[7]\tTrain's multi_logloss: 0.57934\tTest's multi_logloss: 0.602583\n",
      "[8]\tTrain's multi_logloss: 0.541765\tTest's multi_logloss: 0.560331\n",
      "[9]\tTrain's multi_logloss: 0.50884\tTest's multi_logloss: 0.523347\n",
      "[10]\tTrain's multi_logloss: 0.479527\tTest's multi_logloss: 0.490092\n",
      "[11]\tTrain's multi_logloss: 0.451586\tTest's multi_logloss: 0.457504\n",
      "[12]\tTrain's multi_logloss: 0.419615\tTest's multi_logloss: 0.426636\n",
      "[13]\tTrain's multi_logloss: 0.386908\tTest's multi_logloss: 0.3914\n",
      "[14]\tTrain's multi_logloss: 0.359833\tTest's multi_logloss: 0.360838\n",
      "[15]\tTrain's multi_logloss: 0.335844\tTest's multi_logloss: 0.337177\n",
      "[16]\tTrain's multi_logloss: 0.314675\tTest's multi_logloss: 0.31581\n",
      "[17]\tTrain's multi_logloss: 0.29616\tTest's multi_logloss: 0.298323\n",
      "[18]\tTrain's multi_logloss: 0.279269\tTest's multi_logloss: 0.277604\n",
      "[19]\tTrain's multi_logloss: 0.276059\tTest's multi_logloss: 0.274574\n",
      "[20]\tTrain's multi_logloss: 0.271726\tTest's multi_logloss: 0.272045\n",
      "[21]\tTrain's multi_logloss: 0.269129\tTest's multi_logloss: 0.269575\n",
      "[22]\tTrain's multi_logloss: 0.262998\tTest's multi_logloss: 0.263206\n",
      "[23]\tTrain's multi_logloss: 0.259571\tTest's multi_logloss: 0.261599\n",
      "[24]\tTrain's multi_logloss: 0.258693\tTest's multi_logloss: 0.262103\n",
      "[25]\tTrain's multi_logloss: 0.247252\tTest's multi_logloss: 0.245584\n",
      "[26]\tTrain's multi_logloss: 0.236045\tTest's multi_logloss: 0.230916\n",
      "[27]\tTrain's multi_logloss: 0.226512\tTest's multi_logloss: 0.216599\n",
      "[28]\tTrain's multi_logloss: 0.216354\tTest's multi_logloss: 0.205554\n",
      "[29]\tTrain's multi_logloss: 0.206152\tTest's multi_logloss: 0.195255\n",
      "[30]\tTrain's multi_logloss: 0.199206\tTest's multi_logloss: 0.184972\n",
      "[31]\tTrain's multi_logloss: 0.195468\tTest's multi_logloss: 0.182073\n",
      "[32]\tTrain's multi_logloss: 0.191326\tTest's multi_logloss: 0.178801\n",
      "[33]\tTrain's multi_logloss: 0.182914\tTest's multi_logloss: 0.173068\n",
      "[34]\tTrain's multi_logloss: 0.17542\tTest's multi_logloss: 0.167818\n",
      "[35]\tTrain's multi_logloss: 0.168744\tTest's multi_logloss: 0.163168\n",
      "[36]\tTrain's multi_logloss: 0.164981\tTest's multi_logloss: 0.161201\n",
      "[37]\tTrain's multi_logloss: 0.159243\tTest's multi_logloss: 0.152001\n",
      "[38]\tTrain's multi_logloss: 0.155178\tTest's multi_logloss: 0.147804\n",
      "[39]\tTrain's multi_logloss: 0.151789\tTest's multi_logloss: 0.14432\n",
      "[40]\tTrain's multi_logloss: 0.149042\tTest's multi_logloss: 0.14164\n",
      "[41]\tTrain's multi_logloss: 0.145128\tTest's multi_logloss: 0.135229\n",
      "[42]\tTrain's multi_logloss: 0.141753\tTest's multi_logloss: 0.129721\n",
      "[43]\tTrain's multi_logloss: 0.14036\tTest's multi_logloss: 0.127913\n",
      "[44]\tTrain's multi_logloss: 0.139153\tTest's multi_logloss: 0.126336\n",
      "[45]\tTrain's multi_logloss: 0.138039\tTest's multi_logloss: 0.124835\n",
      "[46]\tTrain's multi_logloss: 0.137074\tTest's multi_logloss: 0.123565\n",
      "[47]\tTrain's multi_logloss: 0.136801\tTest's multi_logloss: 0.122718\n",
      "[48]\tTrain's multi_logloss: 0.135769\tTest's multi_logloss: 0.121612\n",
      "[49]\tTrain's multi_logloss: 0.13365\tTest's multi_logloss: 0.120226\n",
      "[50]\tTrain's multi_logloss: 0.131747\tTest's multi_logloss: 0.119013\n",
      "[51]\tTrain's multi_logloss: 0.129082\tTest's multi_logloss: 0.117172\n",
      "[52]\tTrain's multi_logloss: 0.127766\tTest's multi_logloss: 0.116754\n",
      "[53]\tTrain's multi_logloss: 0.127466\tTest's multi_logloss: 0.11798\n",
      "[54]\tTrain's multi_logloss: 0.126004\tTest's multi_logloss: 0.117093\n",
      "[55]\tTrain's multi_logloss: 0.1231\tTest's multi_logloss: 0.116191\n",
      "[56]\tTrain's multi_logloss: 0.121516\tTest's multi_logloss: 0.116173\n",
      "[57]\tTrain's multi_logloss: 0.120061\tTest's multi_logloss: 0.11627\n",
      "[58]\tTrain's multi_logloss: 0.120197\tTest's multi_logloss: 0.116856\n",
      "[59]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[60]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[61]\tTrain's multi_logloss: 0.118679\tTest's multi_logloss: 0.117309\n",
      "[62]\tTrain's multi_logloss: 0.116474\tTest's multi_logloss: 0.113988\n",
      "[63]\tTrain's multi_logloss: 0.11442\tTest's multi_logloss: 0.111441\n",
      "[64]\tTrain's multi_logloss: 0.112302\tTest's multi_logloss: 0.106502\n",
      "[65]\tTrain's multi_logloss: 0.110531\tTest's multi_logloss: 0.102165\n",
      "[66]\tTrain's multi_logloss: 0.108849\tTest's multi_logloss: 0.100404\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[68]\tTrain's multi_logloss: 0.106835\tTest's multi_logloss: 0.0980864\n",
      "[69]\tTrain's multi_logloss: 0.106358\tTest's multi_logloss: 0.0995676\n",
      "[70]\tTrain's multi_logloss: 0.106068\tTest's multi_logloss: 0.100975\n",
      "[71]\tTrain's multi_logloss: 0.104974\tTest's multi_logloss: 0.10047\n",
      "[72]\tTrain's multi_logloss: 0.104922\tTest's multi_logloss: 0.10199\n",
      "[73]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[74]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[75]\tTrain's multi_logloss: 0.102982\tTest's multi_logloss: 0.100988\n",
      "[76]\tTrain's multi_logloss: 0.101918\tTest's multi_logloss: 0.100274\n",
      "[77]\tTrain's multi_logloss: 0.102118\tTest's multi_logloss: 0.0978103\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,744]\u001b[0m Trial 37 finished with value: 0.09675416222275754 and parameters: {'feature_fraction': 0.748}. Best is trial 37 with value: 0.09675416222275754.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  17%|#6        | 1/6 [00:00<00:00, 18.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.983222\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88597\tTest's multi_logloss: 0.923548\n",
      "[3]\tTrain's multi_logloss: 0.806014\tTest's multi_logloss: 0.840006\n",
      "[4]\tTrain's multi_logloss: 0.738065\tTest's multi_logloss: 0.767251\n",
      "[5]\tTrain's multi_logloss: 0.673282\tTest's multi_logloss: 0.698602\n",
      "[6]\tTrain's multi_logloss: 0.617878\tTest's multi_logloss: 0.643634\n",
      "[7]\tTrain's multi_logloss: 0.57934\tTest's multi_logloss: 0.602583\n",
      "[8]\tTrain's multi_logloss: 0.541765\tTest's multi_logloss: 0.560331\n",
      "[9]\tTrain's multi_logloss: 0.50884\tTest's multi_logloss: 0.523347\n",
      "[10]\tTrain's multi_logloss: 0.479527\tTest's multi_logloss: 0.490092\n",
      "[11]\tTrain's multi_logloss: 0.451586\tTest's multi_logloss: 0.457504\n",
      "[12]\tTrain's multi_logloss: 0.419615\tTest's multi_logloss: 0.426636\n",
      "[13]\tTrain's multi_logloss: 0.386908\tTest's multi_logloss: 0.3914\n",
      "[14]\tTrain's multi_logloss: 0.359833\tTest's multi_logloss: 0.360838\n",
      "[15]\tTrain's multi_logloss: 0.335844\tTest's multi_logloss: 0.337177\n",
      "[16]\tTrain's multi_logloss: 0.314675\tTest's multi_logloss: 0.31581\n",
      "[17]\tTrain's multi_logloss: 0.29616\tTest's multi_logloss: 0.298323\n",
      "[18]\tTrain's multi_logloss: 0.279269\tTest's multi_logloss: 0.277604\n",
      "[19]\tTrain's multi_logloss: 0.276059\tTest's multi_logloss: 0.274574\n",
      "[20]\tTrain's multi_logloss: 0.271726\tTest's multi_logloss: 0.272045\n",
      "[21]\tTrain's multi_logloss: 0.269129\tTest's multi_logloss: 0.269575\n",
      "[22]\tTrain's multi_logloss: 0.262998\tTest's multi_logloss: 0.263206\n",
      "[23]\tTrain's multi_logloss: 0.259571\tTest's multi_logloss: 0.261599\n",
      "[24]\tTrain's multi_logloss: 0.258693\tTest's multi_logloss: 0.262103\n",
      "[25]\tTrain's multi_logloss: 0.247252\tTest's multi_logloss: 0.245584\n",
      "[26]\tTrain's multi_logloss: 0.236045\tTest's multi_logloss: 0.230916\n",
      "[27]\tTrain's multi_logloss: 0.226512\tTest's multi_logloss: 0.216599\n",
      "[28]\tTrain's multi_logloss: 0.216354\tTest's multi_logloss: 0.205554\n",
      "[29]\tTrain's multi_logloss: 0.206152\tTest's multi_logloss: 0.195255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  17%|#6        | 1/6 [00:00<00:00,  9.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  33%|###3      | 2/6 [00:00<00:00, 18.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,797]\u001b[0m Trial 38 finished with value: 0.09675416222275754 and parameters: {'feature_fraction': 0.716}. Best is trial 37 with value: 0.09675416222275754.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  33%|###3      | 2/6 [00:00<00:00, 18.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  33%|###3      | 2/6 [00:00<00:00, 18.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,851]\u001b[0m Trial 39 finished with value: 0.09675416222275754 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 37 with value: 0.09675416222275754.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  50%|#####     | 3/6 [00:00<00:00, 18.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tTrain's multi_logloss: 0.199206\tTest's multi_logloss: 0.184972\n",
      "[31]\tTrain's multi_logloss: 0.195468\tTest's multi_logloss: 0.182073\n",
      "[32]\tTrain's multi_logloss: 0.191326\tTest's multi_logloss: 0.178801\n",
      "[33]\tTrain's multi_logloss: 0.182914\tTest's multi_logloss: 0.173068\n",
      "[34]\tTrain's multi_logloss: 0.17542\tTest's multi_logloss: 0.167818\n",
      "[35]\tTrain's multi_logloss: 0.168744\tTest's multi_logloss: 0.163168\n",
      "[36]\tTrain's multi_logloss: 0.164981\tTest's multi_logloss: 0.161201\n",
      "[37]\tTrain's multi_logloss: 0.159243\tTest's multi_logloss: 0.152001\n",
      "[38]\tTrain's multi_logloss: 0.155178\tTest's multi_logloss: 0.147804\n",
      "[39]\tTrain's multi_logloss: 0.151789\tTest's multi_logloss: 0.14432\n",
      "[40]\tTrain's multi_logloss: 0.149042\tTest's multi_logloss: 0.14164\n",
      "[41]\tTrain's multi_logloss: 0.145128\tTest's multi_logloss: 0.135229\n",
      "[42]\tTrain's multi_logloss: 0.141753\tTest's multi_logloss: 0.129721\n",
      "[43]\tTrain's multi_logloss: 0.14036\tTest's multi_logloss: 0.127913\n",
      "[44]\tTrain's multi_logloss: 0.139153\tTest's multi_logloss: 0.126336\n",
      "[45]\tTrain's multi_logloss: 0.138039\tTest's multi_logloss: 0.124835\n",
      "[46]\tTrain's multi_logloss: 0.137074\tTest's multi_logloss: 0.123565\n",
      "[47]\tTrain's multi_logloss: 0.136801\tTest's multi_logloss: 0.122718\n",
      "[48]\tTrain's multi_logloss: 0.135769\tTest's multi_logloss: 0.121612\n",
      "[49]\tTrain's multi_logloss: 0.13365\tTest's multi_logloss: 0.120226\n",
      "[50]\tTrain's multi_logloss: 0.131747\tTest's multi_logloss: 0.119013\n",
      "[51]\tTrain's multi_logloss: 0.129082\tTest's multi_logloss: 0.117172\n",
      "[52]\tTrain's multi_logloss: 0.127766\tTest's multi_logloss: 0.116754\n",
      "[53]\tTrain's multi_logloss: 0.127466\tTest's multi_logloss: 0.11798\n",
      "[54]\tTrain's multi_logloss: 0.126004\tTest's multi_logloss: 0.117093\n",
      "[55]\tTrain's multi_logloss: 0.1231\tTest's multi_logloss: 0.116191\n",
      "[56]\tTrain's multi_logloss: 0.121516\tTest's multi_logloss: 0.116173\n",
      "[57]\tTrain's multi_logloss: 0.120061\tTest's multi_logloss: 0.11627\n",
      "[58]\tTrain's multi_logloss: 0.120197\tTest's multi_logloss: 0.116856\n",
      "[59]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[60]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[61]\tTrain's multi_logloss: 0.118679\tTest's multi_logloss: 0.117309\n",
      "[62]\tTrain's multi_logloss: 0.116474\tTest's multi_logloss: 0.113988\n",
      "[63]\tTrain's multi_logloss: 0.11442\tTest's multi_logloss: 0.111441\n",
      "[64]\tTrain's multi_logloss: 0.112302\tTest's multi_logloss: 0.106502\n",
      "[65]\tTrain's multi_logloss: 0.110531\tTest's multi_logloss: 0.102165\n",
      "[66]\tTrain's multi_logloss: 0.108849\tTest's multi_logloss: 0.100404\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[68]\tTrain's multi_logloss: 0.106835\tTest's multi_logloss: 0.0980864\n",
      "[69]\tTrain's multi_logloss: 0.106358\tTest's multi_logloss: 0.0995676\n",
      "[70]\tTrain's multi_logloss: 0.106068\tTest's multi_logloss: 0.100975\n",
      "[71]\tTrain's multi_logloss: 0.104974\tTest's multi_logloss: 0.10047\n",
      "[72]\tTrain's multi_logloss: 0.104922\tTest's multi_logloss: 0.10199\n",
      "[73]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[74]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[75]\tTrain's multi_logloss: 0.102982\tTest's multi_logloss: 0.100988\n",
      "[76]\tTrain's multi_logloss: 0.101918\tTest's multi_logloss: 0.100274\n",
      "[77]\tTrain's multi_logloss: 0.102118\tTest's multi_logloss: 0.0978103\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[1]\tTrain's multi_logloss: 0.983222\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88597\tTest's multi_logloss: 0.923548\n",
      "[3]\tTrain's multi_logloss: 0.806014\tTest's multi_logloss: 0.840006\n",
      "[4]\tTrain's multi_logloss: 0.738065\tTest's multi_logloss: 0.767251\n",
      "[5]\tTrain's multi_logloss: 0.673282\tTest's multi_logloss: 0.698602\n",
      "[6]\tTrain's multi_logloss: 0.617878\tTest's multi_logloss: 0.643634\n",
      "[7]\tTrain's multi_logloss: 0.57934\tTest's multi_logloss: 0.602583\n",
      "[8]\tTrain's multi_logloss: 0.541765\tTest's multi_logloss: 0.560331\n",
      "[9]\tTrain's multi_logloss: 0.50884\tTest's multi_logloss: 0.523347\n",
      "[10]\tTrain's multi_logloss: 0.479527\tTest's multi_logloss: 0.490092\n",
      "[11]\tTrain's multi_logloss: 0.451586\tTest's multi_logloss: 0.457504\n",
      "[12]\tTrain's multi_logloss: 0.419615\tTest's multi_logloss: 0.426636\n",
      "[13]\tTrain's multi_logloss: 0.386908\tTest's multi_logloss: 0.3914\n",
      "[14]\tTrain's multi_logloss: 0.359833\tTest's multi_logloss: 0.360838\n",
      "[15]\tTrain's multi_logloss: 0.335844\tTest's multi_logloss: 0.337177\n",
      "[16]\tTrain's multi_logloss: 0.314675\tTest's multi_logloss: 0.31581\n",
      "[17]\tTrain's multi_logloss: 0.29616\tTest's multi_logloss: 0.298323\n",
      "[18]\tTrain's multi_logloss: 0.279269\tTest's multi_logloss: 0.277604\n",
      "[19]\tTrain's multi_logloss: 0.276059\tTest's multi_logloss: 0.274574\n",
      "[20]\tTrain's multi_logloss: 0.271726\tTest's multi_logloss: 0.272045\n",
      "[21]\tTrain's multi_logloss: 0.269129\tTest's multi_logloss: 0.269575\n",
      "[22]\tTrain's multi_logloss: 0.262998\tTest's multi_logloss: 0.263206\n",
      "[23]\tTrain's multi_logloss: 0.259571\tTest's multi_logloss: 0.261599\n",
      "[24]\tTrain's multi_logloss: 0.258693\tTest's multi_logloss: 0.262103\n",
      "[25]\tTrain's multi_logloss: 0.247252\tTest's multi_logloss: 0.245584\n",
      "[26]\tTrain's multi_logloss: 0.236045\tTest's multi_logloss: 0.230916\n",
      "[27]\tTrain's multi_logloss: 0.226512\tTest's multi_logloss: 0.216599\n",
      "[28]\tTrain's multi_logloss: 0.216354\tTest's multi_logloss: 0.205554\n",
      "[29]\tTrain's multi_logloss: 0.206152\tTest's multi_logloss: 0.195255\n",
      "[30]\tTrain's multi_logloss: 0.199206\tTest's multi_logloss: 0.184972\n",
      "[31]\tTrain's multi_logloss: 0.195468\tTest's multi_logloss: 0.182073\n",
      "[32]\tTrain's multi_logloss: 0.191326\tTest's multi_logloss: 0.178801\n",
      "[33]\tTrain's multi_logloss: 0.182914\tTest's multi_logloss: 0.173068\n",
      "[34]\tTrain's multi_logloss: 0.17542\tTest's multi_logloss: 0.167818\n",
      "[35]\tTrain's multi_logloss: 0.168744\tTest's multi_logloss: 0.163168\n",
      "[36]\tTrain's multi_logloss: 0.164981\tTest's multi_logloss: 0.161201\n",
      "[37]\tTrain's multi_logloss: 0.159243\tTest's multi_logloss: 0.152001\n",
      "[38]\tTrain's multi_logloss: 0.155178\tTest's multi_logloss: 0.147804\n",
      "[39]\tTrain's multi_logloss: 0.151789\tTest's multi_logloss: 0.14432\n",
      "[40]\tTrain's multi_logloss: 0.149042\tTest's multi_logloss: 0.14164\n",
      "[41]\tTrain's multi_logloss: 0.145128\tTest's multi_logloss: 0.135229\n",
      "[42]\tTrain's multi_logloss: 0.141753\tTest's multi_logloss: 0.129721\n",
      "[43]\tTrain's multi_logloss: 0.14036\tTest's multi_logloss: 0.127913\n",
      "[44]\tTrain's multi_logloss: 0.139153\tTest's multi_logloss: 0.126336\n",
      "[45]\tTrain's multi_logloss: 0.138039\tTest's multi_logloss: 0.124835\n",
      "[46]\tTrain's multi_logloss: 0.137074\tTest's multi_logloss: 0.123565\n",
      "[47]\tTrain's multi_logloss: 0.136801\tTest's multi_logloss: 0.122718\n",
      "[48]\tTrain's multi_logloss: 0.135769\tTest's multi_logloss: 0.121612\n",
      "[49]\tTrain's multi_logloss: 0.13365\tTest's multi_logloss: 0.120226\n",
      "[50]\tTrain's multi_logloss: 0.131747\tTest's multi_logloss: 0.119013\n",
      "[51]\tTrain's multi_logloss: 0.129082\tTest's multi_logloss: 0.117172\n",
      "[52]\tTrain's multi_logloss: 0.127766\tTest's multi_logloss: 0.116754\n",
      "[53]\tTrain's multi_logloss: 0.127466\tTest's multi_logloss: 0.11798\n",
      "[54]\tTrain's multi_logloss: 0.126004\tTest's multi_logloss: 0.117093\n",
      "[55]\tTrain's multi_logloss: 0.1231\tTest's multi_logloss: 0.116191\n",
      "[56]\tTrain's multi_logloss: 0.121516\tTest's multi_logloss: 0.116173\n",
      "[57]\tTrain's multi_logloss: 0.120061\tTest's multi_logloss: 0.11627\n",
      "[58]\tTrain's multi_logloss: 0.120197\tTest's multi_logloss: 0.116856\n",
      "[59]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[60]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[61]\tTrain's multi_logloss: 0.118679\tTest's multi_logloss: 0.117309\n",
      "[62]\tTrain's multi_logloss: 0.116474\tTest's multi_logloss: 0.113988\n",
      "[63]\tTrain's multi_logloss: 0.11442\tTest's multi_logloss: 0.111441\n",
      "[64]\tTrain's multi_logloss: 0.112302\tTest's multi_logloss: 0.106502\n",
      "[65]\tTrain's multi_logloss: 0.110531\tTest's multi_logloss: 0.102165\n",
      "[66]\tTrain's multi_logloss: 0.108849\tTest's multi_logloss: 0.100404\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[68]\tTrain's multi_logloss: 0.106835\tTest's multi_logloss: 0.0980864\n",
      "[69]\tTrain's multi_logloss: 0.106358\tTest's multi_logloss: 0.0995676\n",
      "[70]\tTrain's multi_logloss: 0.106068\tTest's multi_logloss: 0.100975\n",
      "[71]\tTrain's multi_logloss: 0.104974\tTest's multi_logloss: 0.10047\n",
      "[72]\tTrain's multi_logloss: 0.104922\tTest's multi_logloss: 0.10199\n",
      "[73]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[74]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[75]\tTrain's multi_logloss: 0.102982\tTest's multi_logloss: 0.100988\n",
      "[76]\tTrain's multi_logloss: 0.101918\tTest's multi_logloss: 0.100274\n",
      "[77]\tTrain's multi_logloss: 0.102118\tTest's multi_logloss: 0.0978103\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[1]\tTrain's multi_logloss: 0.983222\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88597\tTest's multi_logloss: 0.923548\n",
      "[3]\tTrain's multi_logloss: 0.806014\tTest's multi_logloss: 0.840006\n",
      "[4]\tTrain's multi_logloss: 0.738065\tTest's multi_logloss: 0.767251\n",
      "[5]\tTrain's multi_logloss: 0.673282\tTest's multi_logloss: 0.698602\n",
      "[6]\tTrain's multi_logloss: 0.617878\tTest's multi_logloss: 0.643634\n",
      "[7]\tTrain's multi_logloss: 0.57934\tTest's multi_logloss: 0.602583\n",
      "[8]\tTrain's multi_logloss: 0.541765\tTest's multi_logloss: 0.560331\n",
      "[9]\tTrain's multi_logloss: 0.50884\tTest's multi_logloss: 0.523347\n",
      "[10]\tTrain's multi_logloss: 0.479527\tTest's multi_logloss: 0.490092\n",
      "[11]\tTrain's multi_logloss: 0.451586\tTest's multi_logloss: 0.457504\n",
      "[12]\tTrain's multi_logloss: 0.419615\tTest's multi_logloss: 0.426636\n",
      "[13]\tTrain's multi_logloss: 0.386908\tTest's multi_logloss: 0.3914\n",
      "[14]\tTrain's multi_logloss: 0.359833\tTest's multi_logloss: 0.360838\n",
      "[15]\tTrain's multi_logloss: 0.335844\tTest's multi_logloss: 0.337177\n",
      "[16]\tTrain's multi_logloss: 0.314675\tTest's multi_logloss: 0.31581\n",
      "[17]\tTrain's multi_logloss: 0.29616\tTest's multi_logloss: 0.298323\n",
      "[18]\tTrain's multi_logloss: 0.279269\tTest's multi_logloss: 0.277604\n",
      "[19]\tTrain's multi_logloss: 0.276059\tTest's multi_logloss: 0.274574\n",
      "[20]\tTrain's multi_logloss: 0.271726\tTest's multi_logloss: 0.272045\n",
      "[21]\tTrain's multi_logloss: 0.269129\tTest's multi_logloss: 0.269575\n",
      "[22]\tTrain's multi_logloss: 0.262998\tTest's multi_logloss: 0.263206\n",
      "[23]\tTrain's multi_logloss: 0.259571\tTest's multi_logloss: 0.261599\n",
      "[24]\tTrain's multi_logloss: 0.258693\tTest's multi_logloss: 0.262103\n",
      "[25]\tTrain's multi_logloss: 0.247252\tTest's multi_logloss: 0.245584\n",
      "[26]\tTrain's multi_logloss: 0.236045\tTest's multi_logloss: 0.230916\n",
      "[27]\tTrain's multi_logloss: 0.226512\tTest's multi_logloss: 0.216599\n",
      "[28]\tTrain's multi_logloss: 0.216354\tTest's multi_logloss: 0.205554\n",
      "[29]\tTrain's multi_logloss: 0.206152\tTest's multi_logloss: 0.195255\n",
      "[30]\tTrain's multi_logloss: 0.199206\tTest's multi_logloss: 0.184972\n",
      "[31]\tTrain's multi_logloss: 0.195468\tTest's multi_logloss: 0.182073\n",
      "[32]\tTrain's multi_logloss: 0.191326\tTest's multi_logloss: 0.178801\n",
      "[33]\tTrain's multi_logloss: 0.182914\tTest's multi_logloss: 0.173068\n",
      "[34]\tTrain's multi_logloss: 0.17542\tTest's multi_logloss: 0.167818\n",
      "[35]\tTrain's multi_logloss: 0.168744\tTest's multi_logloss: 0.163168\n",
      "[36]\tTrain's multi_logloss: 0.164981\tTest's multi_logloss: 0.161201\n",
      "[37]\tTrain's multi_logloss: 0.159243\tTest's multi_logloss: 0.152001\n",
      "[38]\tTrain's multi_logloss: 0.155178\tTest's multi_logloss: 0.147804\n",
      "[39]\tTrain's multi_logloss: 0.151789\tTest's multi_logloss: 0.14432\n",
      "[40]\tTrain's multi_logloss: 0.149042\tTest's multi_logloss: 0.14164\n",
      "[41]\tTrain's multi_logloss: 0.145128\tTest's multi_logloss: 0.135229\n",
      "[42]\tTrain's multi_logloss: 0.141753\tTest's multi_logloss: 0.129721\n",
      "[43]\tTrain's multi_logloss: 0.14036\tTest's multi_logloss: 0.127913\n",
      "[44]\tTrain's multi_logloss: 0.139153\tTest's multi_logloss: 0.126336\n",
      "[45]\tTrain's multi_logloss: 0.138039\tTest's multi_logloss: 0.124835\n",
      "[46]\tTrain's multi_logloss: 0.137074\tTest's multi_logloss: 0.123565\n",
      "[47]\tTrain's multi_logloss: 0.136801\tTest's multi_logloss: 0.122718\n",
      "[48]\tTrain's multi_logloss: 0.135769\tTest's multi_logloss: 0.121612\n",
      "[49]\tTrain's multi_logloss: 0.13365\tTest's multi_logloss: 0.120226\n",
      "[50]\tTrain's multi_logloss: 0.131747\tTest's multi_logloss: 0.119013\n",
      "[51]\tTrain's multi_logloss: 0.129082\tTest's multi_logloss: 0.117172\n",
      "[52]\tTrain's multi_logloss: 0.127766\tTest's multi_logloss: 0.116754\n",
      "[53]\tTrain's multi_logloss: 0.127466\tTest's multi_logloss: 0.11798\n",
      "[54]\tTrain's multi_logloss: 0.126004\tTest's multi_logloss: 0.117093\n",
      "[55]\tTrain's multi_logloss: 0.1231\tTest's multi_logloss: 0.116191\n",
      "[56]\tTrain's multi_logloss: 0.121516\tTest's multi_logloss: 0.116173\n",
      "[57]\tTrain's multi_logloss: 0.120061\tTest's multi_logloss: 0.11627\n",
      "[58]\tTrain's multi_logloss: 0.120197\tTest's multi_logloss: 0.116856\n",
      "[59]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[60]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[61]\tTrain's multi_logloss: 0.118679\tTest's multi_logloss: 0.117309\n",
      "[62]\tTrain's multi_logloss: 0.116474\tTest's multi_logloss: 0.113988\n",
      "[63]\tTrain's multi_logloss: 0.11442\tTest's multi_logloss: 0.111441\n",
      "[64]\tTrain's multi_logloss: 0.112302\tTest's multi_logloss: 0.106502\n",
      "[65]\tTrain's multi_logloss: 0.110531\tTest's multi_logloss: 0.102165\n",
      "[66]\tTrain's multi_logloss: 0.108849\tTest's multi_logloss: 0.100404\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[68]\tTrain's multi_logloss: 0.106835\tTest's multi_logloss: 0.0980864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  50%|#####     | 3/6 [00:00<00:00, 18.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  67%|######6   | 4/6 [00:00<00:00, 18.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,905]\u001b[0m Trial 40 finished with value: 0.09675416222275754 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 37 with value: 0.09675416222275754.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  67%|######6   | 4/6 [00:00<00:00, 18.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69]\tTrain's multi_logloss: 0.106358\tTest's multi_logloss: 0.0995676\n",
      "[70]\tTrain's multi_logloss: 0.106068\tTest's multi_logloss: 0.100975\n",
      "[71]\tTrain's multi_logloss: 0.104974\tTest's multi_logloss: 0.10047\n",
      "[72]\tTrain's multi_logloss: 0.104922\tTest's multi_logloss: 0.10199\n",
      "[73]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[74]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[75]\tTrain's multi_logloss: 0.102982\tTest's multi_logloss: 0.100988\n",
      "[76]\tTrain's multi_logloss: 0.101918\tTest's multi_logloss: 0.100274\n",
      "[77]\tTrain's multi_logloss: 0.102118\tTest's multi_logloss: 0.0978103\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[1]\tTrain's multi_logloss: 0.977312\tTest's multi_logloss: 0.998967\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.881351\tTest's multi_logloss: 0.90664\n",
      "[3]\tTrain's multi_logloss: 0.803834\tTest's multi_logloss: 0.829691\n",
      "[4]\tTrain's multi_logloss: 0.737351\tTest's multi_logloss: 0.764518\n",
      "[5]\tTrain's multi_logloss: 0.671026\tTest's multi_logloss: 0.693634\n",
      "[6]\tTrain's multi_logloss: 0.637998\tTest's multi_logloss: 0.664754\n",
      "[7]\tTrain's multi_logloss: 0.590822\tTest's multi_logloss: 0.614396\n",
      "[8]\tTrain's multi_logloss: 0.566795\tTest's multi_logloss: 0.588437\n",
      "[9]\tTrain's multi_logloss: 0.530072\tTest's multi_logloss: 0.548914\n",
      "[10]\tTrain's multi_logloss: 0.498344\tTest's multi_logloss: 0.513193\n",
      "[11]\tTrain's multi_logloss: 0.470144\tTest's multi_logloss: 0.481244\n",
      "[12]\tTrain's multi_logloss: 0.454189\tTest's multi_logloss: 0.462455\n",
      "[13]\tTrain's multi_logloss: 0.42036\tTest's multi_logloss: 0.431635\n",
      "[14]\tTrain's multi_logloss: 0.406712\tTest's multi_logloss: 0.420457\n",
      "[15]\tTrain's multi_logloss: 0.381388\tTest's multi_logloss: 0.4001\n",
      "[16]\tTrain's multi_logloss: 0.355213\tTest's multi_logloss: 0.37289\n",
      "[17]\tTrain's multi_logloss: 0.332873\tTest's multi_logloss: 0.348825\n",
      "[18]\tTrain's multi_logloss: 0.310779\tTest's multi_logloss: 0.321343\n",
      "[19]\tTrain's multi_logloss: 0.310779\tTest's multi_logloss: 0.321343\n",
      "[20]\tTrain's multi_logloss: 0.297188\tTest's multi_logloss: 0.306031\n",
      "[21]\tTrain's multi_logloss: 0.281656\tTest's multi_logloss: 0.288431\n",
      "[22]\tTrain's multi_logloss: 0.266087\tTest's multi_logloss: 0.269543\n",
      "[23]\tTrain's multi_logloss: 0.253325\tTest's multi_logloss: 0.255604\n",
      "[24]\tTrain's multi_logloss: 0.24535\tTest's multi_logloss: 0.244898\n",
      "[25]\tTrain's multi_logloss: 0.23299\tTest's multi_logloss: 0.232783\n",
      "[26]\tTrain's multi_logloss: 0.230668\tTest's multi_logloss: 0.23177\n",
      "[27]\tTrain's multi_logloss: 0.222736\tTest's multi_logloss: 0.223342\n",
      "[28]\tTrain's multi_logloss: 0.216789\tTest's multi_logloss: 0.217894\n",
      "[29]\tTrain's multi_logloss: 0.209488\tTest's multi_logloss: 0.208527\n",
      "[30]\tTrain's multi_logloss: 0.206749\tTest's multi_logloss: 0.206691\n",
      "[31]\tTrain's multi_logloss: 0.200704\tTest's multi_logloss: 0.198752\n",
      "[32]\tTrain's multi_logloss: 0.192837\tTest's multi_logloss: 0.187653\n",
      "[33]\tTrain's multi_logloss: 0.188598\tTest's multi_logloss: 0.181939\n",
      "[34]\tTrain's multi_logloss: 0.183746\tTest's multi_logloss: 0.175857\n",
      "[35]\tTrain's multi_logloss: 0.179537\tTest's multi_logloss: 0.169882\n",
      "[36]\tTrain's multi_logloss: 0.172618\tTest's multi_logloss: 0.160335\n",
      "[37]\tTrain's multi_logloss: 0.16675\tTest's multi_logloss: 0.151525\n",
      "[38]\tTrain's multi_logloss: 0.164406\tTest's multi_logloss: 0.149174\n",
      "[39]\tTrain's multi_logloss: 0.162472\tTest's multi_logloss: 0.146918\n",
      "[40]\tTrain's multi_logloss: 0.162105\tTest's multi_logloss: 0.146535\n",
      "[41]\tTrain's multi_logloss: 0.162165\tTest's multi_logloss: 0.14637\n",
      "[42]\tTrain's multi_logloss: 0.16042\tTest's multi_logloss: 0.144322\n",
      "[43]\tTrain's multi_logloss: 0.160178\tTest's multi_logloss: 0.143854\n",
      "[44]\tTrain's multi_logloss: 0.160162\tTest's multi_logloss: 0.145221\n",
      "[45]\tTrain's multi_logloss: 0.159908\tTest's multi_logloss: 0.144905\n",
      "[46]\tTrain's multi_logloss: 0.159676\tTest's multi_logloss: 0.144616\n",
      "[47]\tTrain's multi_logloss: 0.159665\tTest's multi_logloss: 0.144655\n",
      "[48]\tTrain's multi_logloss: 0.159458\tTest's multi_logloss: 0.144393\n",
      "[49]\tTrain's multi_logloss: 0.159451\tTest's multi_logloss: 0.144427\n",
      "[50]\tTrain's multi_logloss: 0.157041\tTest's multi_logloss: 0.143705\n",
      "[51]\tTrain's multi_logloss: 0.153173\tTest's multi_logloss: 0.141525\n",
      "[52]\tTrain's multi_logloss: 0.151303\tTest's multi_logloss: 0.142014\n",
      "[53]\tTrain's multi_logloss: 0.14769\tTest's multi_logloss: 0.139988\n",
      "[54]\tTrain's multi_logloss: 0.145974\tTest's multi_logloss: 0.138454\n",
      "[55]\tTrain's multi_logloss: 0.146743\tTest's multi_logloss: 0.1405\n",
      "[56]\tTrain's multi_logloss: 0.142716\tTest's multi_logloss: 0.134321\n",
      "[57]\tTrain's multi_logloss: 0.140599\tTest's multi_logloss: 0.132362\n",
      "[58]\tTrain's multi_logloss: 0.137627\tTest's multi_logloss: 0.127651\n",
      "[59]\tTrain's multi_logloss: 0.134907\tTest's multi_logloss: 0.126356\n",
      "[60]\tTrain's multi_logloss: 0.13247\tTest's multi_logloss: 0.122502\n",
      "[61]\tTrain's multi_logloss: 0.129756\tTest's multi_logloss: 0.118272\n",
      "[62]\tTrain's multi_logloss: 0.128728\tTest's multi_logloss: 0.118117\n",
      "[63]\tTrain's multi_logloss: 0.127055\tTest's multi_logloss: 0.116264\n",
      "[64]\tTrain's multi_logloss: 0.12611\tTest's multi_logloss: 0.115993\n",
      "[65]\tTrain's multi_logloss: 0.124486\tTest's multi_logloss: 0.116355\n",
      "[66]\tTrain's multi_logloss: 0.123966\tTest's multi_logloss: 0.117118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  67%|######6   | 4/6 [00:00<00:00, 18.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:43,964]\u001b[0m Trial 41 finished with value: 0.10945861046778566 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 0.09675416222275754.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  83%|########3 | 5/6 [00:00<00:00, 18.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67]\tTrain's multi_logloss: 0.122246\tTest's multi_logloss: 0.116472\n",
      "[68]\tTrain's multi_logloss: 0.122246\tTest's multi_logloss: 0.116472\n",
      "[69]\tTrain's multi_logloss: 0.119939\tTest's multi_logloss: 0.115911\n",
      "[70]\tTrain's multi_logloss: 0.120437\tTest's multi_logloss: 0.115856\n",
      "[71]\tTrain's multi_logloss: 0.118484\tTest's multi_logloss: 0.115432\n",
      "[72]\tTrain's multi_logloss: 0.119125\tTest's multi_logloss: 0.115435\n",
      "[73]\tTrain's multi_logloss: 0.117444\tTest's multi_logloss: 0.115114\n",
      "[74]\tTrain's multi_logloss: 0.116696\tTest's multi_logloss: 0.112344\n",
      "[75]\tTrain's multi_logloss: 0.111679\tTest's multi_logloss: 0.109459\n",
      "[76]\tTrain's multi_logloss: 0.106765\tTest's multi_logloss: 0.109797\n",
      "[77]\tTrain's multi_logloss: 0.103803\tTest's multi_logloss: 0.110519\n",
      "[78]\tTrain's multi_logloss: 0.0998329\tTest's multi_logloss: 0.111436\n",
      "[79]\tTrain's multi_logloss: 0.0974835\tTest's multi_logloss: 0.114567\n",
      "[80]\tTrain's multi_logloss: 0.0960764\tTest's multi_logloss: 0.117731\n",
      "[81]\tTrain's multi_logloss: 0.0956673\tTest's multi_logloss: 0.117806\n",
      "[82]\tTrain's multi_logloss: 0.0960401\tTest's multi_logloss: 0.118714\n",
      "[83]\tTrain's multi_logloss: 0.0942523\tTest's multi_logloss: 0.117412\n",
      "[84]\tTrain's multi_logloss: 0.0934523\tTest's multi_logloss: 0.117092\n",
      "[85]\tTrain's multi_logloss: 0.0935017\tTest's multi_logloss: 0.117416\n",
      "Early stopping, best iteration is:\n",
      "[75]\tTrain's multi_logloss: 0.111679\tTest's multi_logloss: 0.109459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754:  83%|########3 | 5/6 [00:00<00:00, 18.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.096754: 100%|##########| 6/6 [00:00<00:00, 18.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,020]\u001b[0m Trial 42 finished with value: 0.09675416222275754 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.09675416222275754.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.096754: 100%|##########| 6/6 [00:00<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.983222\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88597\tTest's multi_logloss: 0.923548\n",
      "[3]\tTrain's multi_logloss: 0.806014\tTest's multi_logloss: 0.840006\n",
      "[4]\tTrain's multi_logloss: 0.738065\tTest's multi_logloss: 0.767251\n",
      "[5]\tTrain's multi_logloss: 0.673282\tTest's multi_logloss: 0.698602\n",
      "[6]\tTrain's multi_logloss: 0.617878\tTest's multi_logloss: 0.643634\n",
      "[7]\tTrain's multi_logloss: 0.57934\tTest's multi_logloss: 0.602583\n",
      "[8]\tTrain's multi_logloss: 0.541765\tTest's multi_logloss: 0.560331\n",
      "[9]\tTrain's multi_logloss: 0.50884\tTest's multi_logloss: 0.523347\n",
      "[10]\tTrain's multi_logloss: 0.479527\tTest's multi_logloss: 0.490092\n",
      "[11]\tTrain's multi_logloss: 0.451586\tTest's multi_logloss: 0.457504\n",
      "[12]\tTrain's multi_logloss: 0.419615\tTest's multi_logloss: 0.426636\n",
      "[13]\tTrain's multi_logloss: 0.386908\tTest's multi_logloss: 0.3914\n",
      "[14]\tTrain's multi_logloss: 0.359833\tTest's multi_logloss: 0.360838\n",
      "[15]\tTrain's multi_logloss: 0.335844\tTest's multi_logloss: 0.337177\n",
      "[16]\tTrain's multi_logloss: 0.314675\tTest's multi_logloss: 0.31581\n",
      "[17]\tTrain's multi_logloss: 0.29616\tTest's multi_logloss: 0.298323\n",
      "[18]\tTrain's multi_logloss: 0.279269\tTest's multi_logloss: 0.277604\n",
      "[19]\tTrain's multi_logloss: 0.276059\tTest's multi_logloss: 0.274574\n",
      "[20]\tTrain's multi_logloss: 0.271726\tTest's multi_logloss: 0.272045\n",
      "[21]\tTrain's multi_logloss: 0.269129\tTest's multi_logloss: 0.269575\n",
      "[22]\tTrain's multi_logloss: 0.262998\tTest's multi_logloss: 0.263206\n",
      "[23]\tTrain's multi_logloss: 0.259571\tTest's multi_logloss: 0.261599\n",
      "[24]\tTrain's multi_logloss: 0.258693\tTest's multi_logloss: 0.262103\n",
      "[25]\tTrain's multi_logloss: 0.247252\tTest's multi_logloss: 0.245584\n",
      "[26]\tTrain's multi_logloss: 0.236045\tTest's multi_logloss: 0.230916\n",
      "[27]\tTrain's multi_logloss: 0.226512\tTest's multi_logloss: 0.216599\n",
      "[28]\tTrain's multi_logloss: 0.216354\tTest's multi_logloss: 0.205554\n",
      "[29]\tTrain's multi_logloss: 0.206152\tTest's multi_logloss: 0.195255\n",
      "[30]\tTrain's multi_logloss: 0.199206\tTest's multi_logloss: 0.184972\n",
      "[31]\tTrain's multi_logloss: 0.195468\tTest's multi_logloss: 0.182073\n",
      "[32]\tTrain's multi_logloss: 0.191326\tTest's multi_logloss: 0.178801\n",
      "[33]\tTrain's multi_logloss: 0.182914\tTest's multi_logloss: 0.173068\n",
      "[34]\tTrain's multi_logloss: 0.17542\tTest's multi_logloss: 0.167818\n",
      "[35]\tTrain's multi_logloss: 0.168744\tTest's multi_logloss: 0.163168\n",
      "[36]\tTrain's multi_logloss: 0.164981\tTest's multi_logloss: 0.161201\n",
      "[37]\tTrain's multi_logloss: 0.159243\tTest's multi_logloss: 0.152001\n",
      "[38]\tTrain's multi_logloss: 0.155178\tTest's multi_logloss: 0.147804\n",
      "[39]\tTrain's multi_logloss: 0.151789\tTest's multi_logloss: 0.14432\n",
      "[40]\tTrain's multi_logloss: 0.149042\tTest's multi_logloss: 0.14164\n",
      "[41]\tTrain's multi_logloss: 0.145128\tTest's multi_logloss: 0.135229\n",
      "[42]\tTrain's multi_logloss: 0.141753\tTest's multi_logloss: 0.129721\n",
      "[43]\tTrain's multi_logloss: 0.14036\tTest's multi_logloss: 0.127913\n",
      "[44]\tTrain's multi_logloss: 0.139153\tTest's multi_logloss: 0.126336\n",
      "[45]\tTrain's multi_logloss: 0.138039\tTest's multi_logloss: 0.124835\n",
      "[46]\tTrain's multi_logloss: 0.137074\tTest's multi_logloss: 0.123565\n",
      "[47]\tTrain's multi_logloss: 0.136801\tTest's multi_logloss: 0.122718\n",
      "[48]\tTrain's multi_logloss: 0.135769\tTest's multi_logloss: 0.121612\n",
      "[49]\tTrain's multi_logloss: 0.13365\tTest's multi_logloss: 0.120226\n",
      "[50]\tTrain's multi_logloss: 0.131747\tTest's multi_logloss: 0.119013\n",
      "[51]\tTrain's multi_logloss: 0.129082\tTest's multi_logloss: 0.117172\n",
      "[52]\tTrain's multi_logloss: 0.127766\tTest's multi_logloss: 0.116754\n",
      "[53]\tTrain's multi_logloss: 0.127466\tTest's multi_logloss: 0.11798\n",
      "[54]\tTrain's multi_logloss: 0.126004\tTest's multi_logloss: 0.117093\n",
      "[55]\tTrain's multi_logloss: 0.1231\tTest's multi_logloss: 0.116191\n",
      "[56]\tTrain's multi_logloss: 0.121516\tTest's multi_logloss: 0.116173\n",
      "[57]\tTrain's multi_logloss: 0.120061\tTest's multi_logloss: 0.11627\n",
      "[58]\tTrain's multi_logloss: 0.120197\tTest's multi_logloss: 0.116856\n",
      "[59]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[60]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116632\n",
      "[61]\tTrain's multi_logloss: 0.118679\tTest's multi_logloss: 0.117309\n",
      "[62]\tTrain's multi_logloss: 0.116474\tTest's multi_logloss: 0.113988\n",
      "[63]\tTrain's multi_logloss: 0.11442\tTest's multi_logloss: 0.111441\n",
      "[64]\tTrain's multi_logloss: 0.112302\tTest's multi_logloss: 0.106502\n",
      "[65]\tTrain's multi_logloss: 0.110531\tTest's multi_logloss: 0.102165\n",
      "[66]\tTrain's multi_logloss: 0.108849\tTest's multi_logloss: 0.100404\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[68]\tTrain's multi_logloss: 0.106835\tTest's multi_logloss: 0.0980864\n",
      "[69]\tTrain's multi_logloss: 0.106358\tTest's multi_logloss: 0.0995676\n",
      "[70]\tTrain's multi_logloss: 0.106068\tTest's multi_logloss: 0.100975\n",
      "[71]\tTrain's multi_logloss: 0.104974\tTest's multi_logloss: 0.10047\n",
      "[72]\tTrain's multi_logloss: 0.104922\tTest's multi_logloss: 0.10199\n",
      "[73]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[74]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[75]\tTrain's multi_logloss: 0.102982\tTest's multi_logloss: 0.100988\n",
      "[76]\tTrain's multi_logloss: 0.101918\tTest's multi_logloss: 0.100274\n",
      "[77]\tTrain's multi_logloss: 0.102118\tTest's multi_logloss: 0.0978103\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.096754:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.096754:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,068]\u001b[0m Trial 43 finished with value: 0.11618536004197835 and parameters: {'lambda_l1': 1.27839656733247e-07, 'lambda_l2': 0.0029870856827376633}. Best is trial 43 with value: 0.11618536004197835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.096754:   5%|5         | 1/20 [00:00<00:00, 21.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.983262\tTest's multi_logloss: 1.01811\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.886037\tTest's multi_logloss: 0.92361\n",
      "[3]\tTrain's multi_logloss: 0.806098\tTest's multi_logloss: 0.840087\n",
      "[4]\tTrain's multi_logloss: 0.73816\tTest's multi_logloss: 0.767346\n",
      "[5]\tTrain's multi_logloss: 0.673387\tTest's multi_logloss: 0.698709\n",
      "[6]\tTrain's multi_logloss: 0.61799\tTest's multi_logloss: 0.643749\n",
      "[7]\tTrain's multi_logloss: 0.579458\tTest's multi_logloss: 0.602705\n",
      "[8]\tTrain's multi_logloss: 0.541886\tTest's multi_logloss: 0.56046\n",
      "[9]\tTrain's multi_logloss: 0.508963\tTest's multi_logloss: 0.523479\n",
      "[10]\tTrain's multi_logloss: 0.479652\tTest's multi_logloss: 0.490228\n",
      "[11]\tTrain's multi_logloss: 0.451713\tTest's multi_logloss: 0.457644\n",
      "[12]\tTrain's multi_logloss: 0.419749\tTest's multi_logloss: 0.426779\n",
      "[13]\tTrain's multi_logloss: 0.387047\tTest's multi_logloss: 0.39155\n",
      "[14]\tTrain's multi_logloss: 0.359972\tTest's multi_logloss: 0.360991\n",
      "[15]\tTrain's multi_logloss: 0.335985\tTest's multi_logloss: 0.337333\n",
      "[16]\tTrain's multi_logloss: 0.314817\tTest's multi_logloss: 0.315969\n",
      "[17]\tTrain's multi_logloss: 0.296301\tTest's multi_logloss: 0.298481\n",
      "[18]\tTrain's multi_logloss: 0.27941\tTest's multi_logloss: 0.277764\n",
      "[19]\tTrain's multi_logloss: 0.2762\tTest's multi_logloss: 0.274735\n",
      "[20]\tTrain's multi_logloss: 0.271866\tTest's multi_logloss: 0.272206\n",
      "[21]\tTrain's multi_logloss: 0.269269\tTest's multi_logloss: 0.269736\n",
      "[22]\tTrain's multi_logloss: 0.26314\tTest's multi_logloss: 0.26337\n",
      "[23]\tTrain's multi_logloss: 0.259712\tTest's multi_logloss: 0.261762\n",
      "[24]\tTrain's multi_logloss: 0.258832\tTest's multi_logloss: 0.262266\n",
      "[25]\tTrain's multi_logloss: 0.247393\tTest's multi_logloss: 0.24575\n",
      "[26]\tTrain's multi_logloss: 0.236185\tTest's multi_logloss: 0.231081\n",
      "[27]\tTrain's multi_logloss: 0.22665\tTest's multi_logloss: 0.216765\n",
      "[28]\tTrain's multi_logloss: 0.216493\tTest's multi_logloss: 0.205718\n",
      "[29]\tTrain's multi_logloss: 0.20629\tTest's multi_logloss: 0.195418\n",
      "[30]\tTrain's multi_logloss: 0.199342\tTest's multi_logloss: 0.185133\n",
      "[31]\tTrain's multi_logloss: 0.195603\tTest's multi_logloss: 0.182233\n",
      "[32]\tTrain's multi_logloss: 0.191461\tTest's multi_logloss: 0.178959\n",
      "[33]\tTrain's multi_logloss: 0.18305\tTest's multi_logloss: 0.173226\n",
      "[34]\tTrain's multi_logloss: 0.175557\tTest's multi_logloss: 0.167975\n",
      "[35]\tTrain's multi_logloss: 0.168881\tTest's multi_logloss: 0.163323\n",
      "[36]\tTrain's multi_logloss: 0.16512\tTest's multi_logloss: 0.161354\n",
      "[37]\tTrain's multi_logloss: 0.15938\tTest's multi_logloss: 0.152154\n",
      "[38]\tTrain's multi_logloss: 0.155318\tTest's multi_logloss: 0.147955\n",
      "[39]\tTrain's multi_logloss: 0.15193\tTest's multi_logloss: 0.144469\n",
      "[40]\tTrain's multi_logloss: 0.149183\tTest's multi_logloss: 0.141787\n",
      "[41]\tTrain's multi_logloss: 0.145266\tTest's multi_logloss: 0.135374\n",
      "[42]\tTrain's multi_logloss: 0.141889\tTest's multi_logloss: 0.129864\n",
      "[43]\tTrain's multi_logloss: 0.140497\tTest's multi_logloss: 0.128057\n",
      "[44]\tTrain's multi_logloss: 0.139289\tTest's multi_logloss: 0.12648\n",
      "[45]\tTrain's multi_logloss: 0.138175\tTest's multi_logloss: 0.12498\n",
      "[46]\tTrain's multi_logloss: 0.13721\tTest's multi_logloss: 0.12371\n",
      "[47]\tTrain's multi_logloss: 0.136937\tTest's multi_logloss: 0.122864\n",
      "[48]\tTrain's multi_logloss: 0.135904\tTest's multi_logloss: 0.121757\n",
      "[49]\tTrain's multi_logloss: 0.133786\tTest's multi_logloss: 0.120371\n",
      "[50]\tTrain's multi_logloss: 0.131883\tTest's multi_logloss: 0.119158\n",
      "[51]\tTrain's multi_logloss: 0.129219\tTest's multi_logloss: 0.117317\n",
      "[52]\tTrain's multi_logloss: 0.127903\tTest's multi_logloss: 0.116898\n",
      "[53]\tTrain's multi_logloss: 0.127606\tTest's multi_logloss: 0.118122\n",
      "[54]\tTrain's multi_logloss: 0.126144\tTest's multi_logloss: 0.117235\n",
      "[55]\tTrain's multi_logloss: 0.123241\tTest's multi_logloss: 0.116331\n",
      "[56]\tTrain's multi_logloss: 0.121656\tTest's multi_logloss: 0.116312\n",
      "[57]\tTrain's multi_logloss: 0.1202\tTest's multi_logloss: 0.116406\n",
      "[58]\tTrain's multi_logloss: 0.1202\tTest's multi_logloss: 0.116406\n",
      "[59]\tTrain's multi_logloss: 0.118863\tTest's multi_logloss: 0.116604\n",
      "[60]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[61]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[62]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[63]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[64]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[65]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[66]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[67]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[68]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[69]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[70]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "Early stopping, best iteration is:\n",
      "[60]\tTrain's multi_logloss: 0.118157\tTest's multi_logloss: 0.116185\n",
      "[1]\tTrain's multi_logloss: 0.987882\tTest's multi_logloss: 1.02226\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.893881\tTest's multi_logloss: 0.930913\n",
      "[3]\tTrain's multi_logloss: 0.815967\tTest's multi_logloss: 0.849657\n",
      "[4]\tTrain's multi_logloss: 0.749377\tTest's multi_logloss: 0.778553\n",
      "[5]\tTrain's multi_logloss: 0.685779\tTest's multi_logloss: 0.711337\n",
      "[6]\tTrain's multi_logloss: 0.631316\tTest's multi_logloss: 0.657452\n",
      "[7]\tTrain's multi_logloss: 0.59071\tTest's multi_logloss: 0.61468\n",
      "[8]\tTrain's multi_logloss: 0.553869\tTest's multi_logloss: 0.573508\n",
      "[9]\tTrain's multi_logloss: 0.52115\tTest's multi_logloss: 0.536566\n",
      "[10]\tTrain's multi_logloss: 0.49225\tTest's multi_logloss: 0.50399\n",
      "[11]\tTrain's multi_logloss: 0.464757\tTest's multi_logloss: 0.472056\n",
      "[12]\tTrain's multi_logloss: 0.439125\tTest's multi_logloss: 0.4424\n",
      "[13]\tTrain's multi_logloss: 0.40661\tTest's multi_logloss: 0.407894\n",
      "[14]\tTrain's multi_logloss: 0.379566\tTest's multi_logloss: 0.37785\n",
      "[15]\tTrain's multi_logloss: 0.355558\tTest's multi_logloss: 0.354619\n",
      "[16]\tTrain's multi_logloss: 0.334302\tTest's multi_logloss: 0.333605\n",
      "[17]\tTrain's multi_logloss: 0.315449\tTest's multi_logloss: 0.315797\n",
      "[18]\tTrain's multi_logloss: 0.298371\tTest's multi_logloss: 0.295313\n",
      "[19]\tTrain's multi_logloss: 0.293836\tTest's multi_logloss: 0.292754\n",
      "[20]\tTrain's multi_logloss: 0.289469\tTest's multi_logloss: 0.290661\n",
      "[21]\tTrain's multi_logloss: 0.286936\tTest's multi_logloss: 0.28952\n",
      "[22]\tTrain's multi_logloss: 0.285059\tTest's multi_logloss: 0.287467\n",
      "[23]\tTrain's multi_logloss: 0.282258\tTest's multi_logloss: 0.285978\n",
      "[24]\tTrain's multi_logloss: 0.272978\tTest's multi_logloss: 0.276963\n",
      "[25]\tTrain's multi_logloss: 0.261714\tTest's multi_logloss: 0.260854\n",
      "[26]\tTrain's multi_logloss: 0.250701\tTest's multi_logloss: 0.246526\n",
      "[27]\tTrain's multi_logloss: 0.241186\tTest's multi_logloss: 0.23235\n",
      "[28]\tTrain's multi_logloss: 0.231579\tTest's multi_logloss: 0.222609\n",
      "[29]\tTrain's multi_logloss: 0.22134\tTest's multi_logloss: 0.212064\n",
      "[30]\tTrain's multi_logloss: 0.214848\tTest's multi_logloss: 0.203019\n",
      "[31]\tTrain's multi_logloss: 0.211399\tTest's multi_logloss: 0.200371\n",
      "[32]\tTrain's multi_logloss: 0.207561\tTest's multi_logloss: 0.1973\n",
      "[33]\tTrain's multi_logloss: 0.202331\tTest's multi_logloss: 0.192368\n",
      "[34]\tTrain's multi_logloss: 0.197611\tTest's multi_logloss: 0.187786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.096754:   5%|5         | 1/20 [00:00<00:01, 10.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,117]\u001b[0m Trial 44 finished with value: 0.12258137319681053 and parameters: {'lambda_l1': 0.002962485793344968, 'lambda_l2': 0.36491653927883044}. Best is trial 43 with value: 0.11618536004197835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.096754:  10%|#         | 2/20 [00:00<00:00, 20.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\tTrain's multi_logloss: 0.193396\tTest's multi_logloss: 0.183647\n",
      "[36]\tTrain's multi_logloss: 0.189731\tTest's multi_logloss: 0.18165\n",
      "[37]\tTrain's multi_logloss: 0.183369\tTest's multi_logloss: 0.171676\n",
      "[38]\tTrain's multi_logloss: 0.179289\tTest's multi_logloss: 0.166977\n",
      "[39]\tTrain's multi_logloss: 0.17588\tTest's multi_logloss: 0.163041\n",
      "[40]\tTrain's multi_logloss: 0.173112\tTest's multi_logloss: 0.159954\n",
      "[41]\tTrain's multi_logloss: 0.168695\tTest's multi_logloss: 0.153038\n",
      "[42]\tTrain's multi_logloss: 0.164846\tTest's multi_logloss: 0.147065\n",
      "[43]\tTrain's multi_logloss: 0.163345\tTest's multi_logloss: 0.145306\n",
      "[44]\tTrain's multi_logloss: 0.160953\tTest's multi_logloss: 0.14146\n",
      "[45]\tTrain's multi_logloss: 0.15878\tTest's multi_logloss: 0.137945\n",
      "[46]\tTrain's multi_logloss: 0.156801\tTest's multi_logloss: 0.134725\n",
      "[47]\tTrain's multi_logloss: 0.155638\tTest's multi_logloss: 0.13215\n",
      "[48]\tTrain's multi_logloss: 0.153938\tTest's multi_logloss: 0.129392\n",
      "[49]\tTrain's multi_logloss: 0.15261\tTest's multi_logloss: 0.129074\n",
      "[50]\tTrain's multi_logloss: 0.148495\tTest's multi_logloss: 0.127389\n",
      "[51]\tTrain's multi_logloss: 0.14849\tTest's multi_logloss: 0.128471\n",
      "[52]\tTrain's multi_logloss: 0.147027\tTest's multi_logloss: 0.129439\n",
      "[53]\tTrain's multi_logloss: 0.144027\tTest's multi_logloss: 0.12723\n",
      "[54]\tTrain's multi_logloss: 0.142295\tTest's multi_logloss: 0.126365\n",
      "[55]\tTrain's multi_logloss: 0.141489\tTest's multi_logloss: 0.125503\n",
      "[56]\tTrain's multi_logloss: 0.140735\tTest's multi_logloss: 0.124697\n",
      "[57]\tTrain's multi_logloss: 0.140029\tTest's multi_logloss: 0.123944\n",
      "[58]\tTrain's multi_logloss: 0.139368\tTest's multi_logloss: 0.12324\n",
      "[59]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[60]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[61]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[62]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[63]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[64]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[65]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[66]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[67]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[68]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[69]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "Early stopping, best iteration is:\n",
      "[59]\tTrain's multi_logloss: 0.138749\tTest's multi_logloss: 0.122581\n",
      "[1]\tTrain's multi_logloss: 1.00818\tTest's multi_logloss: 1.04049\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.929206\tTest's multi_logloss: 0.963761\n",
      "[3]\tTrain's multi_logloss: 0.861313\tTest's multi_logloss: 0.893466\n",
      "[4]\tTrain's multi_logloss: 0.801674\tTest's multi_logloss: 0.83048\n",
      "[5]\tTrain's multi_logloss: 0.749605\tTest's multi_logloss: 0.774967\n",
      "[6]\tTrain's multi_logloss: 0.699337\tTest's multi_logloss: 0.725798\n",
      "[7]\tTrain's multi_logloss: 0.661544\tTest's multi_logloss: 0.686097\n",
      "[8]\tTrain's multi_logloss: 0.626293\tTest's multi_logloss: 0.650448\n",
      "[9]\tTrain's multi_logloss: 0.592598\tTest's multi_logloss: 0.613065\n",
      "[10]\tTrain's multi_logloss: 0.564142\tTest's multi_logloss: 0.581548\n",
      "[11]\tTrain's multi_logloss: 0.537315\tTest's multi_logloss: 0.55065\n",
      "[12]\tTrain's multi_logloss: 0.514212\tTest's multi_logloss: 0.525371\n",
      "[13]\tTrain's multi_logloss: 0.483659\tTest's multi_logloss: 0.493327\n",
      "[14]\tTrain's multi_logloss: 0.456772\tTest's multi_logloss: 0.464286\n",
      "[15]\tTrain's multi_logloss: 0.43207\tTest's multi_logloss: 0.437799\n",
      "[16]\tTrain's multi_logloss: 0.409915\tTest's multi_logloss: 0.413794\n",
      "[17]\tTrain's multi_logloss: 0.390324\tTest's multi_logloss: 0.395503\n",
      "[18]\tTrain's multi_logloss: 0.372363\tTest's multi_logloss: 0.375134\n",
      "[19]\tTrain's multi_logloss: 0.371628\tTest's multi_logloss: 0.376134\n",
      "[20]\tTrain's multi_logloss: 0.369383\tTest's multi_logloss: 0.376247\n",
      "[21]\tTrain's multi_logloss: 0.369383\tTest's multi_logloss: 0.376247\n",
      "[22]\tTrain's multi_logloss: 0.36942\tTest's multi_logloss: 0.376591\n",
      "[23]\tTrain's multi_logloss: 0.367966\tTest's multi_logloss: 0.375765\n",
      "[24]\tTrain's multi_logloss: 0.366588\tTest's multi_logloss: 0.374831\n",
      "[25]\tTrain's multi_logloss: 0.365332\tTest's multi_logloss: 0.373952\n",
      "[26]\tTrain's multi_logloss: 0.350707\tTest's multi_logloss: 0.356067\n",
      "[27]\tTrain's multi_logloss: 0.337235\tTest's multi_logloss: 0.339315\n",
      "[28]\tTrain's multi_logloss: 0.324652\tTest's multi_logloss: 0.325335\n",
      "[29]\tTrain's multi_logloss: 0.312016\tTest's multi_logloss: 0.312362\n",
      "[30]\tTrain's multi_logloss: 0.302311\tTest's multi_logloss: 0.299236\n",
      "[31]\tTrain's multi_logloss: 0.292267\tTest's multi_logloss: 0.288404\n",
      "[32]\tTrain's multi_logloss: 0.285539\tTest's multi_logloss: 0.283402\n",
      "[33]\tTrain's multi_logloss: 0.279407\tTest's multi_logloss: 0.278342\n",
      "[34]\tTrain's multi_logloss: 0.274115\tTest's multi_logloss: 0.275716\n",
      "[35]\tTrain's multi_logloss: 0.26865\tTest's multi_logloss: 0.273016\n",
      "[36]\tTrain's multi_logloss: 0.264389\tTest's multi_logloss: 0.271122\n",
      "[37]\tTrain's multi_logloss: 0.257638\tTest's multi_logloss: 0.26563\n",
      "[38]\tTrain's multi_logloss: 0.251242\tTest's multi_logloss: 0.257219\n",
      "[39]\tTrain's multi_logloss: 0.24539\tTest's multi_logloss: 0.249524\n",
      "[40]\tTrain's multi_logloss: 0.240426\tTest's multi_logloss: 0.242635\n",
      "[41]\tTrain's multi_logloss: 0.234229\tTest's multi_logloss: 0.233969\n",
      "[42]\tTrain's multi_logloss: 0.228636\tTest's multi_logloss: 0.226279\n",
      "[43]\tTrain's multi_logloss: 0.224576\tTest's multi_logloss: 0.22065\n",
      "[44]\tTrain's multi_logloss: 0.222323\tTest's multi_logloss: 0.218039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45]\tTrain's multi_logloss: 0.218884\tTest's multi_logloss: 0.213476\n",
      "[46]\tTrain's multi_logloss: 0.215648\tTest's multi_logloss: 0.209192\n",
      "[47]\tTrain's multi_logloss: 0.21363\tTest's multi_logloss: 0.205977\n",
      "[48]\tTrain's multi_logloss: 0.211735\tTest's multi_logloss: 0.202952\n",
      "[49]\tTrain's multi_logloss: 0.210627\tTest's multi_logloss: 0.201944\n",
      "[50]\tTrain's multi_logloss: 0.21002\tTest's multi_logloss: 0.201027\n",
      "[51]\tTrain's multi_logloss: 0.209456\tTest's multi_logloss: 0.200168\n",
      "[52]\tTrain's multi_logloss: 0.207222\tTest's multi_logloss: 0.198051\n",
      "[53]\tTrain's multi_logloss: 0.205792\tTest's multi_logloss: 0.196259\n",
      "[54]\tTrain's multi_logloss: 0.205333\tTest's multi_logloss: 0.195548\n",
      "[55]\tTrain's multi_logloss: 0.204254\tTest's multi_logloss: 0.194744\n",
      "[56]\tTrain's multi_logloss: 0.203576\tTest's multi_logloss: 0.194101\n",
      "[57]\tTrain's multi_logloss: 0.200972\tTest's multi_logloss: 0.192462\n",
      "[58]\tTrain's multi_logloss: 0.200972\tTest's multi_logloss: 0.192462\n",
      "[59]\tTrain's multi_logloss: 0.199092\tTest's multi_logloss: 0.191475\n",
      "[60]\tTrain's multi_logloss: 0.197311\tTest's multi_logloss: 0.190558\n",
      "[61]\tTrain's multi_logloss: 0.197311\tTest's multi_logloss: 0.190558\n",
      "[62]\tTrain's multi_logloss: 0.195623\tTest's multi_logloss: 0.189707\n",
      "[63]\tTrain's multi_logloss: 0.19402\tTest's multi_logloss: 0.188917\n",
      "[64]\tTrain's multi_logloss: 0.190185\tTest's multi_logloss: 0.183961\n",
      "[65]\tTrain's multi_logloss: 0.185578\tTest's multi_logloss: 0.179972\n",
      "[66]\tTrain's multi_logloss: 0.181253\tTest's multi_logloss: 0.176277\n",
      "[67]\tTrain's multi_logloss: 0.177334\tTest's multi_logloss: 0.173485\n",
      "[68]\tTrain's multi_logloss: 0.174538\tTest's multi_logloss: 0.170249\n",
      "[69]\tTrain's multi_logloss: 0.171711\tTest's multi_logloss: 0.167646\n",
      "[70]\tTrain's multi_logloss: 0.169588\tTest's multi_logloss: 0.165868\n",
      "[71]\tTrain's multi_logloss: 0.16741\tTest's multi_logloss: 0.162985\n",
      "[72]\tTrain's multi_logloss: 0.165497\tTest's multi_logloss: 0.16048\n",
      "[73]\tTrain's multi_logloss: 0.163701\tTest's multi_logloss: 0.15804\n",
      "[74]\tTrain's multi_logloss: 0.162063\tTest's multi_logloss: 0.155789\n",
      "[75]\tTrain's multi_logloss: 0.160565\tTest's multi_logloss: 0.153707\n",
      "[76]\tTrain's multi_logloss: 0.160565\tTest's multi_logloss: 0.153707\n",
      "[77]\tTrain's multi_logloss: 0.159344\tTest's multi_logloss: 0.151628\n",
      "[78]\tTrain's multi_logloss: 0.157685\tTest's multi_logloss: 0.150552\n",
      "[79]\tTrain's multi_logloss: 0.156188\tTest's multi_logloss: 0.149338\n",
      "[80]\tTrain's multi_logloss: 0.155334\tTest's multi_logloss: 0.147438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.096754:  10%|#         | 2/20 [00:00<00:01, 12.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.096754:  15%|#5        | 3/20 [00:00<00:00, 18.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,187]\u001b[0m Trial 45 finished with value: 0.13532380506233976 and parameters: {'lambda_l1': 7.668092566795717e-06, 'lambda_l2': 2.439901638633852}. Best is trial 43 with value: 0.11618536004197835.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.096754:  15%|#5        | 3/20 [00:00<00:00, 18.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81]\tTrain's multi_logloss: 0.154484\tTest's multi_logloss: 0.145791\n",
      "[82]\tTrain's multi_logloss: 0.153228\tTest's multi_logloss: 0.144855\n",
      "[83]\tTrain's multi_logloss: 0.151316\tTest's multi_logloss: 0.144477\n",
      "[84]\tTrain's multi_logloss: 0.149191\tTest's multi_logloss: 0.143227\n",
      "[85]\tTrain's multi_logloss: 0.146704\tTest's multi_logloss: 0.141923\n",
      "[86]\tTrain's multi_logloss: 0.145313\tTest's multi_logloss: 0.142032\n",
      "[87]\tTrain's multi_logloss: 0.144074\tTest's multi_logloss: 0.14223\n",
      "[88]\tTrain's multi_logloss: 0.14174\tTest's multi_logloss: 0.141076\n",
      "[89]\tTrain's multi_logloss: 0.140289\tTest's multi_logloss: 0.140531\n",
      "[90]\tTrain's multi_logloss: 0.139049\tTest's multi_logloss: 0.139913\n",
      "[91]\tTrain's multi_logloss: 0.137681\tTest's multi_logloss: 0.139618\n",
      "[92]\tTrain's multi_logloss: 0.136724\tTest's multi_logloss: 0.138929\n",
      "[93]\tTrain's multi_logloss: 0.13581\tTest's multi_logloss: 0.138495\n",
      "[94]\tTrain's multi_logloss: 0.135001\tTest's multi_logloss: 0.138126\n",
      "[95]\tTrain's multi_logloss: 0.134492\tTest's multi_logloss: 0.137598\n",
      "[96]\tTrain's multi_logloss: 0.134142\tTest's multi_logloss: 0.137569\n",
      "[97]\tTrain's multi_logloss: 0.132778\tTest's multi_logloss: 0.136812\n",
      "[98]\tTrain's multi_logloss: 0.13235\tTest's multi_logloss: 0.136514\n",
      "[99]\tTrain's multi_logloss: 0.131118\tTest's multi_logloss: 0.135887\n",
      "[100]\tTrain's multi_logloss: 0.129954\tTest's multi_logloss: 0.135324\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's multi_logloss: 0.129954\tTest's multi_logloss: 0.135324\n",
      "[1]\tTrain's multi_logloss: 0.983696\tTest's multi_logloss: 1.01853\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88681\tTest's multi_logloss: 0.924382\n",
      "[3]\tTrain's multi_logloss: 0.807116\tTest's multi_logloss: 0.841159\n",
      "[4]\tTrain's multi_logloss: 0.739369\tTest's multi_logloss: 0.768665\n",
      "[5]\tTrain's multi_logloss: 0.674754\tTest's multi_logloss: 0.700233\n",
      "[6]\tTrain's multi_logloss: 0.619514\tTest's multi_logloss: 0.645447\n",
      "[7]\tTrain's multi_logloss: 0.581108\tTest's multi_logloss: 0.604559\n",
      "[8]\tTrain's multi_logloss: 0.543648\tTest's multi_logloss: 0.562464\n",
      "[9]\tTrain's multi_logloss: 0.510814\tTest's multi_logloss: 0.525606\n",
      "[10]\tTrain's multi_logloss: 0.481577\tTest's multi_logloss: 0.492464\n",
      "[11]\tTrain's multi_logloss: 0.453727\tTest's multi_logloss: 0.460002\n",
      "[12]\tTrain's multi_logloss: 0.427849\tTest's multi_logloss: 0.429961\n",
      "[13]\tTrain's multi_logloss: 0.394751\tTest's multi_logloss: 0.394745\n",
      "[14]\tTrain's multi_logloss: 0.36741\tTest's multi_logloss: 0.364205\n",
      "[15]\tTrain's multi_logloss: 0.343178\tTest's multi_logloss: 0.340581\n",
      "[16]\tTrain's multi_logloss: 0.321792\tTest's multi_logloss: 0.319243\n",
      "[17]\tTrain's multi_logloss: 0.302876\tTest's multi_logloss: 0.301374\n",
      "[18]\tTrain's multi_logloss: 0.285814\tTest's multi_logloss: 0.280692\n",
      "[19]\tTrain's multi_logloss: 0.281256\tTest's multi_logloss: 0.278048\n",
      "[20]\tTrain's multi_logloss: 0.277663\tTest's multi_logloss: 0.276342\n",
      "[21]\tTrain's multi_logloss: 0.275191\tTest's multi_logloss: 0.275181\n",
      "[22]\tTrain's multi_logloss: 0.26901\tTest's multi_logloss: 0.268783\n",
      "[23]\tTrain's multi_logloss: 0.262209\tTest's multi_logloss: 0.263393\n",
      "[24]\tTrain's multi_logloss: 0.256163\tTest's multi_logloss: 0.258394\n",
      "[25]\tTrain's multi_logloss: 0.245156\tTest's multi_logloss: 0.242238\n",
      "[26]\tTrain's multi_logloss: 0.234407\tTest's multi_logloss: 0.227875\n",
      "[27]\tTrain's multi_logloss: 0.225203\tTest's multi_logloss: 0.213967\n",
      "[28]\tTrain's multi_logloss: 0.21579\tTest's multi_logloss: 0.204461\n",
      "[29]\tTrain's multi_logloss: 0.205746\tTest's multi_logloss: 0.194117\n",
      "[30]\tTrain's multi_logloss: 0.19965\tTest's multi_logloss: 0.185399\n",
      "[31]\tTrain's multi_logloss: 0.196116\tTest's multi_logloss: 0.18266\n",
      "[32]\tTrain's multi_logloss: 0.190733\tTest's multi_logloss: 0.177718\n",
      "[33]\tTrain's multi_logloss: 0.182669\tTest's multi_logloss: 0.172145\n",
      "[34]\tTrain's multi_logloss: 0.175457\tTest's multi_logloss: 0.167067\n",
      "[35]\tTrain's multi_logloss: 0.169025\tTest's multi_logloss: 0.162556\n",
      "[36]\tTrain's multi_logloss: 0.165583\tTest's multi_logloss: 0.16092\n",
      "[37]\tTrain's multi_logloss: 0.159975\tTest's multi_logloss: 0.151782\n",
      "[38]\tTrain's multi_logloss: 0.156053\tTest's multi_logloss: 0.147658\n",
      "[39]\tTrain's multi_logloss: 0.152827\tTest's multi_logloss: 0.144278\n",
      "[40]\tTrain's multi_logloss: 0.150274\tTest's multi_logloss: 0.141762\n",
      "[41]\tTrain's multi_logloss: 0.146528\tTest's multi_logloss: 0.135523\n",
      "[42]\tTrain's multi_logloss: 0.143332\tTest's multi_logloss: 0.13023\n",
      "[43]\tTrain's multi_logloss: 0.142893\tTest's multi_logloss: 0.129393\n",
      "[44]\tTrain's multi_logloss: 0.141848\tTest's multi_logloss: 0.127992\n",
      "[45]\tTrain's multi_logloss: 0.14149\tTest's multi_logloss: 0.127005\n",
      "[46]\tTrain's multi_logloss: 0.140595\tTest's multi_logloss: 0.125824\n",
      "[47]\tTrain's multi_logloss: 0.140189\tTest's multi_logloss: 0.125058\n",
      "[48]\tTrain's multi_logloss: 0.138578\tTest's multi_logloss: 0.122172\n",
      "[49]\tTrain's multi_logloss: 0.136688\tTest's multi_logloss: 0.121269\n",
      "[50]\tTrain's multi_logloss: 0.13497\tTest's multi_logloss: 0.120489\n",
      "[51]\tTrain's multi_logloss: 0.132316\tTest's multi_logloss: 0.118585\n",
      "[52]\tTrain's multi_logloss: 0.132085\tTest's multi_logloss: 0.119774\n",
      "[53]\tTrain's multi_logloss: 0.131965\tTest's multi_logloss: 0.120995\n",
      "[54]\tTrain's multi_logloss: 0.130299\tTest's multi_logloss: 0.119899\n",
      "[55]\tTrain's multi_logloss: 0.127401\tTest's multi_logloss: 0.1186\n",
      "[56]\tTrain's multi_logloss: 0.124747\tTest's multi_logloss: 0.117515\n",
      "[57]\tTrain's multi_logloss: 0.122313\tTest's multi_logloss: 0.116624\n",
      "[58]\tTrain's multi_logloss: 0.121644\tTest's multi_logloss: 0.115887\n",
      "[59]\tTrain's multi_logloss: 0.119466\tTest's multi_logloss: 0.115235\n",
      "[60]\tTrain's multi_logloss: 0.117467\tTest's multi_logloss: 0.114742\n",
      "[61]\tTrain's multi_logloss: 0.114922\tTest's multi_logloss: 0.10905\n",
      "[62]\tTrain's multi_logloss: 0.113372\tTest's multi_logloss: 0.106343\n",
      "[63]\tTrain's multi_logloss: 0.111823\tTest's multi_logloss: 0.104227\n",
      "[64]\tTrain's multi_logloss: 0.11014\tTest's multi_logloss: 0.0999116\n",
      "[65]\tTrain's multi_logloss: 0.108771\tTest's multi_logloss: 0.0961505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  15%|#5        | 3/20 [00:00<00:00, 18.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,238]\u001b[0m Trial 46 finished with value: 0.0939874474503158 and parameters: {'lambda_l1': 0.03850625556053545, 'lambda_l2': 0.0045965525980078}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  20%|##        | 4/20 [00:00<00:00, 18.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  20%|##        | 4/20 [00:00<00:00, 18.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  25%|##5       | 5/20 [00:00<00:00, 18.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,290]\u001b[0m Trial 47 finished with value: 0.09675595142448515 and parameters: {'lambda_l1': 3.3923585498008402e-06, 'lambda_l2': 3.5583354233467945e-05}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  25%|##5       | 5/20 [00:00<00:00, 18.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66]\tTrain's multi_logloss: 0.105657\tTest's multi_logloss: 0.0939874\n",
      "[67]\tTrain's multi_logloss: 0.104392\tTest's multi_logloss: 0.094621\n",
      "[68]\tTrain's multi_logloss: 0.104039\tTest's multi_logloss: 0.0953626\n",
      "[69]\tTrain's multi_logloss: 0.103752\tTest's multi_logloss: 0.0970201\n",
      "[70]\tTrain's multi_logloss: 0.103624\tTest's multi_logloss: 0.0985786\n",
      "[71]\tTrain's multi_logloss: 0.102833\tTest's multi_logloss: 0.0984346\n",
      "[72]\tTrain's multi_logloss: 0.102922\tTest's multi_logloss: 0.0999829\n",
      "[73]\tTrain's multi_logloss: 0.102922\tTest's multi_logloss: 0.0999829\n",
      "[74]\tTrain's multi_logloss: 0.101323\tTest's multi_logloss: 0.0999253\n",
      "[75]\tTrain's multi_logloss: 0.100146\tTest's multi_logloss: 0.0991173\n",
      "[76]\tTrain's multi_logloss: 0.100229\tTest's multi_logloss: 0.0965756\n",
      "Early stopping, best iteration is:\n",
      "[66]\tTrain's multi_logloss: 0.105657\tTest's multi_logloss: 0.0939874\n",
      "[1]\tTrain's multi_logloss: 0.983223\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.885971\tTest's multi_logloss: 0.923548\n",
      "[3]\tTrain's multi_logloss: 0.806015\tTest's multi_logloss: 0.840007\n",
      "[4]\tTrain's multi_logloss: 0.738067\tTest's multi_logloss: 0.767253\n",
      "[5]\tTrain's multi_logloss: 0.673283\tTest's multi_logloss: 0.698604\n",
      "[6]\tTrain's multi_logloss: 0.617879\tTest's multi_logloss: 0.643635\n",
      "[7]\tTrain's multi_logloss: 0.579342\tTest's multi_logloss: 0.602584\n",
      "[8]\tTrain's multi_logloss: 0.541767\tTest's multi_logloss: 0.560333\n",
      "[9]\tTrain's multi_logloss: 0.508842\tTest's multi_logloss: 0.523349\n",
      "[10]\tTrain's multi_logloss: 0.479528\tTest's multi_logloss: 0.490094\n",
      "[11]\tTrain's multi_logloss: 0.451587\tTest's multi_logloss: 0.457506\n",
      "[12]\tTrain's multi_logloss: 0.419617\tTest's multi_logloss: 0.426638\n",
      "[13]\tTrain's multi_logloss: 0.38691\tTest's multi_logloss: 0.391402\n",
      "[14]\tTrain's multi_logloss: 0.359834\tTest's multi_logloss: 0.36084\n",
      "[15]\tTrain's multi_logloss: 0.335846\tTest's multi_logloss: 0.337179\n",
      "[16]\tTrain's multi_logloss: 0.314677\tTest's multi_logloss: 0.315812\n",
      "[17]\tTrain's multi_logloss: 0.296162\tTest's multi_logloss: 0.298325\n",
      "[18]\tTrain's multi_logloss: 0.279271\tTest's multi_logloss: 0.277606\n",
      "[19]\tTrain's multi_logloss: 0.276061\tTest's multi_logloss: 0.274576\n",
      "[20]\tTrain's multi_logloss: 0.271728\tTest's multi_logloss: 0.272047\n",
      "[21]\tTrain's multi_logloss: 0.269131\tTest's multi_logloss: 0.269578\n",
      "[22]\tTrain's multi_logloss: 0.263\tTest's multi_logloss: 0.263209\n",
      "[23]\tTrain's multi_logloss: 0.259573\tTest's multi_logloss: 0.261601\n",
      "[24]\tTrain's multi_logloss: 0.258695\tTest's multi_logloss: 0.262105\n",
      "[25]\tTrain's multi_logloss: 0.247254\tTest's multi_logloss: 0.245586\n",
      "[26]\tTrain's multi_logloss: 0.236047\tTest's multi_logloss: 0.230918\n",
      "[27]\tTrain's multi_logloss: 0.226514\tTest's multi_logloss: 0.216602\n",
      "[28]\tTrain's multi_logloss: 0.216356\tTest's multi_logloss: 0.205556\n",
      "[29]\tTrain's multi_logloss: 0.206154\tTest's multi_logloss: 0.195258\n",
      "[30]\tTrain's multi_logloss: 0.199208\tTest's multi_logloss: 0.184974\n",
      "[31]\tTrain's multi_logloss: 0.19547\tTest's multi_logloss: 0.182075\n",
      "[32]\tTrain's multi_logloss: 0.191328\tTest's multi_logloss: 0.178803\n",
      "[33]\tTrain's multi_logloss: 0.182916\tTest's multi_logloss: 0.17307\n",
      "[34]\tTrain's multi_logloss: 0.175422\tTest's multi_logloss: 0.167821\n",
      "[35]\tTrain's multi_logloss: 0.168746\tTest's multi_logloss: 0.163171\n",
      "[36]\tTrain's multi_logloss: 0.164983\tTest's multi_logloss: 0.161203\n",
      "[37]\tTrain's multi_logloss: 0.159244\tTest's multi_logloss: 0.152004\n",
      "[38]\tTrain's multi_logloss: 0.15518\tTest's multi_logloss: 0.147806\n",
      "[39]\tTrain's multi_logloss: 0.151791\tTest's multi_logloss: 0.144322\n",
      "[40]\tTrain's multi_logloss: 0.149044\tTest's multi_logloss: 0.141642\n",
      "[41]\tTrain's multi_logloss: 0.14513\tTest's multi_logloss: 0.135231\n",
      "[42]\tTrain's multi_logloss: 0.141755\tTest's multi_logloss: 0.129723\n",
      "[43]\tTrain's multi_logloss: 0.140362\tTest's multi_logloss: 0.127915\n",
      "[44]\tTrain's multi_logloss: 0.139155\tTest's multi_logloss: 0.126338\n",
      "[45]\tTrain's multi_logloss: 0.138041\tTest's multi_logloss: 0.124837\n",
      "[46]\tTrain's multi_logloss: 0.137075\tTest's multi_logloss: 0.123567\n",
      "[47]\tTrain's multi_logloss: 0.136803\tTest's multi_logloss: 0.12272\n",
      "[48]\tTrain's multi_logloss: 0.13577\tTest's multi_logloss: 0.121614\n",
      "[49]\tTrain's multi_logloss: 0.133652\tTest's multi_logloss: 0.120228\n",
      "[50]\tTrain's multi_logloss: 0.131749\tTest's multi_logloss: 0.119015\n",
      "[51]\tTrain's multi_logloss: 0.129084\tTest's multi_logloss: 0.117174\n",
      "[52]\tTrain's multi_logloss: 0.127768\tTest's multi_logloss: 0.116756\n",
      "[53]\tTrain's multi_logloss: 0.127468\tTest's multi_logloss: 0.117982\n",
      "[54]\tTrain's multi_logloss: 0.126006\tTest's multi_logloss: 0.117095\n",
      "[55]\tTrain's multi_logloss: 0.123102\tTest's multi_logloss: 0.116193\n",
      "[56]\tTrain's multi_logloss: 0.121518\tTest's multi_logloss: 0.116175\n",
      "[57]\tTrain's multi_logloss: 0.120063\tTest's multi_logloss: 0.116272\n",
      "[58]\tTrain's multi_logloss: 0.120199\tTest's multi_logloss: 0.116858\n",
      "[59]\tTrain's multi_logloss: 0.118345\tTest's multi_logloss: 0.116634\n",
      "[60]\tTrain's multi_logloss: 0.118345\tTest's multi_logloss: 0.116634\n",
      "[61]\tTrain's multi_logloss: 0.118681\tTest's multi_logloss: 0.117311\n",
      "[62]\tTrain's multi_logloss: 0.116476\tTest's multi_logloss: 0.11399\n",
      "[63]\tTrain's multi_logloss: 0.114422\tTest's multi_logloss: 0.111443\n",
      "[64]\tTrain's multi_logloss: 0.112304\tTest's multi_logloss: 0.106504\n",
      "[65]\tTrain's multi_logloss: 0.110532\tTest's multi_logloss: 0.102167\n",
      "[66]\tTrain's multi_logloss: 0.108851\tTest's multi_logloss: 0.100406\n",
      "[67]\tTrain's multi_logloss: 0.107476\tTest's multi_logloss: 0.096756\n",
      "[68]\tTrain's multi_logloss: 0.106836\tTest's multi_logloss: 0.0980881\n",
      "[69]\tTrain's multi_logloss: 0.10636\tTest's multi_logloss: 0.0995692\n",
      "[70]\tTrain's multi_logloss: 0.10607\tTest's multi_logloss: 0.100977\n",
      "[71]\tTrain's multi_logloss: 0.104976\tTest's multi_logloss: 0.100471\n",
      "[72]\tTrain's multi_logloss: 0.104924\tTest's multi_logloss: 0.101991\n",
      "[73]\tTrain's multi_logloss: 0.104443\tTest's multi_logloss: 0.101985\n",
      "[74]\tTrain's multi_logloss: 0.104443\tTest's multi_logloss: 0.101985\n",
      "[75]\tTrain's multi_logloss: 0.102984\tTest's multi_logloss: 0.100989\n",
      "[76]\tTrain's multi_logloss: 0.10192\tTest's multi_logloss: 0.100275\n",
      "[77]\tTrain's multi_logloss: 0.102119\tTest's multi_logloss: 0.0978117\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107476\tTest's multi_logloss: 0.096756\n",
      "[1]\tTrain's multi_logloss: 0.983222\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88597\tTest's multi_logloss: 0.923548\n",
      "[3]\tTrain's multi_logloss: 0.806014\tTest's multi_logloss: 0.840006\n",
      "[4]\tTrain's multi_logloss: 0.738065\tTest's multi_logloss: 0.767251\n",
      "[5]\tTrain's multi_logloss: 0.673282\tTest's multi_logloss: 0.698602\n",
      "[6]\tTrain's multi_logloss: 0.617878\tTest's multi_logloss: 0.643634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  25%|##5       | 5/20 [00:00<00:00, 18.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,342]\u001b[0m Trial 48 finished with value: 0.09675420749377965 and parameters: {'lambda_l1': 2.78559125392141e-07, 'lambda_l2': 5.715524064454488e-07}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  30%|###       | 6/20 [00:00<00:00, 18.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tTrain's multi_logloss: 0.57934\tTest's multi_logloss: 0.602583\n",
      "[8]\tTrain's multi_logloss: 0.541765\tTest's multi_logloss: 0.560331\n",
      "[9]\tTrain's multi_logloss: 0.50884\tTest's multi_logloss: 0.523347\n",
      "[10]\tTrain's multi_logloss: 0.479527\tTest's multi_logloss: 0.490092\n",
      "[11]\tTrain's multi_logloss: 0.451586\tTest's multi_logloss: 0.457504\n",
      "[12]\tTrain's multi_logloss: 0.419615\tTest's multi_logloss: 0.426636\n",
      "[13]\tTrain's multi_logloss: 0.386908\tTest's multi_logloss: 0.3914\n",
      "[14]\tTrain's multi_logloss: 0.359833\tTest's multi_logloss: 0.360838\n",
      "[15]\tTrain's multi_logloss: 0.335844\tTest's multi_logloss: 0.337177\n",
      "[16]\tTrain's multi_logloss: 0.314675\tTest's multi_logloss: 0.31581\n",
      "[17]\tTrain's multi_logloss: 0.29616\tTest's multi_logloss: 0.298323\n",
      "[18]\tTrain's multi_logloss: 0.279269\tTest's multi_logloss: 0.277604\n",
      "[19]\tTrain's multi_logloss: 0.276059\tTest's multi_logloss: 0.274574\n",
      "[20]\tTrain's multi_logloss: 0.271726\tTest's multi_logloss: 0.272045\n",
      "[21]\tTrain's multi_logloss: 0.269129\tTest's multi_logloss: 0.269576\n",
      "[22]\tTrain's multi_logloss: 0.262998\tTest's multi_logloss: 0.263206\n",
      "[23]\tTrain's multi_logloss: 0.259571\tTest's multi_logloss: 0.261599\n",
      "[24]\tTrain's multi_logloss: 0.258693\tTest's multi_logloss: 0.262103\n",
      "[25]\tTrain's multi_logloss: 0.247252\tTest's multi_logloss: 0.245584\n",
      "[26]\tTrain's multi_logloss: 0.236045\tTest's multi_logloss: 0.230916\n",
      "[27]\tTrain's multi_logloss: 0.226512\tTest's multi_logloss: 0.2166\n",
      "[28]\tTrain's multi_logloss: 0.216354\tTest's multi_logloss: 0.205554\n",
      "[29]\tTrain's multi_logloss: 0.206152\tTest's multi_logloss: 0.195255\n",
      "[30]\tTrain's multi_logloss: 0.199206\tTest's multi_logloss: 0.184972\n",
      "[31]\tTrain's multi_logloss: 0.195468\tTest's multi_logloss: 0.182073\n",
      "[32]\tTrain's multi_logloss: 0.191326\tTest's multi_logloss: 0.178801\n",
      "[33]\tTrain's multi_logloss: 0.182914\tTest's multi_logloss: 0.173068\n",
      "[34]\tTrain's multi_logloss: 0.17542\tTest's multi_logloss: 0.167818\n",
      "[35]\tTrain's multi_logloss: 0.168744\tTest's multi_logloss: 0.163168\n",
      "[36]\tTrain's multi_logloss: 0.164981\tTest's multi_logloss: 0.161201\n",
      "[37]\tTrain's multi_logloss: 0.159243\tTest's multi_logloss: 0.152001\n",
      "[38]\tTrain's multi_logloss: 0.155178\tTest's multi_logloss: 0.147804\n",
      "[39]\tTrain's multi_logloss: 0.151789\tTest's multi_logloss: 0.14432\n",
      "[40]\tTrain's multi_logloss: 0.149042\tTest's multi_logloss: 0.14164\n",
      "[41]\tTrain's multi_logloss: 0.145128\tTest's multi_logloss: 0.135229\n",
      "[42]\tTrain's multi_logloss: 0.141753\tTest's multi_logloss: 0.129721\n",
      "[43]\tTrain's multi_logloss: 0.140361\tTest's multi_logloss: 0.127913\n",
      "[44]\tTrain's multi_logloss: 0.139153\tTest's multi_logloss: 0.126336\n",
      "[45]\tTrain's multi_logloss: 0.138039\tTest's multi_logloss: 0.124835\n",
      "[46]\tTrain's multi_logloss: 0.137074\tTest's multi_logloss: 0.123565\n",
      "[47]\tTrain's multi_logloss: 0.136801\tTest's multi_logloss: 0.122718\n",
      "[48]\tTrain's multi_logloss: 0.135769\tTest's multi_logloss: 0.121612\n",
      "[49]\tTrain's multi_logloss: 0.13365\tTest's multi_logloss: 0.120226\n",
      "[50]\tTrain's multi_logloss: 0.131747\tTest's multi_logloss: 0.119013\n",
      "[51]\tTrain's multi_logloss: 0.129082\tTest's multi_logloss: 0.117172\n",
      "[52]\tTrain's multi_logloss: 0.127766\tTest's multi_logloss: 0.116754\n",
      "[53]\tTrain's multi_logloss: 0.127466\tTest's multi_logloss: 0.11798\n",
      "[54]\tTrain's multi_logloss: 0.126004\tTest's multi_logloss: 0.117093\n",
      "[55]\tTrain's multi_logloss: 0.1231\tTest's multi_logloss: 0.116191\n",
      "[56]\tTrain's multi_logloss: 0.121516\tTest's multi_logloss: 0.116174\n",
      "[57]\tTrain's multi_logloss: 0.120061\tTest's multi_logloss: 0.11627\n",
      "[58]\tTrain's multi_logloss: 0.120198\tTest's multi_logloss: 0.116856\n",
      "[59]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116633\n",
      "[60]\tTrain's multi_logloss: 0.118343\tTest's multi_logloss: 0.116633\n",
      "[61]\tTrain's multi_logloss: 0.118679\tTest's multi_logloss: 0.117309\n",
      "[62]\tTrain's multi_logloss: 0.116474\tTest's multi_logloss: 0.113988\n",
      "[63]\tTrain's multi_logloss: 0.11442\tTest's multi_logloss: 0.111441\n",
      "[64]\tTrain's multi_logloss: 0.112302\tTest's multi_logloss: 0.106502\n",
      "[65]\tTrain's multi_logloss: 0.110531\tTest's multi_logloss: 0.102165\n",
      "[66]\tTrain's multi_logloss: 0.108849\tTest's multi_logloss: 0.100404\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[68]\tTrain's multi_logloss: 0.106835\tTest's multi_logloss: 0.0980864\n",
      "[69]\tTrain's multi_logloss: 0.106358\tTest's multi_logloss: 0.0995677\n",
      "[70]\tTrain's multi_logloss: 0.106068\tTest's multi_logloss: 0.100975\n",
      "[71]\tTrain's multi_logloss: 0.104974\tTest's multi_logloss: 0.10047\n",
      "[72]\tTrain's multi_logloss: 0.104922\tTest's multi_logloss: 0.10199\n",
      "[73]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[74]\tTrain's multi_logloss: 0.104442\tTest's multi_logloss: 0.101984\n",
      "[75]\tTrain's multi_logloss: 0.102982\tTest's multi_logloss: 0.100988\n",
      "[76]\tTrain's multi_logloss: 0.101918\tTest's multi_logloss: 0.100274\n",
      "[77]\tTrain's multi_logloss: 0.102118\tTest's multi_logloss: 0.0978103\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107474\tTest's multi_logloss: 0.0967542\n",
      "[1]\tTrain's multi_logloss: 1.02122\tTest's multi_logloss: 1.05216\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.952613\tTest's multi_logloss: 0.985518\n",
      "[3]\tTrain's multi_logloss: 0.892218\tTest's multi_logloss: 0.92324\n",
      "[4]\tTrain's multi_logloss: 0.83813\tTest's multi_logloss: 0.866474\n",
      "[5]\tTrain's multi_logloss: 0.790052\tTest's multi_logloss: 0.815633\n",
      "[6]\tTrain's multi_logloss: 0.746759\tTest's multi_logloss: 0.772681\n",
      "[7]\tTrain's multi_logloss: 0.711343\tTest's multi_logloss: 0.735871\n",
      "[8]\tTrain's multi_logloss: 0.676091\tTest's multi_logloss: 0.700607\n",
      "[9]\tTrain's multi_logloss: 0.647468\tTest's multi_logloss: 0.671526\n",
      "[10]\tTrain's multi_logloss: 0.61827\tTest's multi_logloss: 0.639484\n",
      "[11]\tTrain's multi_logloss: 0.591028\tTest's multi_logloss: 0.608391\n",
      "[12]\tTrain's multi_logloss: 0.568178\tTest's multi_logloss: 0.583752\n",
      "[13]\tTrain's multi_logloss: 0.539956\tTest's multi_logloss: 0.557663\n",
      "[14]\tTrain's multi_logloss: 0.513414\tTest's multi_logloss: 0.529386\n",
      "[15]\tTrain's multi_logloss: 0.488927\tTest's multi_logloss: 0.503331\n",
      "[16]\tTrain's multi_logloss: 0.466658\tTest's multi_logloss: 0.479431\n",
      "[17]\tTrain's multi_logloss: 0.446694\tTest's multi_logloss: 0.460839\n",
      "[18]\tTrain's multi_logloss: 0.428081\tTest's multi_logloss: 0.440214\n",
      "[19]\tTrain's multi_logloss: 0.422931\tTest's multi_logloss: 0.436306\n",
      "[20]\tTrain's multi_logloss: 0.41609\tTest's multi_logloss: 0.431102\n",
      "[21]\tTrain's multi_logloss: 0.411245\tTest's multi_logloss: 0.427538\n",
      "[22]\tTrain's multi_logloss: 0.407035\tTest's multi_logloss: 0.424445\n",
      "[23]\tTrain's multi_logloss: 0.401468\tTest's multi_logloss: 0.420303\n",
      "[24]\tTrain's multi_logloss: 0.396591\tTest's multi_logloss: 0.41524\n",
      "[25]\tTrain's multi_logloss: 0.382713\tTest's multi_logloss: 0.398181\n",
      "[26]\tTrain's multi_logloss: 0.369989\tTest's multi_logloss: 0.382512\n",
      "[27]\tTrain's multi_logloss: 0.358119\tTest's multi_logloss: 0.367668\n",
      "[28]\tTrain's multi_logloss: 0.347127\tTest's multi_logloss: 0.355407\n",
      "[29]\tTrain's multi_logloss: 0.33572\tTest's multi_logloss: 0.343518\n",
      "[30]\tTrain's multi_logloss: 0.327063\tTest's multi_logloss: 0.331767\n",
      "[31]\tTrain's multi_logloss: 0.320014\tTest's multi_logloss: 0.325811\n",
      "[32]\tTrain's multi_logloss: 0.313882\tTest's multi_logloss: 0.32055\n",
      "[33]\tTrain's multi_logloss: 0.308244\tTest's multi_logloss: 0.315852\n",
      "[34]\tTrain's multi_logloss: 0.301052\tTest's multi_logloss: 0.311298\n",
      "[35]\tTrain's multi_logloss: 0.294009\tTest's multi_logloss: 0.305451\n",
      "[36]\tTrain's multi_logloss: 0.287829\tTest's multi_logloss: 0.301725\n",
      "[37]\tTrain's multi_logloss: 0.28075\tTest's multi_logloss: 0.291627\n",
      "[38]\tTrain's multi_logloss: 0.275387\tTest's multi_logloss: 0.283971\n",
      "[39]\tTrain's multi_logloss: 0.270348\tTest's multi_logloss: 0.2768\n",
      "[40]\tTrain's multi_logloss: 0.265705\tTest's multi_logloss: 0.2703\n",
      "[41]\tTrain's multi_logloss: 0.260041\tTest's multi_logloss: 0.262323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  30%|###       | 6/20 [00:00<00:00, 18.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  35%|###5      | 7/20 [00:00<00:00, 17.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,408]\u001b[0m Trial 49 finished with value: 0.1580705328299051 and parameters: {'lambda_l1': 0.00016067007154104215, 'lambda_l2': 4.382573881446638}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  35%|###5      | 7/20 [00:00<00:00, 17.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42]\tTrain's multi_logloss: 0.254836\tTest's multi_logloss: 0.2551\n",
      "[43]\tTrain's multi_logloss: 0.252898\tTest's multi_logloss: 0.253164\n",
      "[44]\tTrain's multi_logloss: 0.251036\tTest's multi_logloss: 0.251305\n",
      "[45]\tTrain's multi_logloss: 0.249246\tTest's multi_logloss: 0.249521\n",
      "[46]\tTrain's multi_logloss: 0.247379\tTest's multi_logloss: 0.247546\n",
      "[47]\tTrain's multi_logloss: 0.247247\tTest's multi_logloss: 0.247297\n",
      "[48]\tTrain's multi_logloss: 0.24547\tTest's multi_logloss: 0.245418\n",
      "[49]\tTrain's multi_logloss: 0.243609\tTest's multi_logloss: 0.2434\n",
      "[50]\tTrain's multi_logloss: 0.241881\tTest's multi_logloss: 0.241538\n",
      "[51]\tTrain's multi_logloss: 0.241199\tTest's multi_logloss: 0.240521\n",
      "[52]\tTrain's multi_logloss: 0.240235\tTest's multi_logloss: 0.239623\n",
      "[53]\tTrain's multi_logloss: 0.239347\tTest's multi_logloss: 0.238815\n",
      "[54]\tTrain's multi_logloss: 0.239304\tTest's multi_logloss: 0.238776\n",
      "[55]\tTrain's multi_logloss: 0.238583\tTest's multi_logloss: 0.238151\n",
      "[56]\tTrain's multi_logloss: 0.235757\tTest's multi_logloss: 0.237747\n",
      "[57]\tTrain's multi_logloss: 0.235245\tTest's multi_logloss: 0.238751\n",
      "[58]\tTrain's multi_logloss: 0.233296\tTest's multi_logloss: 0.23694\n",
      "[59]\tTrain's multi_logloss: 0.229914\tTest's multi_logloss: 0.234912\n",
      "[60]\tTrain's multi_logloss: 0.227062\tTest's multi_logloss: 0.231981\n",
      "[61]\tTrain's multi_logloss: 0.223128\tTest's multi_logloss: 0.22651\n",
      "[62]\tTrain's multi_logloss: 0.219541\tTest's multi_logloss: 0.221574\n",
      "[63]\tTrain's multi_logloss: 0.215941\tTest's multi_logloss: 0.217719\n",
      "[64]\tTrain's multi_logloss: 0.212424\tTest's multi_logloss: 0.213002\n",
      "[65]\tTrain's multi_logloss: 0.208048\tTest's multi_logloss: 0.208834\n",
      "[66]\tTrain's multi_logloss: 0.2039\tTest's multi_logloss: 0.204921\n",
      "[67]\tTrain's multi_logloss: 0.200446\tTest's multi_logloss: 0.201606\n",
      "[68]\tTrain's multi_logloss: 0.198058\tTest's multi_logloss: 0.198459\n",
      "[69]\tTrain's multi_logloss: 0.195673\tTest's multi_logloss: 0.195308\n",
      "[70]\tTrain's multi_logloss: 0.193724\tTest's multi_logloss: 0.193449\n",
      "[71]\tTrain's multi_logloss: 0.191815\tTest's multi_logloss: 0.191642\n",
      "[72]\tTrain's multi_logloss: 0.190071\tTest's multi_logloss: 0.190038\n",
      "[73]\tTrain's multi_logloss: 0.190071\tTest's multi_logloss: 0.190038\n",
      "[74]\tTrain's multi_logloss: 0.188163\tTest's multi_logloss: 0.188441\n",
      "[75]\tTrain's multi_logloss: 0.186215\tTest's multi_logloss: 0.186845\n",
      "[76]\tTrain's multi_logloss: 0.184384\tTest's multi_logloss: 0.185338\n",
      "[77]\tTrain's multi_logloss: 0.183134\tTest's multi_logloss: 0.183409\n",
      "[78]\tTrain's multi_logloss: 0.1815\tTest's multi_logloss: 0.182034\n",
      "[79]\tTrain's multi_logloss: 0.179918\tTest's multi_logloss: 0.180714\n",
      "[80]\tTrain's multi_logloss: 0.177348\tTest's multi_logloss: 0.17879\n",
      "[81]\tTrain's multi_logloss: 0.175685\tTest's multi_logloss: 0.177428\n",
      "[82]\tTrain's multi_logloss: 0.172712\tTest's multi_logloss: 0.175043\n",
      "[83]\tTrain's multi_logloss: 0.1714\tTest's multi_logloss: 0.174529\n",
      "[84]\tTrain's multi_logloss: 0.168446\tTest's multi_logloss: 0.172114\n",
      "[85]\tTrain's multi_logloss: 0.166222\tTest's multi_logloss: 0.170579\n",
      "[86]\tTrain's multi_logloss: 0.165351\tTest's multi_logloss: 0.170229\n",
      "[87]\tTrain's multi_logloss: 0.164585\tTest's multi_logloss: 0.169945\n",
      "[88]\tTrain's multi_logloss: 0.163384\tTest's multi_logloss: 0.169193\n",
      "[89]\tTrain's multi_logloss: 0.162011\tTest's multi_logloss: 0.16843\n",
      "[90]\tTrain's multi_logloss: 0.160959\tTest's multi_logloss: 0.167758\n",
      "[91]\tTrain's multi_logloss: 0.159623\tTest's multi_logloss: 0.167309\n",
      "[92]\tTrain's multi_logloss: 0.158812\tTest's multi_logloss: 0.166436\n",
      "[93]\tTrain's multi_logloss: 0.158285\tTest's multi_logloss: 0.166074\n",
      "[94]\tTrain's multi_logloss: 0.1578\tTest's multi_logloss: 0.165752\n",
      "[95]\tTrain's multi_logloss: 0.157078\tTest's multi_logloss: 0.164965\n",
      "[96]\tTrain's multi_logloss: 0.156395\tTest's multi_logloss: 0.164221\n",
      "[97]\tTrain's multi_logloss: 0.154877\tTest's multi_logloss: 0.16304\n",
      "[98]\tTrain's multi_logloss: 0.15293\tTest's multi_logloss: 0.160996\n",
      "[99]\tTrain's multi_logloss: 0.151331\tTest's multi_logloss: 0.159824\n",
      "[100]\tTrain's multi_logloss: 0.149371\tTest's multi_logloss: 0.158071\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's multi_logloss: 0.149371\tTest's multi_logloss: 0.158071\n",
      "[1]\tTrain's multi_logloss: 0.999964\tTest's multi_logloss: 1.03311\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.914734\tTest's multi_logloss: 0.950306\n",
      "[3]\tTrain's multi_logloss: 0.842549\tTest's multi_logloss: 0.875357\n",
      "[4]\tTrain's multi_logloss: 0.779868\tTest's multi_logloss: 0.808876\n",
      "[5]\tTrain's multi_logloss: 0.719656\tTest's multi_logloss: 0.745647\n",
      "[6]\tTrain's multi_logloss: 0.66781\tTest's multi_logloss: 0.6947\n",
      "[7]\tTrain's multi_logloss: 0.629108\tTest's multi_logloss: 0.653775\n",
      "[8]\tTrain's multi_logloss: 0.593327\tTest's multi_logloss: 0.617352\n",
      "[9]\tTrain's multi_logloss: 0.561114\tTest's multi_logloss: 0.581267\n",
      "[10]\tTrain's multi_logloss: 0.532421\tTest's multi_logloss: 0.549152\n",
      "[11]\tTrain's multi_logloss: 0.505524\tTest's multi_logloss: 0.518136\n",
      "[12]\tTrain's multi_logloss: 0.482493\tTest's multi_logloss: 0.492677\n",
      "[13]\tTrain's multi_logloss: 0.451214\tTest's multi_logloss: 0.459626\n",
      "[14]\tTrain's multi_logloss: 0.424257\tTest's multi_logloss: 0.430173\n",
      "[15]\tTrain's multi_logloss: 0.39938\tTest's multi_logloss: 0.40321\n",
      "[16]\tTrain's multi_logloss: 0.378203\tTest's multi_logloss: 0.382733\n",
      "[17]\tTrain's multi_logloss: 0.358878\tTest's multi_logloss: 0.364576\n",
      "[18]\tTrain's multi_logloss: 0.341293\tTest's multi_logloss: 0.344201\n",
      "[19]\tTrain's multi_logloss: 0.334992\tTest's multi_logloss: 0.339898\n",
      "[20]\tTrain's multi_logloss: 0.328432\tTest's multi_logloss: 0.334524\n",
      "[21]\tTrain's multi_logloss: 0.324936\tTest's multi_logloss: 0.331259\n",
      "[22]\tTrain's multi_logloss: 0.32497\tTest's multi_logloss: 0.331587\n",
      "[23]\tTrain's multi_logloss: 0.323783\tTest's multi_logloss: 0.330918\n",
      "[24]\tTrain's multi_logloss: 0.322089\tTest's multi_logloss: 0.330885\n",
      "[25]\tTrain's multi_logloss: 0.308486\tTest's multi_logloss: 0.313405\n",
      "[26]\tTrain's multi_logloss: 0.296329\tTest's multi_logloss: 0.297766\n",
      "[27]\tTrain's multi_logloss: 0.286509\tTest's multi_logloss: 0.284396\n",
      "[28]\tTrain's multi_logloss: 0.275676\tTest's multi_logloss: 0.272426\n",
      "[29]\tTrain's multi_logloss: 0.264618\tTest's multi_logloss: 0.261122\n",
      "[30]\tTrain's multi_logloss: 0.256764\tTest's multi_logloss: 0.250057\n",
      "[31]\tTrain's multi_logloss: 0.250965\tTest's multi_logloss: 0.248012\n",
      "[32]\tTrain's multi_logloss: 0.246132\tTest's multi_logloss: 0.245052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  35%|###5      | 7/20 [00:00<00:00, 17.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,473]\u001b[0m Trial 50 finished with value: 0.1213020329477143 and parameters: {'lambda_l1': 1.0898342384494874e-06, 'lambda_l2': 1.4921389413657447}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  40%|####      | 8/20 [00:00<00:00, 17.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\tTrain's multi_logloss: 0.241283\tTest's multi_logloss: 0.241545\n",
      "[34]\tTrain's multi_logloss: 0.237063\tTest's multi_logloss: 0.24005\n",
      "[35]\tTrain's multi_logloss: 0.233681\tTest's multi_logloss: 0.239727\n",
      "[36]\tTrain's multi_logloss: 0.230388\tTest's multi_logloss: 0.238837\n",
      "[37]\tTrain's multi_logloss: 0.223023\tTest's multi_logloss: 0.22863\n",
      "[38]\tTrain's multi_logloss: 0.218583\tTest's multi_logloss: 0.222791\n",
      "[39]\tTrain's multi_logloss: 0.214034\tTest's multi_logloss: 0.216098\n",
      "[40]\tTrain's multi_logloss: 0.209981\tTest's multi_logloss: 0.210225\n",
      "[41]\tTrain's multi_logloss: 0.204827\tTest's multi_logloss: 0.20274\n",
      "[42]\tTrain's multi_logloss: 0.20025\tTest's multi_logloss: 0.196176\n",
      "[43]\tTrain's multi_logloss: 0.198442\tTest's multi_logloss: 0.193833\n",
      "[44]\tTrain's multi_logloss: 0.197158\tTest's multi_logloss: 0.191438\n",
      "[45]\tTrain's multi_logloss: 0.191643\tTest's multi_logloss: 0.186733\n",
      "[46]\tTrain's multi_logloss: 0.190591\tTest's multi_logloss: 0.184925\n",
      "[47]\tTrain's multi_logloss: 0.188791\tTest's multi_logloss: 0.182492\n",
      "[48]\tTrain's multi_logloss: 0.186346\tTest's multi_logloss: 0.17931\n",
      "[49]\tTrain's multi_logloss: 0.18496\tTest's multi_logloss: 0.178252\n",
      "[50]\tTrain's multi_logloss: 0.183745\tTest's multi_logloss: 0.177386\n",
      "[51]\tTrain's multi_logloss: 0.183351\tTest's multi_logloss: 0.176757\n",
      "[52]\tTrain's multi_logloss: 0.182316\tTest's multi_logloss: 0.176106\n",
      "[53]\tTrain's multi_logloss: 0.181417\tTest's multi_logloss: 0.175602\n",
      "[54]\tTrain's multi_logloss: 0.181099\tTest's multi_logloss: 0.175096\n",
      "[55]\tTrain's multi_logloss: 0.178757\tTest's multi_logloss: 0.172607\n",
      "[56]\tTrain's multi_logloss: 0.17658\tTest's multi_logloss: 0.170276\n",
      "[57]\tTrain's multi_logloss: 0.174597\tTest's multi_logloss: 0.169319\n",
      "[58]\tTrain's multi_logloss: 0.174741\tTest's multi_logloss: 0.170033\n",
      "[59]\tTrain's multi_logloss: 0.173792\tTest's multi_logloss: 0.169375\n",
      "[60]\tTrain's multi_logloss: 0.173258\tTest's multi_logloss: 0.169612\n",
      "[61]\tTrain's multi_logloss: 0.170273\tTest's multi_logloss: 0.165109\n",
      "[62]\tTrain's multi_logloss: 0.167299\tTest's multi_logloss: 0.161078\n",
      "[63]\tTrain's multi_logloss: 0.164117\tTest's multi_logloss: 0.158054\n",
      "[64]\tTrain's multi_logloss: 0.161467\tTest's multi_logloss: 0.154366\n",
      "[65]\tTrain's multi_logloss: 0.159025\tTest's multi_logloss: 0.150948\n",
      "[66]\tTrain's multi_logloss: 0.155092\tTest's multi_logloss: 0.148234\n",
      "[67]\tTrain's multi_logloss: 0.151916\tTest's multi_logloss: 0.145447\n",
      "[68]\tTrain's multi_logloss: 0.150423\tTest's multi_logloss: 0.144066\n",
      "[69]\tTrain's multi_logloss: 0.147587\tTest's multi_logloss: 0.141635\n",
      "[70]\tTrain's multi_logloss: 0.146321\tTest's multi_logloss: 0.141335\n",
      "[71]\tTrain's multi_logloss: 0.143739\tTest's multi_logloss: 0.139153\n",
      "[72]\tTrain's multi_logloss: 0.142488\tTest's multi_logloss: 0.137288\n",
      "[73]\tTrain's multi_logloss: 0.142488\tTest's multi_logloss: 0.137288\n",
      "[74]\tTrain's multi_logloss: 0.140874\tTest's multi_logloss: 0.136187\n",
      "[75]\tTrain's multi_logloss: 0.139343\tTest's multi_logloss: 0.134896\n",
      "[76]\tTrain's multi_logloss: 0.13796\tTest's multi_logloss: 0.13372\n",
      "[77]\tTrain's multi_logloss: 0.137383\tTest's multi_logloss: 0.132006\n",
      "[78]\tTrain's multi_logloss: 0.136072\tTest's multi_logloss: 0.131166\n",
      "[79]\tTrain's multi_logloss: 0.134986\tTest's multi_logloss: 0.130203\n",
      "[80]\tTrain's multi_logloss: 0.132152\tTest's multi_logloss: 0.129027\n",
      "[81]\tTrain's multi_logloss: 0.130029\tTest's multi_logloss: 0.127973\n",
      "[82]\tTrain's multi_logloss: 0.128301\tTest's multi_logloss: 0.127305\n",
      "[83]\tTrain's multi_logloss: 0.126833\tTest's multi_logloss: 0.127628\n",
      "[84]\tTrain's multi_logloss: 0.123752\tTest's multi_logloss: 0.125819\n",
      "[85]\tTrain's multi_logloss: 0.121306\tTest's multi_logloss: 0.125082\n",
      "[86]\tTrain's multi_logloss: 0.120933\tTest's multi_logloss: 0.124556\n",
      "[87]\tTrain's multi_logloss: 0.120677\tTest's multi_logloss: 0.124113\n",
      "[88]\tTrain's multi_logloss: 0.120077\tTest's multi_logloss: 0.124171\n",
      "[89]\tTrain's multi_logloss: 0.119127\tTest's multi_logloss: 0.123968\n",
      "[90]\tTrain's multi_logloss: 0.118708\tTest's multi_logloss: 0.124103\n",
      "[91]\tTrain's multi_logloss: 0.118447\tTest's multi_logloss: 0.124574\n",
      "[92]\tTrain's multi_logloss: 0.118163\tTest's multi_logloss: 0.124452\n",
      "[93]\tTrain's multi_logloss: 0.118026\tTest's multi_logloss: 0.124211\n",
      "[94]\tTrain's multi_logloss: 0.117887\tTest's multi_logloss: 0.123957\n",
      "[95]\tTrain's multi_logloss: 0.117647\tTest's multi_logloss: 0.123885\n",
      "[96]\tTrain's multi_logloss: 0.117439\tTest's multi_logloss: 0.123844\n",
      "[97]\tTrain's multi_logloss: 0.116237\tTest's multi_logloss: 0.12331\n",
      "[98]\tTrain's multi_logloss: 0.113687\tTest's multi_logloss: 0.121487\n",
      "[99]\tTrain's multi_logloss: 0.111734\tTest's multi_logloss: 0.121196\n",
      "[100]\tTrain's multi_logloss: 0.110287\tTest's multi_logloss: 0.121302\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's multi_logloss: 0.110287\tTest's multi_logloss: 0.121302\n",
      "[1]\tTrain's multi_logloss: 0.98328\tTest's multi_logloss: 1.01812\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.886068\tTest's multi_logloss: 0.923638\n",
      "[3]\tTrain's multi_logloss: 0.806136\tTest's multi_logloss: 0.840124\n",
      "[4]\tTrain's multi_logloss: 0.738204\tTest's multi_logloss: 0.76739\n",
      "[5]\tTrain's multi_logloss: 0.673435\tTest's multi_logloss: 0.698758\n",
      "[6]\tTrain's multi_logloss: 0.618042\tTest's multi_logloss: 0.643803\n",
      "[7]\tTrain's multi_logloss: 0.579512\tTest's multi_logloss: 0.602762\n",
      "[8]\tTrain's multi_logloss: 0.541942\tTest's multi_logloss: 0.560519\n",
      "[9]\tTrain's multi_logloss: 0.50902\tTest's multi_logloss: 0.523541\n",
      "[10]\tTrain's multi_logloss: 0.479709\tTest's multi_logloss: 0.49029\n",
      "[11]\tTrain's multi_logloss: 0.451772\tTest's multi_logloss: 0.457708\n",
      "[12]\tTrain's multi_logloss: 0.41981\tTest's multi_logloss: 0.426845\n",
      "[13]\tTrain's multi_logloss: 0.38711\tTest's multi_logloss: 0.391619\n",
      "[14]\tTrain's multi_logloss: 0.360036\tTest's multi_logloss: 0.361062\n",
      "[15]\tTrain's multi_logloss: 0.33605\tTest's multi_logloss: 0.337405\n",
      "[16]\tTrain's multi_logloss: 0.314882\tTest's multi_logloss: 0.316042\n",
      "[17]\tTrain's multi_logloss: 0.296366\tTest's multi_logloss: 0.298554\n",
      "[18]\tTrain's multi_logloss: 0.279474\tTest's multi_logloss: 0.277837\n",
      "[19]\tTrain's multi_logloss: 0.276265\tTest's multi_logloss: 0.274809\n",
      "[20]\tTrain's multi_logloss: 0.27193\tTest's multi_logloss: 0.27228\n",
      "[21]\tTrain's multi_logloss: 0.269333\tTest's multi_logloss: 0.26981\n",
      "[22]\tTrain's multi_logloss: 0.263206\tTest's multi_logloss: 0.263446\n",
      "[23]\tTrain's multi_logloss: 0.259777\tTest's multi_logloss: 0.261837\n",
      "[24]\tTrain's multi_logloss: 0.258897\tTest's multi_logloss: 0.262341\n",
      "[25]\tTrain's multi_logloss: 0.247457\tTest's multi_logloss: 0.245826\n",
      "[26]\tTrain's multi_logloss: 0.236249\tTest's multi_logloss: 0.231158\n",
      "[27]\tTrain's multi_logloss: 0.226714\tTest's multi_logloss: 0.216841\n",
      "[28]\tTrain's multi_logloss: 0.216557\tTest's multi_logloss: 0.205794\n",
      "[29]\tTrain's multi_logloss: 0.206354\tTest's multi_logloss: 0.195493\n",
      "[30]\tTrain's multi_logloss: 0.199405\tTest's multi_logloss: 0.185207\n",
      "[31]\tTrain's multi_logloss: 0.195665\tTest's multi_logloss: 0.182306\n",
      "[32]\tTrain's multi_logloss: 0.191523\tTest's multi_logloss: 0.179032\n",
      "[33]\tTrain's multi_logloss: 0.183112\tTest's multi_logloss: 0.173299\n",
      "[34]\tTrain's multi_logloss: 0.175619\tTest's multi_logloss: 0.168047\n",
      "[35]\tTrain's multi_logloss: 0.168943\tTest's multi_logloss: 0.163395\n",
      "[36]\tTrain's multi_logloss: 0.165183\tTest's multi_logloss: 0.161424\n",
      "[37]\tTrain's multi_logloss: 0.159443\tTest's multi_logloss: 0.152224\n",
      "[38]\tTrain's multi_logloss: 0.155382\tTest's multi_logloss: 0.148025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  40%|####      | 8/20 [00:00<00:00, 17.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  45%|####5     | 9/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,516]\u001b[0m Trial 51 finished with value: 0.11624590815749045 and parameters: {'lambda_l1': 3.678654245027904e-08, 'lambda_l2': 0.004365767526692536}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  45%|####5     | 9/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39]\tTrain's multi_logloss: 0.151994\tTest's multi_logloss: 0.144538\n",
      "[40]\tTrain's multi_logloss: 0.149248\tTest's multi_logloss: 0.141855\n",
      "[41]\tTrain's multi_logloss: 0.14533\tTest's multi_logloss: 0.135441\n",
      "[42]\tTrain's multi_logloss: 0.141951\tTest's multi_logloss: 0.129929\n",
      "[43]\tTrain's multi_logloss: 0.14056\tTest's multi_logloss: 0.128123\n",
      "[44]\tTrain's multi_logloss: 0.139352\tTest's multi_logloss: 0.126546\n",
      "[45]\tTrain's multi_logloss: 0.138238\tTest's multi_logloss: 0.125047\n",
      "[46]\tTrain's multi_logloss: 0.137272\tTest's multi_logloss: 0.123776\n",
      "[47]\tTrain's multi_logloss: 0.137\tTest's multi_logloss: 0.122931\n",
      "[48]\tTrain's multi_logloss: 0.135967\tTest's multi_logloss: 0.121824\n",
      "[49]\tTrain's multi_logloss: 0.133849\tTest's multi_logloss: 0.120438\n",
      "[50]\tTrain's multi_logloss: 0.131946\tTest's multi_logloss: 0.119225\n",
      "[51]\tTrain's multi_logloss: 0.129283\tTest's multi_logloss: 0.117384\n",
      "[52]\tTrain's multi_logloss: 0.127966\tTest's multi_logloss: 0.116965\n",
      "[53]\tTrain's multi_logloss: 0.12767\tTest's multi_logloss: 0.118188\n",
      "[54]\tTrain's multi_logloss: 0.126208\tTest's multi_logloss: 0.1173\n",
      "[55]\tTrain's multi_logloss: 0.123305\tTest's multi_logloss: 0.116396\n",
      "[56]\tTrain's multi_logloss: 0.12172\tTest's multi_logloss: 0.116376\n",
      "[57]\tTrain's multi_logloss: 0.120264\tTest's multi_logloss: 0.116469\n",
      "[58]\tTrain's multi_logloss: 0.120264\tTest's multi_logloss: 0.116469\n",
      "[59]\tTrain's multi_logloss: 0.118927\tTest's multi_logloss: 0.116666\n",
      "[60]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[61]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[62]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[63]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[64]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[65]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[66]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[67]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[68]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[69]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[70]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "Early stopping, best iteration is:\n",
      "[60]\tTrain's multi_logloss: 0.11822\tTest's multi_logloss: 0.116246\n",
      "[1]\tTrain's multi_logloss: 0.983745\tTest's multi_logloss: 1.01858\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.886903\tTest's multi_logloss: 0.924482\n",
      "[3]\tTrain's multi_logloss: 0.807246\tTest's multi_logloss: 0.841308\n",
      "[4]\tTrain's multi_logloss: 0.739531\tTest's multi_logloss: 0.768856\n",
      "[5]\tTrain's multi_logloss: 0.674942\tTest's multi_logloss: 0.700459\n",
      "[6]\tTrain's multi_logloss: 0.61973\tTest's multi_logloss: 0.645704\n",
      "[7]\tTrain's multi_logloss: 0.58135\tTest's multi_logloss: 0.604846\n",
      "[8]\tTrain's multi_logloss: 0.543914\tTest's multi_logloss: 0.562781\n",
      "[9]\tTrain's multi_logloss: 0.511099\tTest's multi_logloss: 0.525949\n",
      "[10]\tTrain's multi_logloss: 0.481879\tTest's multi_logloss: 0.492831\n",
      "[11]\tTrain's multi_logloss: 0.454049\tTest's multi_logloss: 0.460396\n",
      "[12]\tTrain's multi_logloss: 0.428184\tTest's multi_logloss: 0.430374\n",
      "[13]\tTrain's multi_logloss: 0.395106\tTest's multi_logloss: 0.395182\n",
      "[14]\tTrain's multi_logloss: 0.367772\tTest's multi_logloss: 0.364655\n",
      "[15]\tTrain's multi_logloss: 0.343552\tTest's multi_logloss: 0.341038\n",
      "[16]\tTrain's multi_logloss: 0.322176\tTest's multi_logloss: 0.319705\n",
      "[17]\tTrain's multi_logloss: 0.303267\tTest's multi_logloss: 0.301845\n",
      "[18]\tTrain's multi_logloss: 0.286206\tTest's multi_logloss: 0.281171\n",
      "[19]\tTrain's multi_logloss: 0.281662\tTest's multi_logloss: 0.278529\n",
      "[20]\tTrain's multi_logloss: 0.278088\tTest's multi_logloss: 0.276833\n",
      "[21]\tTrain's multi_logloss: 0.275626\tTest's multi_logloss: 0.275674\n",
      "[22]\tTrain's multi_logloss: 0.26945\tTest's multi_logloss: 0.269281\n",
      "[23]\tTrain's multi_logloss: 0.262657\tTest's multi_logloss: 0.263899\n",
      "[24]\tTrain's multi_logloss: 0.256618\tTest's multi_logloss: 0.258903\n",
      "[25]\tTrain's multi_logloss: 0.245617\tTest's multi_logloss: 0.242766\n",
      "[26]\tTrain's multi_logloss: 0.234869\tTest's multi_logloss: 0.228408\n",
      "[27]\tTrain's multi_logloss: 0.225673\tTest's multi_logloss: 0.214517\n",
      "[28]\tTrain's multi_logloss: 0.216265\tTest's multi_logloss: 0.20502\n",
      "[29]\tTrain's multi_logloss: 0.206225\tTest's multi_logloss: 0.194677\n",
      "[30]\tTrain's multi_logloss: 0.200124\tTest's multi_logloss: 0.185952\n",
      "[31]\tTrain's multi_logloss: 0.1966\tTest's multi_logloss: 0.183224\n",
      "[32]\tTrain's multi_logloss: 0.192955\tTest's multi_logloss: 0.180355\n",
      "[33]\tTrain's multi_logloss: 0.184788\tTest's multi_logloss: 0.174656\n",
      "[34]\tTrain's multi_logloss: 0.177473\tTest's multi_logloss: 0.169465\n",
      "[35]\tTrain's multi_logloss: 0.170942\tTest's multi_logloss: 0.164844\n",
      "[36]\tTrain's multi_logloss: 0.167453\tTest's multi_logloss: 0.163108\n",
      "[37]\tTrain's multi_logloss: 0.161723\tTest's multi_logloss: 0.153834\n",
      "[38]\tTrain's multi_logloss: 0.157735\tTest's multi_logloss: 0.14959\n",
      "[39]\tTrain's multi_logloss: 0.154445\tTest's multi_logloss: 0.146096\n",
      "[40]\tTrain's multi_logloss: 0.151833\tTest's multi_logloss: 0.143483\n",
      "[41]\tTrain's multi_logloss: 0.147999\tTest's multi_logloss: 0.13715\n",
      "[42]\tTrain's multi_logloss: 0.144726\tTest's multi_logloss: 0.131779\n",
      "[43]\tTrain's multi_logloss: 0.143563\tTest's multi_logloss: 0.130232\n",
      "[44]\tTrain's multi_logloss: 0.142548\tTest's multi_logloss: 0.128877\n",
      "[45]\tTrain's multi_logloss: 0.142574\tTest's multi_logloss: 0.128569\n",
      "[46]\tTrain's multi_logloss: 0.142653\tTest's multi_logloss: 0.128386\n",
      "[47]\tTrain's multi_logloss: 0.142186\tTest's multi_logloss: 0.127823\n",
      "[48]\tTrain's multi_logloss: 0.140517\tTest's multi_logloss: 0.124892\n",
      "[49]\tTrain's multi_logloss: 0.138665\tTest's multi_logloss: 0.124015\n",
      "[50]\tTrain's multi_logloss: 0.135796\tTest's multi_logloss: 0.121895\n",
      "[51]\tTrain's multi_logloss: 0.134249\tTest's multi_logloss: 0.121231\n",
      "[52]\tTrain's multi_logloss: 0.132838\tTest's multi_logloss: 0.120656\n",
      "[53]\tTrain's multi_logloss: 0.132495\tTest's multi_logloss: 0.121764\n",
      "[54]\tTrain's multi_logloss: 0.130921\tTest's multi_logloss: 0.120691\n",
      "[55]\tTrain's multi_logloss: 0.129808\tTest's multi_logloss: 0.12001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  45%|####5     | 9/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,567]\u001b[0m Trial 52 finished with value: 0.09832809290124873 and parameters: {'lambda_l1': 0.04872458798324643, 'lambda_l2': 3.367819582953625e-08}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  50%|#####     | 10/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56]\tTrain's multi_logloss: 0.129808\tTest's multi_logloss: 0.12001\n",
      "[57]\tTrain's multi_logloss: 0.129693\tTest's multi_logloss: 0.119804\n",
      "[58]\tTrain's multi_logloss: 0.12959\tTest's multi_logloss: 0.119617\n",
      "[59]\tTrain's multi_logloss: 0.128721\tTest's multi_logloss: 0.118638\n",
      "[60]\tTrain's multi_logloss: 0.12792\tTest's multi_logloss: 0.117734\n",
      "[61]\tTrain's multi_logloss: 0.127182\tTest's multi_logloss: 0.116901\n",
      "[62]\tTrain's multi_logloss: 0.124663\tTest's multi_logloss: 0.113338\n",
      "[63]\tTrain's multi_logloss: 0.122756\tTest's multi_logloss: 0.110944\n",
      "[64]\tTrain's multi_logloss: 0.120512\tTest's multi_logloss: 0.106295\n",
      "[65]\tTrain's multi_logloss: 0.116531\tTest's multi_logloss: 0.103287\n",
      "[66]\tTrain's multi_logloss: 0.112941\tTest's multi_logloss: 0.100644\n",
      "[67]\tTrain's multi_logloss: 0.109695\tTest's multi_logloss: 0.0983281\n",
      "[68]\tTrain's multi_logloss: 0.10897\tTest's multi_logloss: 0.0997446\n",
      "[69]\tTrain's multi_logloss: 0.108461\tTest's multi_logloss: 0.101333\n",
      "[70]\tTrain's multi_logloss: 0.10816\tTest's multi_logloss: 0.102856\n",
      "[71]\tTrain's multi_logloss: 0.107108\tTest's multi_logloss: 0.102526\n",
      "[72]\tTrain's multi_logloss: 0.107088\tTest's multi_logloss: 0.104119\n",
      "[73]\tTrain's multi_logloss: 0.107046\tTest's multi_logloss: 0.105415\n",
      "[74]\tTrain's multi_logloss: 0.107046\tTest's multi_logloss: 0.105415\n",
      "[75]\tTrain's multi_logloss: 0.105587\tTest's multi_logloss: 0.104533\n",
      "[76]\tTrain's multi_logloss: 0.104482\tTest's multi_logloss: 0.103923\n",
      "[77]\tTrain's multi_logloss: 0.104534\tTest's multi_logloss: 0.101595\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.109695\tTest's multi_logloss: 0.0983281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  50%|#####     | 10/20 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  55%|#####5    | 11/20 [00:00<00:00, 18.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,623]\u001b[0m Trial 53 finished with value: 0.7709246824043521 and parameters: {'lambda_l1': 7.973012726933501, 'lambda_l2': 2.953530096255426e-05}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  55%|#####5    | 11/20 [00:00<00:00, 18.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 1.19111\tTest's multi_logloss: 1.33202\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 1.15818\tTest's multi_logloss: 1.29646\n",
      "[3]\tTrain's multi_logloss: 1.12856\tTest's multi_logloss: 1.26376\n",
      "[4]\tTrain's multi_logloss: 1.10212\tTest's multi_logloss: 1.23426\n",
      "[5]\tTrain's multi_logloss: 1.07866\tTest's multi_logloss: 1.208\n",
      "[6]\tTrain's multi_logloss: 1.05788\tTest's multi_logloss: 1.18489\n",
      "[7]\tTrain's multi_logloss: 1.03154\tTest's multi_logloss: 1.15301\n",
      "[8]\tTrain's multi_logloss: 1.01627\tTest's multi_logloss: 1.13623\n",
      "[9]\tTrain's multi_logloss: 0.995214\tTest's multi_logloss: 1.11061\n",
      "[10]\tTrain's multi_logloss: 0.983559\tTest's multi_logloss: 1.09804\n",
      "[11]\tTrain's multi_logloss: 0.973795\tTest's multi_logloss: 1.08741\n",
      "[12]\tTrain's multi_logloss: 0.964379\tTest's multi_logloss: 1.0774\n",
      "[13]\tTrain's multi_logloss: 0.957007\tTest's multi_logloss: 1.07029\n",
      "[14]\tTrain's multi_logloss: 0.949952\tTest's multi_logloss: 1.06316\n",
      "[15]\tTrain's multi_logloss: 0.943353\tTest's multi_logloss: 1.05656\n",
      "[16]\tTrain's multi_logloss: 0.937137\tTest's multi_logloss: 1.05033\n",
      "[17]\tTrain's multi_logloss: 0.932359\tTest's multi_logloss: 1.04567\n",
      "[18]\tTrain's multi_logloss: 0.926724\tTest's multi_logloss: 1.03996\n",
      "[19]\tTrain's multi_logloss: 0.926724\tTest's multi_logloss: 1.03996\n",
      "[20]\tTrain's multi_logloss: 0.914959\tTest's multi_logloss: 1.0241\n",
      "[21]\tTrain's multi_logloss: 0.904434\tTest's multi_logloss: 1.00993\n",
      "[22]\tTrain's multi_logloss: 0.898719\tTest's multi_logloss: 1.00209\n",
      "[23]\tTrain's multi_logloss: 0.89086\tTest's multi_logloss: 0.991154\n",
      "[24]\tTrain's multi_logloss: 0.885119\tTest's multi_logloss: 0.983437\n",
      "[25]\tTrain's multi_logloss: 0.878618\tTest's multi_logloss: 0.97439\n",
      "[26]\tTrain's multi_logloss: 0.87738\tTest's multi_logloss: 0.973098\n",
      "[27]\tTrain's multi_logloss: 0.876228\tTest's multi_logloss: 0.971894\n",
      "[28]\tTrain's multi_logloss: 0.875118\tTest's multi_logloss: 0.970737\n",
      "[29]\tTrain's multi_logloss: 0.874074\tTest's multi_logloss: 0.969648\n",
      "[30]\tTrain's multi_logloss: 0.874074\tTest's multi_logloss: 0.969648\n",
      "[31]\tTrain's multi_logloss: 0.873091\tTest's multi_logloss: 0.968624\n",
      "[32]\tTrain's multi_logloss: 0.873037\tTest's multi_logloss: 0.968569\n",
      "[33]\tTrain's multi_logloss: 0.866756\tTest's multi_logloss: 0.962114\n",
      "[34]\tTrain's multi_logloss: 0.860826\tTest's multi_logloss: 0.95602\n",
      "[35]\tTrain's multi_logloss: 0.855228\tTest's multi_logloss: 0.950264\n",
      "[36]\tTrain's multi_logloss: 0.849942\tTest's multi_logloss: 0.944829\n",
      "[37]\tTrain's multi_logloss: 0.844104\tTest's multi_logloss: 0.939131\n",
      "[38]\tTrain's multi_logloss: 0.83874\tTest's multi_logloss: 0.933402\n",
      "[39]\tTrain's multi_logloss: 0.83874\tTest's multi_logloss: 0.933402\n",
      "[40]\tTrain's multi_logloss: 0.83874\tTest's multi_logloss: 0.933402\n",
      "[41]\tTrain's multi_logloss: 0.83874\tTest's multi_logloss: 0.933402\n",
      "[42]\tTrain's multi_logloss: 0.833702\tTest's multi_logloss: 0.927276\n",
      "[43]\tTrain's multi_logloss: 0.827169\tTest's multi_logloss: 0.917781\n",
      "[44]\tTrain's multi_logloss: 0.822689\tTest's multi_logloss: 0.912135\n",
      "[45]\tTrain's multi_logloss: 0.817523\tTest's multi_logloss: 0.90631\n",
      "[46]\tTrain's multi_logloss: 0.811948\tTest's multi_logloss: 0.899765\n",
      "[47]\tTrain's multi_logloss: 0.803611\tTest's multi_logloss: 0.888426\n",
      "[48]\tTrain's multi_logloss: 0.803344\tTest's multi_logloss: 0.888144\n",
      "[49]\tTrain's multi_logloss: 0.803344\tTest's multi_logloss: 0.888144\n",
      "[50]\tTrain's multi_logloss: 0.803344\tTest's multi_logloss: 0.888144\n",
      "[51]\tTrain's multi_logloss: 0.803344\tTest's multi_logloss: 0.888144\n",
      "[52]\tTrain's multi_logloss: 0.803095\tTest's multi_logloss: 0.887881\n",
      "[53]\tTrain's multi_logloss: 0.802863\tTest's multi_logloss: 0.887636\n",
      "[54]\tTrain's multi_logloss: 0.802646\tTest's multi_logloss: 0.887407\n",
      "[55]\tTrain's multi_logloss: 0.802444\tTest's multi_logloss: 0.887194\n",
      "[56]\tTrain's multi_logloss: 0.802255\tTest's multi_logloss: 0.886995\n",
      "[57]\tTrain's multi_logloss: 0.802255\tTest's multi_logloss: 0.886995\n",
      "[58]\tTrain's multi_logloss: 0.802248\tTest's multi_logloss: 0.886988\n",
      "[59]\tTrain's multi_logloss: 0.802241\tTest's multi_logloss: 0.886981\n",
      "[60]\tTrain's multi_logloss: 0.802235\tTest's multi_logloss: 0.886975\n",
      "[61]\tTrain's multi_logloss: 0.802229\tTest's multi_logloss: 0.886969\n",
      "[62]\tTrain's multi_logloss: 0.802224\tTest's multi_logloss: 0.886963\n",
      "[63]\tTrain's multi_logloss: 0.802219\tTest's multi_logloss: 0.886958\n",
      "[64]\tTrain's multi_logloss: 0.801859\tTest's multi_logloss: 0.88661\n",
      "[65]\tTrain's multi_logloss: 0.800244\tTest's multi_logloss: 0.884911\n",
      "[66]\tTrain's multi_logloss: 0.799699\tTest's multi_logloss: 0.88427\n",
      "[67]\tTrain's multi_logloss: 0.799192\tTest's multi_logloss: 0.883672\n",
      "[68]\tTrain's multi_logloss: 0.797933\tTest's multi_logloss: 0.882436\n",
      "[69]\tTrain's multi_logloss: 0.797459\tTest's multi_logloss: 0.881878\n",
      "[70]\tTrain's multi_logloss: 0.797459\tTest's multi_logloss: 0.881878\n",
      "[71]\tTrain's multi_logloss: 0.797434\tTest's multi_logloss: 0.881847\n",
      "[72]\tTrain's multi_logloss: 0.79741\tTest's multi_logloss: 0.881818\n",
      "[73]\tTrain's multi_logloss: 0.797388\tTest's multi_logloss: 0.881791\n",
      "[74]\tTrain's multi_logloss: 0.797367\tTest's multi_logloss: 0.881766\n",
      "[75]\tTrain's multi_logloss: 0.797348\tTest's multi_logloss: 0.881742\n",
      "[76]\tTrain's multi_logloss: 0.79733\tTest's multi_logloss: 0.88172\n",
      "[77]\tTrain's multi_logloss: 0.786633\tTest's multi_logloss: 0.869021\n",
      "[78]\tTrain's multi_logloss: 0.776209\tTest's multi_logloss: 0.855742\n",
      "[79]\tTrain's multi_logloss: 0.766874\tTest's multi_logloss: 0.843871\n",
      "[80]\tTrain's multi_logloss: 0.757818\tTest's multi_logloss: 0.832464\n",
      "[81]\tTrain's multi_logloss: 0.750356\tTest's multi_logloss: 0.823058\n",
      "[82]\tTrain's multi_logloss: 0.743544\tTest's multi_logloss: 0.814422\n",
      "[83]\tTrain's multi_logloss: 0.743544\tTest's multi_logloss: 0.814422\n",
      "[84]\tTrain's multi_logloss: 0.743024\tTest's multi_logloss: 0.813886\n",
      "[85]\tTrain's multi_logloss: 0.742539\tTest's multi_logloss: 0.813386\n",
      "[86]\tTrain's multi_logloss: 0.742098\tTest's multi_logloss: 0.812946\n",
      "[87]\tTrain's multi_logloss: 0.741687\tTest's multi_logloss: 0.812535\n",
      "[88]\tTrain's multi_logloss: 0.741293\tTest's multi_logloss: 0.812129\n",
      "[89]\tTrain's multi_logloss: 0.740926\tTest's multi_logloss: 0.81175\n",
      "[90]\tTrain's multi_logloss: 0.734928\tTest's multi_logloss: 0.805135\n",
      "[91]\tTrain's multi_logloss: 0.729449\tTest's multi_logloss: 0.799153\n",
      "[92]\tTrain's multi_logloss: 0.72403\tTest's multi_logloss: 0.793135\n",
      "[93]\tTrain's multi_logloss: 0.718887\tTest's multi_logloss: 0.78741\n",
      "[94]\tTrain's multi_logloss: 0.714005\tTest's multi_logloss: 0.781961\n",
      "[95]\tTrain's multi_logloss: 0.709371\tTest's multi_logloss: 0.776777\n",
      "[96]\tTrain's multi_logloss: 0.708325\tTest's multi_logloss: 0.77514\n",
      "[97]\tTrain's multi_logloss: 0.707359\tTest's multi_logloss: 0.773625\n",
      "[98]\tTrain's multi_logloss: 0.707359\tTest's multi_logloss: 0.773625\n",
      "[99]\tTrain's multi_logloss: 0.706465\tTest's multi_logloss: 0.772223\n",
      "[100]\tTrain's multi_logloss: 0.705638\tTest's multi_logloss: 0.770925\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's multi_logloss: 0.705638\tTest's multi_logloss: 0.770925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.985969\tTest's multi_logloss: 1.02077\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.890873\tTest's multi_logloss: 0.928459\n",
      "[3]\tTrain's multi_logloss: 0.812498\tTest's multi_logloss: 0.846855\n",
      "[4]\tTrain's multi_logloss: 0.745782\tTest's multi_logloss: 0.775695\n",
      "[5]\tTrain's multi_logloss: 0.682028\tTest's multi_logloss: 0.708378\n",
      "[6]\tTrain's multi_logloss: 0.627643\tTest's multi_logloss: 0.654536\n",
      "[7]\tTrain's multi_logloss: 0.587285\tTest's multi_logloss: 0.611834\n",
      "[8]\tTrain's multi_logloss: 0.550748\tTest's multi_logloss: 0.570996\n",
      "[9]\tTrain's multi_logloss: 0.518355\tTest's multi_logloss: 0.534451\n",
      "[10]\tTrain's multi_logloss: 0.489771\tTest's multi_logloss: 0.502268\n",
      "[11]\tTrain's multi_logloss: 0.462598\tTest's multi_logloss: 0.470745\n",
      "[12]\tTrain's multi_logloss: 0.437193\tTest's multi_logloss: 0.441411\n",
      "[13]\tTrain's multi_logloss: 0.404779\tTest's multi_logloss: 0.406999\n",
      "[14]\tTrain's multi_logloss: 0.377828\tTest's multi_logloss: 0.377048\n",
      "[15]\tTrain's multi_logloss: 0.35401\tTest's multi_logloss: 0.353773\n",
      "[16]\tTrain's multi_logloss: 0.332942\tTest's multi_logloss: 0.332714\n",
      "[17]\tTrain's multi_logloss: 0.314313\tTest's multi_logloss: 0.315172\n",
      "[18]\tTrain's multi_logloss: 0.297359\tTest's multi_logloss: 0.294838\n",
      "[19]\tTrain's multi_logloss: 0.293153\tTest's multi_logloss: 0.292308\n",
      "[20]\tTrain's multi_logloss: 0.288681\tTest's multi_logloss: 0.289904\n",
      "[21]\tTrain's multi_logloss: 0.28644\tTest's multi_logloss: 0.2888\n",
      "[22]\tTrain's multi_logloss: 0.284791\tTest's multi_logloss: 0.287005\n",
      "[23]\tTrain's multi_logloss: 0.282403\tTest's multi_logloss: 0.285773\n",
      "[24]\tTrain's multi_logloss: 0.273387\tTest's multi_logloss: 0.276895\n",
      "[25]\tTrain's multi_logloss: 0.262239\tTest's multi_logloss: 0.260989\n",
      "[26]\tTrain's multi_logloss: 0.251342\tTest's multi_logloss: 0.246771\n",
      "[27]\tTrain's multi_logloss: 0.242376\tTest's multi_logloss: 0.234038\n",
      "[28]\tTrain's multi_logloss: 0.23232\tTest's multi_logloss: 0.223106\n",
      "[29]\tTrain's multi_logloss: 0.222356\tTest's multi_logloss: 0.212977\n",
      "[30]\tTrain's multi_logloss: 0.215946\tTest's multi_logloss: 0.20409\n",
      "[31]\tTrain's multi_logloss: 0.212819\tTest's multi_logloss: 0.201838\n",
      "[32]\tTrain's multi_logloss: 0.209153\tTest's multi_logloss: 0.19901\n",
      "[33]\tTrain's multi_logloss: 0.20608\tTest's multi_logloss: 0.196238\n",
      "[34]\tTrain's multi_logloss: 0.201314\tTest's multi_logloss: 0.191683\n",
      "[35]\tTrain's multi_logloss: 0.197046\tTest's multi_logloss: 0.187558\n",
      "[36]\tTrain's multi_logloss: 0.193937\tTest's multi_logloss: 0.184446\n",
      "[37]\tTrain's multi_logloss: 0.187604\tTest's multi_logloss: 0.174687\n",
      "[38]\tTrain's multi_logloss: 0.183627\tTest's multi_logloss: 0.170056\n",
      "[39]\tTrain's multi_logloss: 0.180285\tTest's multi_logloss: 0.166164\n",
      "[40]\tTrain's multi_logloss: 0.17755\tTest's multi_logloss: 0.163099\n",
      "[41]\tTrain's multi_logloss: 0.173106\tTest's multi_logloss: 0.15633\n",
      "[42]\tTrain's multi_logloss: 0.16923\tTest's multi_logloss: 0.150495\n",
      "[43]\tTrain's multi_logloss: 0.167798\tTest's multi_logloss: 0.149206\n",
      "[44]\tTrain's multi_logloss: 0.165737\tTest's multi_logloss: 0.146143\n",
      "[45]\tTrain's multi_logloss: 0.16386\tTest's multi_logloss: 0.143336\n",
      "[46]\tTrain's multi_logloss: 0.16215\tTest's multi_logloss: 0.14076\n",
      "[47]\tTrain's multi_logloss: 0.161216\tTest's multi_logloss: 0.139058\n",
      "[48]\tTrain's multi_logloss: 0.15975\tTest's multi_logloss: 0.136703\n",
      "[49]\tTrain's multi_logloss: 0.158686\tTest's multi_logloss: 0.137472\n",
      "[50]\tTrain's multi_logloss: 0.158662\tTest's multi_logloss: 0.13745\n",
      "[51]\tTrain's multi_logloss: 0.158688\tTest's multi_logloss: 0.138441\n",
      "[52]\tTrain's multi_logloss: 0.158808\tTest's multi_logloss: 0.139465\n",
      "[53]\tTrain's multi_logloss: 0.158968\tTest's multi_logloss: 0.140474\n",
      "[54]\tTrain's multi_logloss: 0.158968\tTest's multi_logloss: 0.140474\n",
      "[55]\tTrain's multi_logloss: 0.158696\tTest's multi_logloss: 0.14247\n",
      "[56]\tTrain's multi_logloss: 0.158696\tTest's multi_logloss: 0.14247\n",
      "[57]\tTrain's multi_logloss: 0.152158\tTest's multi_logloss: 0.13691\n",
      "[58]\tTrain's multi_logloss: 0.149372\tTest's multi_logloss: 0.132675\n",
      "[59]\tTrain's multi_logloss: 0.143825\tTest's multi_logloss: 0.128034\n",
      "[60]\tTrain's multi_logloss: 0.138638\tTest's multi_logloss: 0.124938\n",
      "[61]\tTrain's multi_logloss: 0.136126\tTest's multi_logloss: 0.12048\n",
      "[62]\tTrain's multi_logloss: 0.134408\tTest's multi_logloss: 0.117638\n",
      "[63]\tTrain's multi_logloss: 0.131514\tTest's multi_logloss: 0.116195\n",
      "[64]\tTrain's multi_logloss: 0.130141\tTest's multi_logloss: 0.115772\n",
      "[65]\tTrain's multi_logloss: 0.127525\tTest's multi_logloss: 0.114526\n",
      "[66]\tTrain's multi_logloss: 0.125195\tTest's multi_logloss: 0.113513\n",
      "[67]\tTrain's multi_logloss: 0.123109\tTest's multi_logloss: 0.112696\n",
      "[68]\tTrain's multi_logloss: 0.122731\tTest's multi_logloss: 0.113086\n",
      "[69]\tTrain's multi_logloss: 0.122731\tTest's multi_logloss: 0.113086\n",
      "[70]\tTrain's multi_logloss: 0.122237\tTest's multi_logloss: 0.111036\n",
      "[71]\tTrain's multi_logloss: 0.120785\tTest's multi_logloss: 0.11016\n",
      "[72]\tTrain's multi_logloss: 0.119313\tTest's multi_logloss: 0.109749\n",
      "[73]\tTrain's multi_logloss: 0.118284\tTest's multi_logloss: 0.10913\n",
      "[74]\tTrain's multi_logloss: 0.117172\tTest's multi_logloss: 0.108904\n",
      "[75]\tTrain's multi_logloss: 0.116352\tTest's multi_logloss: 0.108479\n",
      "[76]\tTrain's multi_logloss: 0.11377\tTest's multi_logloss: 0.110399\n",
      "[77]\tTrain's multi_logloss: 0.111918\tTest's multi_logloss: 0.112338\n",
      "[78]\tTrain's multi_logloss: 0.108728\tTest's multi_logloss: 0.111147\n",
      "[79]\tTrain's multi_logloss: 0.107356\tTest's multi_logloss: 0.113292\n",
      "[80]\tTrain's multi_logloss: 0.104645\tTest's multi_logloss: 0.113373\n",
      "[81]\tTrain's multi_logloss: 0.10355\tTest's multi_logloss: 0.113979\n",
      "[82]\tTrain's multi_logloss: 0.102609\tTest's multi_logloss: 0.115115\n",
      "[83]\tTrain's multi_logloss: 0.102182\tTest's multi_logloss: 0.11447\n",
      "[84]\tTrain's multi_logloss: 0.10191\tTest's multi_logloss: 0.114795\n",
      "[85]\tTrain's multi_logloss: 0.101503\tTest's multi_logloss: 0.114825\n",
      "Early stopping, best iteration is:\n",
      "[75]\tTrain's multi_logloss: 0.116352\tTest's multi_logloss: 0.108479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  55%|#####5    | 11/20 [00:00<00:00, 18.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,702]\u001b[0m Trial 54 finished with value: 0.10847945063445535 and parameters: {'lambda_l1': 0.2556013198786153, 'lambda_l2': 1.3864927876603123e-07}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  60%|######    | 12/20 [00:00<00:00, 18.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  60%|######    | 12/20 [00:00<00:00, 18.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  65%|######5   | 13/20 [00:00<00:00, 17.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.983226\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.885977\tTest's multi_logloss: 0.923555\n",
      "[3]\tTrain's multi_logloss: 0.806024\tTest's multi_logloss: 0.840016\n",
      "[4]\tTrain's multi_logloss: 0.738077\tTest's multi_logloss: 0.767264\n",
      "[5]\tTrain's multi_logloss: 0.673295\tTest's multi_logloss: 0.698617\n",
      "[6]\tTrain's multi_logloss: 0.617892\tTest's multi_logloss: 0.64365\n",
      "[7]\tTrain's multi_logloss: 0.579356\tTest's multi_logloss: 0.602601\n",
      "[8]\tTrain's multi_logloss: 0.541782\tTest's multi_logloss: 0.56035\n",
      "[9]\tTrain's multi_logloss: 0.508858\tTest's multi_logloss: 0.523367\n",
      "[10]\tTrain's multi_logloss: 0.479545\tTest's multi_logloss: 0.490113\n",
      "[11]\tTrain's multi_logloss: 0.451605\tTest's multi_logloss: 0.457527\n",
      "[12]\tTrain's multi_logloss: 0.419636\tTest's multi_logloss: 0.426659\n",
      "[13]\tTrain's multi_logloss: 0.38693\tTest's multi_logloss: 0.391425\n",
      "[14]\tTrain's multi_logloss: 0.359854\tTest's multi_logloss: 0.360864\n",
      "[15]\tTrain's multi_logloss: 0.335866\tTest's multi_logloss: 0.337203\n",
      "[16]\tTrain's multi_logloss: 0.314697\tTest's multi_logloss: 0.315836\n",
      "[17]\tTrain's multi_logloss: 0.296183\tTest's multi_logloss: 0.298349\n",
      "[18]\tTrain's multi_logloss: 0.279292\tTest's multi_logloss: 0.277631\n",
      "[19]\tTrain's multi_logloss: 0.276082\tTest's multi_logloss: 0.274601\n",
      "[20]\tTrain's multi_logloss: 0.27175\tTest's multi_logloss: 0.272072\n",
      "[21]\tTrain's multi_logloss: 0.269153\tTest's multi_logloss: 0.269603\n",
      "[22]\tTrain's multi_logloss: 0.263023\tTest's multi_logloss: 0.263235\n",
      "[23]\tTrain's multi_logloss: 0.259596\tTest's multi_logloss: 0.261628\n",
      "[24]\tTrain's multi_logloss: 0.258718\tTest's multi_logloss: 0.262132\n",
      "[25]\tTrain's multi_logloss: 0.247277\tTest's multi_logloss: 0.245614\n",
      "[26]\tTrain's multi_logloss: 0.23607\tTest's multi_logloss: 0.230945\n",
      "[27]\tTrain's multi_logloss: 0.226537\tTest's multi_logloss: 0.21663\n",
      "[28]\tTrain's multi_logloss: 0.216379\tTest's multi_logloss: 0.205584\n",
      "[29]\tTrain's multi_logloss: 0.206178\tTest's multi_logloss: 0.195286\n",
      "[30]\tTrain's multi_logloss: 0.199231\tTest's multi_logloss: 0.185003\n",
      "[31]\tTrain's multi_logloss: 0.195493\tTest's multi_logloss: 0.182104\n",
      "[32]\tTrain's multi_logloss: 0.191352\tTest's multi_logloss: 0.178831\n",
      "[33]\tTrain's multi_logloss: 0.18294\tTest's multi_logloss: 0.173098\n",
      "[34]\tTrain's multi_logloss: 0.175446\tTest's multi_logloss: 0.167848\n",
      "[35]\tTrain's multi_logloss: 0.16877\tTest's multi_logloss: 0.163198\n",
      "[36]\tTrain's multi_logloss: 0.165008\tTest's multi_logloss: 0.16123\n",
      "[37]\tTrain's multi_logloss: 0.159269\tTest's multi_logloss: 0.152031\n",
      "[38]\tTrain's multi_logloss: 0.155205\tTest's multi_logloss: 0.147833\n",
      "[39]\tTrain's multi_logloss: 0.151817\tTest's multi_logloss: 0.144349\n",
      "[40]\tTrain's multi_logloss: 0.14907\tTest's multi_logloss: 0.141669\n",
      "[41]\tTrain's multi_logloss: 0.145155\tTest's multi_logloss: 0.135257\n",
      "[42]\tTrain's multi_logloss: 0.14178\tTest's multi_logloss: 0.129749\n",
      "[43]\tTrain's multi_logloss: 0.140388\tTest's multi_logloss: 0.127942\n",
      "[44]\tTrain's multi_logloss: 0.13918\tTest's multi_logloss: 0.126365\n",
      "[45]\tTrain's multi_logloss: 0.138066\tTest's multi_logloss: 0.124864\n",
      "[46]\tTrain's multi_logloss: 0.1371\tTest's multi_logloss: 0.123594\n",
      "[47]\tTrain's multi_logloss: 0.136828\tTest's multi_logloss: 0.122748\n",
      "[48]\tTrain's multi_logloss: 0.135796\tTest's multi_logloss: 0.121642\n",
      "[49]\tTrain's multi_logloss: 0.133678\tTest's multi_logloss: 0.120256\n",
      "[50]\tTrain's multi_logloss: 0.131775\tTest's multi_logloss: 0.119044\n",
      "[51]\tTrain's multi_logloss: 0.12911\tTest's multi_logloss: 0.117203\n",
      "[52]\tTrain's multi_logloss: 0.127794\tTest's multi_logloss: 0.116785\n",
      "[53]\tTrain's multi_logloss: 0.127495\tTest's multi_logloss: 0.11801\n",
      "[54]\tTrain's multi_logloss: 0.126034\tTest's multi_logloss: 0.117124\n",
      "[55]\tTrain's multi_logloss: 0.123129\tTest's multi_logloss: 0.116221\n",
      "[56]\tTrain's multi_logloss: 0.121544\tTest's multi_logloss: 0.116203\n",
      "[57]\tTrain's multi_logloss: 0.120089\tTest's multi_logloss: 0.116299\n",
      "[58]\tTrain's multi_logloss: 0.120089\tTest's multi_logloss: 0.116299\n",
      "[59]\tTrain's multi_logloss: 0.118751\tTest's multi_logloss: 0.116499\n",
      "[60]\tTrain's multi_logloss: 0.118048\tTest's multi_logloss: 0.116082\n",
      "[61]\tTrain's multi_logloss: 0.118339\tTest's multi_logloss: 0.116769\n",
      "[62]\tTrain's multi_logloss: 0.116202\tTest's multi_logloss: 0.11352\n",
      "[63]\tTrain's multi_logloss: 0.11419\tTest's multi_logloss: 0.111016\n",
      "[64]\tTrain's multi_logloss: 0.112092\tTest's multi_logloss: 0.106114\n",
      "[65]\tTrain's multi_logloss: 0.110343\tTest's multi_logloss: 0.101811\n",
      "[66]\tTrain's multi_logloss: 0.108692\tTest's multi_logloss: 0.100072\n",
      "[67]\tTrain's multi_logloss: 0.107337\tTest's multi_logloss: 0.0964484\n",
      "[68]\tTrain's multi_logloss: 0.106766\tTest's multi_logloss: 0.0970682\n",
      "[69]\tTrain's multi_logloss: 0.106279\tTest's multi_logloss: 0.0986659\n",
      "[70]\tTrain's multi_logloss: 0.105995\tTest's multi_logloss: 0.100188\n",
      "[71]\tTrain's multi_logloss: 0.104872\tTest's multi_logloss: 0.0997322\n",
      "[72]\tTrain's multi_logloss: 0.104835\tTest's multi_logloss: 0.101351\n",
      "[73]\tTrain's multi_logloss: 0.104783\tTest's multi_logloss: 0.102617\n",
      "[74]\tTrain's multi_logloss: 0.104783\tTest's multi_logloss: 0.102617\n",
      "[75]\tTrain's multi_logloss: 0.10326\tTest's multi_logloss: 0.101629\n",
      "[76]\tTrain's multi_logloss: 0.102122\tTest's multi_logloss: 0.100957\n",
      "[77]\tTrain's multi_logloss: 0.10234\tTest's multi_logloss: 0.0985752\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107337\tTest's multi_logloss: 0.0964484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-05 17:55:44,754]\u001b[0m Trial 55 finished with value: 0.09644842882791885 and parameters: {'lambda_l1': 0.00038072041899420833, 'lambda_l2': 3.2054861595547832e-06}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  65%|######5   | 13/20 [00:00<00:00, 17.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.983224\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.885974\tTest's multi_logloss: 0.923551\n",
      "[3]\tTrain's multi_logloss: 0.806019\tTest's multi_logloss: 0.840011\n",
      "[4]\tTrain's multi_logloss: 0.738071\tTest's multi_logloss: 0.767257\n",
      "[5]\tTrain's multi_logloss: 0.673288\tTest's multi_logloss: 0.69861\n",
      "[6]\tTrain's multi_logloss: 0.617885\tTest's multi_logloss: 0.643641\n",
      "[7]\tTrain's multi_logloss: 0.579348\tTest's multi_logloss: 0.602591\n",
      "[8]\tTrain's multi_logloss: 0.541773\tTest's multi_logloss: 0.56034\n",
      "[9]\tTrain's multi_logloss: 0.508849\tTest's multi_logloss: 0.523357\n",
      "[10]\tTrain's multi_logloss: 0.479536\tTest's multi_logloss: 0.490102\n",
      "[11]\tTrain's multi_logloss: 0.451595\tTest's multi_logloss: 0.457515\n",
      "[12]\tTrain's multi_logloss: 0.419625\tTest's multi_logloss: 0.426647\n",
      "[13]\tTrain's multi_logloss: 0.386919\tTest's multi_logloss: 0.391412\n",
      "[14]\tTrain's multi_logloss: 0.359843\tTest's multi_logloss: 0.360851\n",
      "[15]\tTrain's multi_logloss: 0.335854\tTest's multi_logloss: 0.337189\n",
      "[16]\tTrain's multi_logloss: 0.314686\tTest's multi_logloss: 0.315822\n",
      "[17]\tTrain's multi_logloss: 0.296171\tTest's multi_logloss: 0.298336\n",
      "[18]\tTrain's multi_logloss: 0.27928\tTest's multi_logloss: 0.277617\n",
      "[19]\tTrain's multi_logloss: 0.27607\tTest's multi_logloss: 0.274587\n",
      "[20]\tTrain's multi_logloss: 0.271737\tTest's multi_logloss: 0.272058\n",
      "[21]\tTrain's multi_logloss: 0.269141\tTest's multi_logloss: 0.269589\n",
      "[22]\tTrain's multi_logloss: 0.26301\tTest's multi_logloss: 0.26322\n",
      "[23]\tTrain's multi_logloss: 0.259583\tTest's multi_logloss: 0.261613\n",
      "[24]\tTrain's multi_logloss: 0.258705\tTest's multi_logloss: 0.262117\n",
      "[25]\tTrain's multi_logloss: 0.247264\tTest's multi_logloss: 0.245599\n",
      "[26]\tTrain's multi_logloss: 0.236057\tTest's multi_logloss: 0.23093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  65%|######5   | 13/20 [00:00<00:00, 17.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,805]\u001b[0m Trial 56 finished with value: 0.09643350259497385 and parameters: {'lambda_l1': 0.00018008375648829672, 'lambda_l2': 5.787493117517493e-06}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  70%|#######   | 14/20 [00:00<00:00, 17.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\tTrain's multi_logloss: 0.226524\tTest's multi_logloss: 0.216614\n",
      "[28]\tTrain's multi_logloss: 0.216366\tTest's multi_logloss: 0.205568\n",
      "[29]\tTrain's multi_logloss: 0.206164\tTest's multi_logloss: 0.19527\n",
      "[30]\tTrain's multi_logloss: 0.199218\tTest's multi_logloss: 0.184987\n",
      "[31]\tTrain's multi_logloss: 0.19548\tTest's multi_logloss: 0.182088\n",
      "[32]\tTrain's multi_logloss: 0.191339\tTest's multi_logloss: 0.178815\n",
      "[33]\tTrain's multi_logloss: 0.182926\tTest's multi_logloss: 0.173083\n",
      "[34]\tTrain's multi_logloss: 0.175432\tTest's multi_logloss: 0.167833\n",
      "[35]\tTrain's multi_logloss: 0.168757\tTest's multi_logloss: 0.163183\n",
      "[36]\tTrain's multi_logloss: 0.164994\tTest's multi_logloss: 0.161215\n",
      "[37]\tTrain's multi_logloss: 0.159255\tTest's multi_logloss: 0.152015\n",
      "[38]\tTrain's multi_logloss: 0.155191\tTest's multi_logloss: 0.147818\n",
      "[39]\tTrain's multi_logloss: 0.151802\tTest's multi_logloss: 0.144334\n",
      "[40]\tTrain's multi_logloss: 0.149056\tTest's multi_logloss: 0.141654\n",
      "[41]\tTrain's multi_logloss: 0.145141\tTest's multi_logloss: 0.135243\n",
      "[42]\tTrain's multi_logloss: 0.141766\tTest's multi_logloss: 0.129734\n",
      "[43]\tTrain's multi_logloss: 0.140373\tTest's multi_logloss: 0.127927\n",
      "[44]\tTrain's multi_logloss: 0.139166\tTest's multi_logloss: 0.12635\n",
      "[45]\tTrain's multi_logloss: 0.138052\tTest's multi_logloss: 0.124849\n",
      "[46]\tTrain's multi_logloss: 0.137086\tTest's multi_logloss: 0.123579\n",
      "[47]\tTrain's multi_logloss: 0.136814\tTest's multi_logloss: 0.122732\n",
      "[48]\tTrain's multi_logloss: 0.135782\tTest's multi_logloss: 0.121626\n",
      "[49]\tTrain's multi_logloss: 0.133663\tTest's multi_logloss: 0.12024\n",
      "[50]\tTrain's multi_logloss: 0.131761\tTest's multi_logloss: 0.119028\n",
      "[51]\tTrain's multi_logloss: 0.129095\tTest's multi_logloss: 0.117186\n",
      "[52]\tTrain's multi_logloss: 0.127779\tTest's multi_logloss: 0.116769\n",
      "[53]\tTrain's multi_logloss: 0.12748\tTest's multi_logloss: 0.117994\n",
      "[54]\tTrain's multi_logloss: 0.126018\tTest's multi_logloss: 0.117108\n",
      "[55]\tTrain's multi_logloss: 0.123114\tTest's multi_logloss: 0.116205\n",
      "[56]\tTrain's multi_logloss: 0.121529\tTest's multi_logloss: 0.116188\n",
      "[57]\tTrain's multi_logloss: 0.120074\tTest's multi_logloss: 0.116284\n",
      "[58]\tTrain's multi_logloss: 0.120074\tTest's multi_logloss: 0.116284\n",
      "[59]\tTrain's multi_logloss: 0.118737\tTest's multi_logloss: 0.116484\n",
      "[60]\tTrain's multi_logloss: 0.118033\tTest's multi_logloss: 0.116067\n",
      "[61]\tTrain's multi_logloss: 0.118325\tTest's multi_logloss: 0.116754\n",
      "[62]\tTrain's multi_logloss: 0.116188\tTest's multi_logloss: 0.113506\n",
      "[63]\tTrain's multi_logloss: 0.114176\tTest's multi_logloss: 0.111002\n",
      "[64]\tTrain's multi_logloss: 0.112079\tTest's multi_logloss: 0.1061\n",
      "[65]\tTrain's multi_logloss: 0.110329\tTest's multi_logloss: 0.101796\n",
      "[66]\tTrain's multi_logloss: 0.108679\tTest's multi_logloss: 0.100057\n",
      "[67]\tTrain's multi_logloss: 0.107324\tTest's multi_logloss: 0.0964335\n",
      "[68]\tTrain's multi_logloss: 0.106752\tTest's multi_logloss: 0.0970538\n",
      "[69]\tTrain's multi_logloss: 0.106266\tTest's multi_logloss: 0.0986526\n",
      "[70]\tTrain's multi_logloss: 0.105982\tTest's multi_logloss: 0.100175\n",
      "[71]\tTrain's multi_logloss: 0.104858\tTest's multi_logloss: 0.0997198\n",
      "[72]\tTrain's multi_logloss: 0.104822\tTest's multi_logloss: 0.10134\n",
      "[73]\tTrain's multi_logloss: 0.10477\tTest's multi_logloss: 0.102607\n",
      "[74]\tTrain's multi_logloss: 0.10477\tTest's multi_logloss: 0.102607\n",
      "[75]\tTrain's multi_logloss: 0.103247\tTest's multi_logloss: 0.101619\n",
      "[76]\tTrain's multi_logloss: 0.102109\tTest's multi_logloss: 0.100946\n",
      "[77]\tTrain's multi_logloss: 0.102328\tTest's multi_logloss: 0.0985638\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107324\tTest's multi_logloss: 0.0964335\n",
      "[1]\tTrain's multi_logloss: 0.983729\tTest's multi_logloss: 1.01854\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.886843\tTest's multi_logloss: 0.924383\n",
      "[3]\tTrain's multi_logloss: 0.80713\tTest's multi_logloss: 0.841125\n",
      "[4]\tTrain's multi_logloss: 0.739354\tTest's multi_logloss: 0.768588\n",
      "[5]\tTrain's multi_logloss: 0.674719\tTest's multi_logloss: 0.700124\n",
      "[6]\tTrain's multi_logloss: 0.619445\tTest's multi_logloss: 0.645304\n",
      "[7]\tTrain's multi_logloss: 0.581001\tTest's multi_logloss: 0.604376\n",
      "[8]\tTrain's multi_logloss: 0.543505\tTest's multi_logloss: 0.562237\n",
      "[9]\tTrain's multi_logloss: 0.510638\tTest's multi_logloss: 0.525339\n",
      "[10]\tTrain's multi_logloss: 0.48137\tTest's multi_logloss: 0.492156\n",
      "[11]\tTrain's multi_logloss: 0.453488\tTest's multi_logloss: 0.459651\n",
      "[12]\tTrain's multi_logloss: 0.427588\tTest's multi_logloss: 0.429577\n",
      "[13]\tTrain's multi_logloss: 0.394465\tTest's multi_logloss: 0.394334\n",
      "[14]\tTrain's multi_logloss: 0.367114\tTest's multi_logloss: 0.363779\n",
      "[15]\tTrain's multi_logloss: 0.342862\tTest's multi_logloss: 0.34015\n",
      "[16]\tTrain's multi_logloss: 0.32146\tTest's multi_logloss: 0.318811\n",
      "[17]\tTrain's multi_logloss: 0.302528\tTest's multi_logloss: 0.300924\n",
      "[18]\tTrain's multi_logloss: 0.285462\tTest's multi_logloss: 0.280229\n",
      "[19]\tTrain's multi_logloss: 0.280878\tTest's multi_logloss: 0.277583\n",
      "[20]\tTrain's multi_logloss: 0.277241\tTest's multi_logloss: 0.275853\n",
      "[21]\tTrain's multi_logloss: 0.274747\tTest's multi_logloss: 0.274691\n",
      "[22]\tTrain's multi_logloss: 0.268561\tTest's multi_logloss: 0.268286\n",
      "[23]\tTrain's multi_logloss: 0.261745\tTest's multi_logloss: 0.262884\n",
      "[24]\tTrain's multi_logloss: 0.255687\tTest's multi_logloss: 0.257883\n",
      "[25]\tTrain's multi_logloss: 0.244669\tTest's multi_logloss: 0.241702\n",
      "[26]\tTrain's multi_logloss: 0.233918\tTest's multi_logloss: 0.22733\n",
      "[27]\tTrain's multi_logloss: 0.224695\tTest's multi_logloss: 0.213385\n",
      "[28]\tTrain's multi_logloss: 0.21527\tTest's multi_logloss: 0.20386\n",
      "[29]\tTrain's multi_logloss: 0.205216\tTest's multi_logloss: 0.193508\n",
      "[30]\tTrain's multi_logloss: 0.199125\tTest's multi_logloss: 0.184797\n",
      "[31]\tTrain's multi_logloss: 0.195567\tTest's multi_logloss: 0.182031\n",
      "[32]\tTrain's multi_logloss: 0.190184\tTest's multi_logloss: 0.177088\n",
      "[33]\tTrain's multi_logloss: 0.18213\tTest's multi_logloss: 0.17153\n",
      "[34]\tTrain's multi_logloss: 0.174927\tTest's multi_logloss: 0.166465\n",
      "[35]\tTrain's multi_logloss: 0.168506\tTest's multi_logloss: 0.161969\n",
      "[36]\tTrain's multi_logloss: 0.16504\tTest's multi_logloss: 0.160351\n",
      "[37]\tTrain's multi_logloss: 0.159417\tTest's multi_logloss: 0.151187\n",
      "[38]\tTrain's multi_logloss: 0.155458\tTest's multi_logloss: 0.147057\n",
      "[39]\tTrain's multi_logloss: 0.152206\tTest's multi_logloss: 0.143675\n",
      "[40]\tTrain's multi_logloss: 0.149635\tTest's multi_logloss: 0.141163\n",
      "[41]\tTrain's multi_logloss: 0.145891\tTest's multi_logloss: 0.134915\n",
      "[42]\tTrain's multi_logloss: 0.142698\tTest's multi_logloss: 0.129616\n",
      "[43]\tTrain's multi_logloss: 0.142251\tTest's multi_logloss: 0.128738\n",
      "[44]\tTrain's multi_logloss: 0.141871\tTest's multi_logloss: 0.127685\n",
      "[45]\tTrain's multi_logloss: 0.140844\tTest's multi_logloss: 0.126304\n",
      "[46]\tTrain's multi_logloss: 0.139959\tTest's multi_logloss: 0.125111\n",
      "[47]\tTrain's multi_logloss: 0.138909\tTest's multi_logloss: 0.122454\n",
      "[48]\tTrain's multi_logloss: 0.137389\tTest's multi_logloss: 0.119715\n",
      "[49]\tTrain's multi_logloss: 0.135478\tTest's multi_logloss: 0.118783\n",
      "[50]\tTrain's multi_logloss: 0.133742\tTest's multi_logloss: 0.117976\n",
      "[51]\tTrain's multi_logloss: 0.1311\tTest's multi_logloss: 0.116077\n",
      "[52]\tTrain's multi_logloss: 0.130613\tTest's multi_logloss: 0.11712\n",
      "[53]\tTrain's multi_logloss: 0.128143\tTest's multi_logloss: 0.115368\n",
      "[54]\tTrain's multi_logloss: 0.126621\tTest's multi_logloss: 0.114392\n",
      "[55]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[56]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[57]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[58]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[59]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[60]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[61]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[62]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[63]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  70%|#######   | 14/20 [00:00<00:00, 17.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,847]\u001b[0m Trial 57 finished with value: 0.1137628720609356 and parameters: {'lambda_l1': 0.016923723686623263, 'lambda_l2': 0.024628518743008723}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  75%|#######5  | 15/20 [00:00<00:00, 17.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  75%|#######5  | 15/20 [00:00<00:00, 17.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  80%|########  | 16/20 [00:00<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,898]\u001b[0m Trial 58 finished with value: 0.09676238376069364 and parameters: {'lambda_l1': 4.754504956342319e-05, 'lambda_l2': 0.00010809793291282794}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  80%|########  | 16/20 [00:00<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[65]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "Early stopping, best iteration is:\n",
      "[55]\tTrain's multi_logloss: 0.125566\tTest's multi_logloss: 0.113763\n",
      "[1]\tTrain's multi_logloss: 0.983224\tTest's multi_logloss: 1.01807\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.885973\tTest's multi_logloss: 0.923551\n",
      "[3]\tTrain's multi_logloss: 0.806018\tTest's multi_logloss: 0.84001\n",
      "[4]\tTrain's multi_logloss: 0.73807\tTest's multi_logloss: 0.767256\n",
      "[5]\tTrain's multi_logloss: 0.673288\tTest's multi_logloss: 0.698608\n",
      "[6]\tTrain's multi_logloss: 0.617883\tTest's multi_logloss: 0.64364\n",
      "[7]\tTrain's multi_logloss: 0.579347\tTest's multi_logloss: 0.602589\n",
      "[8]\tTrain's multi_logloss: 0.541772\tTest's multi_logloss: 0.560338\n",
      "[9]\tTrain's multi_logloss: 0.508847\tTest's multi_logloss: 0.523354\n",
      "[10]\tTrain's multi_logloss: 0.479534\tTest's multi_logloss: 0.490099\n",
      "[11]\tTrain's multi_logloss: 0.451593\tTest's multi_logloss: 0.457512\n",
      "[12]\tTrain's multi_logloss: 0.419623\tTest's multi_logloss: 0.426644\n",
      "[13]\tTrain's multi_logloss: 0.386916\tTest's multi_logloss: 0.391408\n",
      "[14]\tTrain's multi_logloss: 0.35984\tTest's multi_logloss: 0.360847\n",
      "[15]\tTrain's multi_logloss: 0.335852\tTest's multi_logloss: 0.337186\n",
      "[16]\tTrain's multi_logloss: 0.314683\tTest's multi_logloss: 0.315819\n",
      "[17]\tTrain's multi_logloss: 0.296168\tTest's multi_logloss: 0.298332\n",
      "[18]\tTrain's multi_logloss: 0.279277\tTest's multi_logloss: 0.277613\n",
      "[19]\tTrain's multi_logloss: 0.276067\tTest's multi_logloss: 0.274583\n",
      "[20]\tTrain's multi_logloss: 0.271734\tTest's multi_logloss: 0.272054\n",
      "[21]\tTrain's multi_logloss: 0.269137\tTest's multi_logloss: 0.269585\n",
      "[22]\tTrain's multi_logloss: 0.263007\tTest's multi_logloss: 0.263216\n",
      "[23]\tTrain's multi_logloss: 0.25958\tTest's multi_logloss: 0.261609\n",
      "[24]\tTrain's multi_logloss: 0.258701\tTest's multi_logloss: 0.262113\n",
      "[25]\tTrain's multi_logloss: 0.24726\tTest's multi_logloss: 0.245594\n",
      "[26]\tTrain's multi_logloss: 0.236053\tTest's multi_logloss: 0.230925\n",
      "[27]\tTrain's multi_logloss: 0.22652\tTest's multi_logloss: 0.216609\n",
      "[28]\tTrain's multi_logloss: 0.216362\tTest's multi_logloss: 0.205563\n",
      "[29]\tTrain's multi_logloss: 0.20616\tTest's multi_logloss: 0.195265\n",
      "[30]\tTrain's multi_logloss: 0.199214\tTest's multi_logloss: 0.184982\n",
      "[31]\tTrain's multi_logloss: 0.195476\tTest's multi_logloss: 0.182083\n",
      "[32]\tTrain's multi_logloss: 0.191334\tTest's multi_logloss: 0.17881\n",
      "[33]\tTrain's multi_logloss: 0.182922\tTest's multi_logloss: 0.173077\n",
      "[34]\tTrain's multi_logloss: 0.175428\tTest's multi_logloss: 0.167828\n",
      "[35]\tTrain's multi_logloss: 0.168752\tTest's multi_logloss: 0.163178\n",
      "[36]\tTrain's multi_logloss: 0.16499\tTest's multi_logloss: 0.16121\n",
      "[37]\tTrain's multi_logloss: 0.159251\tTest's multi_logloss: 0.152011\n",
      "[38]\tTrain's multi_logloss: 0.155187\tTest's multi_logloss: 0.147813\n",
      "[39]\tTrain's multi_logloss: 0.151798\tTest's multi_logloss: 0.144329\n",
      "[40]\tTrain's multi_logloss: 0.149051\tTest's multi_logloss: 0.141649\n",
      "[41]\tTrain's multi_logloss: 0.145136\tTest's multi_logloss: 0.135238\n",
      "[42]\tTrain's multi_logloss: 0.141761\tTest's multi_logloss: 0.129729\n",
      "[43]\tTrain's multi_logloss: 0.140369\tTest's multi_logloss: 0.127922\n",
      "[44]\tTrain's multi_logloss: 0.139161\tTest's multi_logloss: 0.126345\n",
      "[45]\tTrain's multi_logloss: 0.138047\tTest's multi_logloss: 0.124844\n",
      "[46]\tTrain's multi_logloss: 0.137082\tTest's multi_logloss: 0.123574\n",
      "[47]\tTrain's multi_logloss: 0.13681\tTest's multi_logloss: 0.122727\n",
      "[48]\tTrain's multi_logloss: 0.135777\tTest's multi_logloss: 0.121621\n",
      "[49]\tTrain's multi_logloss: 0.133658\tTest's multi_logloss: 0.120235\n",
      "[50]\tTrain's multi_logloss: 0.131755\tTest's multi_logloss: 0.119022\n",
      "[51]\tTrain's multi_logloss: 0.12909\tTest's multi_logloss: 0.117181\n",
      "[52]\tTrain's multi_logloss: 0.127774\tTest's multi_logloss: 0.116763\n",
      "[53]\tTrain's multi_logloss: 0.127474\tTest's multi_logloss: 0.117989\n",
      "[54]\tTrain's multi_logloss: 0.126013\tTest's multi_logloss: 0.117102\n",
      "[55]\tTrain's multi_logloss: 0.123109\tTest's multi_logloss: 0.1162\n",
      "[56]\tTrain's multi_logloss: 0.121524\tTest's multi_logloss: 0.116182\n",
      "[57]\tTrain's multi_logloss: 0.12007\tTest's multi_logloss: 0.116278\n",
      "[58]\tTrain's multi_logloss: 0.120206\tTest's multi_logloss: 0.116864\n",
      "[59]\tTrain's multi_logloss: 0.118352\tTest's multi_logloss: 0.116641\n",
      "[60]\tTrain's multi_logloss: 0.118352\tTest's multi_logloss: 0.116641\n",
      "[61]\tTrain's multi_logloss: 0.118688\tTest's multi_logloss: 0.117317\n",
      "[62]\tTrain's multi_logloss: 0.116483\tTest's multi_logloss: 0.113996\n",
      "[63]\tTrain's multi_logloss: 0.114428\tTest's multi_logloss: 0.111449\n",
      "[64]\tTrain's multi_logloss: 0.11231\tTest's multi_logloss: 0.10651\n",
      "[65]\tTrain's multi_logloss: 0.110539\tTest's multi_logloss: 0.102173\n",
      "[66]\tTrain's multi_logloss: 0.108857\tTest's multi_logloss: 0.100412\n",
      "[67]\tTrain's multi_logloss: 0.107482\tTest's multi_logloss: 0.0967624\n",
      "[68]\tTrain's multi_logloss: 0.106843\tTest's multi_logloss: 0.0980941\n",
      "[69]\tTrain's multi_logloss: 0.106366\tTest's multi_logloss: 0.0995749\n",
      "[70]\tTrain's multi_logloss: 0.106076\tTest's multi_logloss: 0.100982\n",
      "[71]\tTrain's multi_logloss: 0.104982\tTest's multi_logloss: 0.100477\n",
      "[72]\tTrain's multi_logloss: 0.10493\tTest's multi_logloss: 0.101996\n",
      "[73]\tTrain's multi_logloss: 0.10445\tTest's multi_logloss: 0.10199\n",
      "[74]\tTrain's multi_logloss: 0.10445\tTest's multi_logloss: 0.10199\n",
      "[75]\tTrain's multi_logloss: 0.10299\tTest's multi_logloss: 0.100994\n",
      "[76]\tTrain's multi_logloss: 0.101926\tTest's multi_logloss: 0.10028\n",
      "[77]\tTrain's multi_logloss: 0.102125\tTest's multi_logloss: 0.0978169\n",
      "Early stopping, best iteration is:\n",
      "[67]\tTrain's multi_logloss: 0.107482\tTest's multi_logloss: 0.0967624\n",
      "[1]\tTrain's multi_logloss: 0.992176\tTest's multi_logloss: 1.02689\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.901989\tTest's multi_logloss: 0.939577\n",
      "[3]\tTrain's multi_logloss: 0.827244\tTest's multi_logloss: 0.862398\n",
      "[4]\tTrain's multi_logloss: 0.763387\tTest's multi_logloss: 0.794904\n",
      "[5]\tTrain's multi_logloss: 0.702036\tTest's multi_logloss: 0.730664\n",
      "[6]\tTrain's multi_logloss: 0.650018\tTest's multi_logloss: 0.679418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  80%|########  | 16/20 [00:00<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,940]\u001b[0m Trial 59 finished with value: 0.18879320439581307 and parameters: {'lambda_l1': 0.8282287491647691, 'lambda_l2': 0.0019378513826273848}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  85%|########5 | 17/20 [00:00<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tTrain's multi_logloss: 0.611724\tTest's multi_logloss: 0.638869\n",
      "[8]\tTrain's multi_logloss: 0.576928\tTest's multi_logloss: 0.600379\n",
      "[9]\tTrain's multi_logloss: 0.546021\tTest's multi_logloss: 0.565953\n",
      "[10]\tTrain's multi_logloss: 0.518652\tTest's multi_logloss: 0.535543\n",
      "[11]\tTrain's multi_logloss: 0.492886\tTest's multi_logloss: 0.505959\n",
      "[12]\tTrain's multi_logloss: 0.471078\tTest's multi_logloss: 0.482044\n",
      "[13]\tTrain's multi_logloss: 0.440065\tTest's multi_logloss: 0.449288\n",
      "[14]\tTrain's multi_logloss: 0.413574\tTest's multi_logloss: 0.420173\n",
      "[15]\tTrain's multi_logloss: 0.389379\tTest's multi_logloss: 0.393878\n",
      "[16]\tTrain's multi_logloss: 0.369005\tTest's multi_logloss: 0.373342\n",
      "[17]\tTrain's multi_logloss: 0.350788\tTest's multi_logloss: 0.356311\n",
      "[18]\tTrain's multi_logloss: 0.333938\tTest's multi_logloss: 0.336631\n",
      "[19]\tTrain's multi_logloss: 0.328653\tTest's multi_logloss: 0.332327\n",
      "[20]\tTrain's multi_logloss: 0.323692\tTest's multi_logloss: 0.328005\n",
      "[21]\tTrain's multi_logloss: 0.323692\tTest's multi_logloss: 0.328005\n",
      "[22]\tTrain's multi_logloss: 0.323692\tTest's multi_logloss: 0.328005\n",
      "[23]\tTrain's multi_logloss: 0.323372\tTest's multi_logloss: 0.328077\n",
      "[24]\tTrain's multi_logloss: 0.322712\tTest's multi_logloss: 0.328464\n",
      "[25]\tTrain's multi_logloss: 0.322142\tTest's multi_logloss: 0.328828\n",
      "[26]\tTrain's multi_logloss: 0.32165\tTest's multi_logloss: 0.329167\n",
      "[27]\tTrain's multi_logloss: 0.308784\tTest's multi_logloss: 0.312495\n",
      "[28]\tTrain's multi_logloss: 0.296654\tTest's multi_logloss: 0.29872\n",
      "[29]\tTrain's multi_logloss: 0.284731\tTest's multi_logloss: 0.285992\n",
      "[30]\tTrain's multi_logloss: 0.27611\tTest's multi_logloss: 0.27431\n",
      "[31]\tTrain's multi_logloss: 0.266954\tTest's multi_logloss: 0.264463\n",
      "[32]\tTrain's multi_logloss: 0.257894\tTest's multi_logloss: 0.255249\n",
      "[33]\tTrain's multi_logloss: 0.253285\tTest's multi_logloss: 0.25345\n",
      "[34]\tTrain's multi_logloss: 0.24887\tTest's multi_logloss: 0.251147\n",
      "[35]\tTrain's multi_logloss: 0.243057\tTest's multi_logloss: 0.247467\n",
      "[36]\tTrain's multi_logloss: 0.239607\tTest's multi_logloss: 0.245775\n",
      "[37]\tTrain's multi_logloss: 0.23417\tTest's multi_logloss: 0.241974\n",
      "[38]\tTrain's multi_logloss: 0.230206\tTest's multi_logloss: 0.237555\n",
      "[39]\tTrain's multi_logloss: 0.225898\tTest's multi_logloss: 0.231191\n",
      "[40]\tTrain's multi_logloss: 0.222139\tTest's multi_logloss: 0.225733\n",
      "[41]\tTrain's multi_logloss: 0.216516\tTest's multi_logloss: 0.217444\n",
      "[42]\tTrain's multi_logloss: 0.211556\tTest's multi_logloss: 0.21023\n",
      "[43]\tTrain's multi_logloss: 0.209089\tTest's multi_logloss: 0.207003\n",
      "[44]\tTrain's multi_logloss: 0.204718\tTest's multi_logloss: 0.200665\n",
      "[45]\tTrain's multi_logloss: 0.198841\tTest's multi_logloss: 0.195754\n",
      "[46]\tTrain's multi_logloss: 0.197349\tTest's multi_logloss: 0.193641\n",
      "[47]\tTrain's multi_logloss: 0.196655\tTest's multi_logloss: 0.192402\n",
      "[48]\tTrain's multi_logloss: 0.195333\tTest's multi_logloss: 0.190542\n",
      "[49]\tTrain's multi_logloss: 0.195227\tTest's multi_logloss: 0.190442\n",
      "[50]\tTrain's multi_logloss: 0.19467\tTest's multi_logloss: 0.189414\n",
      "[51]\tTrain's multi_logloss: 0.194561\tTest's multi_logloss: 0.189272\n",
      "[52]\tTrain's multi_logloss: 0.194561\tTest's multi_logloss: 0.189272\n",
      "[53]\tTrain's multi_logloss: 0.194561\tTest's multi_logloss: 0.189272\n",
      "[54]\tTrain's multi_logloss: 0.194459\tTest's multi_logloss: 0.189139\n",
      "[55]\tTrain's multi_logloss: 0.194365\tTest's multi_logloss: 0.189015\n",
      "[56]\tTrain's multi_logloss: 0.194277\tTest's multi_logloss: 0.1889\n",
      "[57]\tTrain's multi_logloss: 0.194277\tTest's multi_logloss: 0.1889\n",
      "[58]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[59]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[60]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[61]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[62]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[63]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[64]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[65]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[66]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[67]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[68]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "Early stopping, best iteration is:\n",
      "[58]\tTrain's multi_logloss: 0.194196\tTest's multi_logloss: 0.188793\n",
      "[1]\tTrain's multi_logloss: 0.983237\tTest's multi_logloss: 1.01808\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.885996\tTest's multi_logloss: 0.923573\n",
      "[3]\tTrain's multi_logloss: 0.806048\tTest's multi_logloss: 0.840042\n",
      "[4]\tTrain's multi_logloss: 0.738106\tTest's multi_logloss: 0.767295\n",
      "[5]\tTrain's multi_logloss: 0.673328\tTest's multi_logloss: 0.698653\n",
      "[6]\tTrain's multi_logloss: 0.617928\tTest's multi_logloss: 0.64369\n",
      "[7]\tTrain's multi_logloss: 0.579395\tTest's multi_logloss: 0.602645\n",
      "[8]\tTrain's multi_logloss: 0.541824\tTest's multi_logloss: 0.560398\n",
      "[9]\tTrain's multi_logloss: 0.508902\tTest's multi_logloss: 0.523418\n",
      "[10]\tTrain's multi_logloss: 0.479591\tTest's multi_logloss: 0.490167\n",
      "[11]\tTrain's multi_logloss: 0.451653\tTest's multi_logloss: 0.457583\n",
      "[12]\tTrain's multi_logloss: 0.419686\tTest's multi_logloss: 0.426718\n",
      "[13]\tTrain's multi_logloss: 0.386982\tTest's multi_logloss: 0.391486\n",
      "[14]\tTrain's multi_logloss: 0.359908\tTest's multi_logloss: 0.360927\n",
      "[15]\tTrain's multi_logloss: 0.335921\tTest's multi_logloss: 0.337267\n",
      "[16]\tTrain's multi_logloss: 0.314753\tTest's multi_logloss: 0.315901\n",
      "[17]\tTrain's multi_logloss: 0.296239\tTest's multi_logloss: 0.298415\n",
      "[18]\tTrain's multi_logloss: 0.279348\tTest's multi_logloss: 0.277698\n",
      "[19]\tTrain's multi_logloss: 0.276139\tTest's multi_logloss: 0.274667\n",
      "[20]\tTrain's multi_logloss: 0.271808\tTest's multi_logloss: 0.27214\n",
      "[21]\tTrain's multi_logloss: 0.269212\tTest's multi_logloss: 0.269671\n",
      "[22]\tTrain's multi_logloss: 0.263083\tTest's multi_logloss: 0.263307\n",
      "[23]\tTrain's multi_logloss: 0.259658\tTest's multi_logloss: 0.261701\n",
      "[24]\tTrain's multi_logloss: 0.258779\tTest's multi_logloss: 0.262204\n",
      "[25]\tTrain's multi_logloss: 0.247339\tTest's multi_logloss: 0.245688\n",
      "[26]\tTrain's multi_logloss: 0.236132\tTest's multi_logloss: 0.23102\n",
      "[27]\tTrain's multi_logloss: 0.226599\tTest's multi_logloss: 0.216705\n",
      "[28]\tTrain's multi_logloss: 0.216442\tTest's multi_logloss: 0.20566\n",
      "[29]\tTrain's multi_logloss: 0.206241\tTest's multi_logloss: 0.195362\n",
      "[30]\tTrain's multi_logloss: 0.199294\tTest's multi_logloss: 0.185078\n",
      "[31]\tTrain's multi_logloss: 0.195558\tTest's multi_logloss: 0.182181\n",
      "[32]\tTrain's multi_logloss: 0.191417\tTest's multi_logloss: 0.178908\n",
      "[33]\tTrain's multi_logloss: 0.183004\tTest's multi_logloss: 0.173174\n",
      "[34]\tTrain's multi_logloss: 0.17551\tTest's multi_logloss: 0.167923\n",
      "[35]\tTrain's multi_logloss: 0.168834\tTest's multi_logloss: 0.163271\n",
      "[36]\tTrain's multi_logloss: 0.165073\tTest's multi_logloss: 0.161302\n",
      "[37]\tTrain's multi_logloss: 0.159334\tTest's multi_logloss: 0.152103\n",
      "[38]\tTrain's multi_logloss: 0.155273\tTest's multi_logloss: 0.147906\n",
      "[39]\tTrain's multi_logloss: 0.151885\tTest's multi_logloss: 0.14442\n",
      "[40]\tTrain's multi_logloss: 0.149139\tTest's multi_logloss: 0.141739\n",
      "[41]\tTrain's multi_logloss: 0.145223\tTest's multi_logloss: 0.135328\n",
      "[42]\tTrain's multi_logloss: 0.141847\tTest's multi_logloss: 0.129819\n",
      "[43]\tTrain's multi_logloss: 0.140455\tTest's multi_logloss: 0.128014\n",
      "[44]\tTrain's multi_logloss: 0.139247\tTest's multi_logloss: 0.126437\n",
      "[45]\tTrain's multi_logloss: 0.138133\tTest's multi_logloss: 0.124937\n",
      "[46]\tTrain's multi_logloss: 0.137167\tTest's multi_logloss: 0.123668\n",
      "[47]\tTrain's multi_logloss: 0.136894\tTest's multi_logloss: 0.122823\n",
      "[48]\tTrain's multi_logloss: 0.135863\tTest's multi_logloss: 0.121717\n",
      "[49]\tTrain's multi_logloss: 0.133746\tTest's multi_logloss: 0.120333\n",
      "[50]\tTrain's multi_logloss: 0.131845\tTest's multi_logloss: 0.119121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  85%|########5 | 17/20 [00:00<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:44,984]\u001b[0m Trial 60 finished with value: 0.11615159398210982 and parameters: {'lambda_l1': 0.001329194620819361, 'lambda_l2': 6.6457360423420936e-06}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  90%|######### | 18/20 [00:00<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  90%|######### | 18/20 [00:01<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  95%|#########5| 19/20 [00:01<00:00, 19.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:45,042]\u001b[0m Trial 61 finished with value: 0.09555617481165074 and parameters: {'lambda_l1': 0.011385582898267153, 'lambda_l2': 0.09453060332683662}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  95%|#########5| 19/20 [00:01<00:00, 19.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\tTrain's multi_logloss: 0.129181\tTest's multi_logloss: 0.11728\n",
      "[52]\tTrain's multi_logloss: 0.127866\tTest's multi_logloss: 0.116862\n",
      "[53]\tTrain's multi_logloss: 0.127568\tTest's multi_logloss: 0.118086\n",
      "[54]\tTrain's multi_logloss: 0.126107\tTest's multi_logloss: 0.1172\n",
      "[55]\tTrain's multi_logloss: 0.123201\tTest's multi_logloss: 0.116295\n",
      "[56]\tTrain's multi_logloss: 0.121615\tTest's multi_logloss: 0.116276\n",
      "[57]\tTrain's multi_logloss: 0.120158\tTest's multi_logloss: 0.11637\n",
      "[58]\tTrain's multi_logloss: 0.120158\tTest's multi_logloss: 0.11637\n",
      "[59]\tTrain's multi_logloss: 0.118819\tTest's multi_logloss: 0.116569\n",
      "[60]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[61]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[62]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[63]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[64]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[65]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[66]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[67]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[68]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[69]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[70]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "Early stopping, best iteration is:\n",
      "[60]\tTrain's multi_logloss: 0.118115\tTest's multi_logloss: 0.116152\n",
      "[1]\tTrain's multi_logloss: 0.984581\tTest's multi_logloss: 1.0193\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.88828\tTest's multi_logloss: 0.925713\n",
      "[3]\tTrain's multi_logloss: 0.808926\tTest's multi_logloss: 0.842854\n",
      "[4]\tTrain's multi_logloss: 0.741383\tTest's multi_logloss: 0.770599\n",
      "[5]\tTrain's multi_logloss: 0.676953\tTest's multi_logloss: 0.702383\n",
      "[6]\tTrain's multi_logloss: 0.621839\tTest's multi_logloss: 0.647748\n",
      "[7]\tTrain's multi_logloss: 0.580806\tTest's multi_logloss: 0.604396\n",
      "[8]\tTrain's multi_logloss: 0.543679\tTest's multi_logloss: 0.562778\n",
      "[9]\tTrain's multi_logloss: 0.510771\tTest's multi_logloss: 0.525511\n",
      "[10]\tTrain's multi_logloss: 0.481762\tTest's multi_logloss: 0.492718\n",
      "[11]\tTrain's multi_logloss: 0.4541\tTest's multi_logloss: 0.460521\n",
      "[12]\tTrain's multi_logloss: 0.428377\tTest's multi_logloss: 0.430692\n",
      "[13]\tTrain's multi_logloss: 0.395448\tTest's multi_logloss: 0.395673\n",
      "[14]\tTrain's multi_logloss: 0.368312\tTest's multi_logloss: 0.365397\n",
      "[15]\tTrain's multi_logloss: 0.344175\tTest's multi_logloss: 0.341923\n",
      "[16]\tTrain's multi_logloss: 0.322868\tTest's multi_logloss: 0.320724\n",
      "[17]\tTrain's multi_logloss: 0.304067\tTest's multi_logloss: 0.302974\n",
      "[18]\tTrain's multi_logloss: 0.287098\tTest's multi_logloss: 0.282434\n",
      "[19]\tTrain's multi_logloss: 0.282552\tTest's multi_logloss: 0.279839\n",
      "[20]\tTrain's multi_logloss: 0.278894\tTest's multi_logloss: 0.278118\n",
      "[21]\tTrain's multi_logloss: 0.276409\tTest's multi_logloss: 0.276983\n",
      "[22]\tTrain's multi_logloss: 0.273976\tTest's multi_logloss: 0.274643\n",
      "[23]\tTrain's multi_logloss: 0.267039\tTest's multi_logloss: 0.268841\n",
      "[24]\tTrain's multi_logloss: 0.260745\tTest's multi_logloss: 0.263575\n",
      "[25]\tTrain's multi_logloss: 0.249607\tTest's multi_logloss: 0.247344\n",
      "[26]\tTrain's multi_logloss: 0.2387\tTest's multi_logloss: 0.23285\n",
      "[27]\tTrain's multi_logloss: 0.229391\tTest's multi_logloss: 0.21878\n",
      "[28]\tTrain's multi_logloss: 0.21987\tTest's multi_logloss: 0.209165\n",
      "[29]\tTrain's multi_logloss: 0.209689\tTest's multi_logloss: 0.198676\n",
      "[30]\tTrain's multi_logloss: 0.203461\tTest's multi_logloss: 0.189847\n",
      "[31]\tTrain's multi_logloss: 0.200124\tTest's multi_logloss: 0.187234\n",
      "[32]\tTrain's multi_logloss: 0.196334\tTest's multi_logloss: 0.184214\n",
      "[33]\tTrain's multi_logloss: 0.188056\tTest's multi_logloss: 0.178375\n",
      "[34]\tTrain's multi_logloss: 0.180615\tTest's multi_logloss: 0.173043\n",
      "[35]\tTrain's multi_logloss: 0.173964\tTest's multi_logloss: 0.168289\n",
      "[36]\tTrain's multi_logloss: 0.170353\tTest's multi_logloss: 0.166438\n",
      "[37]\tTrain's multi_logloss: 0.164481\tTest's multi_logloss: 0.157025\n",
      "[38]\tTrain's multi_logloss: 0.16039\tTest's multi_logloss: 0.152679\n",
      "[39]\tTrain's multi_logloss: 0.156998\tTest's multi_logloss: 0.149084\n",
      "[40]\tTrain's multi_logloss: 0.154273\tTest's multi_logloss: 0.146342\n",
      "[41]\tTrain's multi_logloss: 0.149999\tTest's multi_logloss: 0.139744\n",
      "[42]\tTrain's multi_logloss: 0.146572\tTest's multi_logloss: 0.13416\n",
      "[43]\tTrain's multi_logloss: 0.145292\tTest's multi_logloss: 0.132511\n",
      "[44]\tTrain's multi_logloss: 0.144179\tTest's multi_logloss: 0.13107\n",
      "[45]\tTrain's multi_logloss: 0.143167\tTest's multi_logloss: 0.129742\n",
      "[46]\tTrain's multi_logloss: 0.142268\tTest's multi_logloss: 0.128571\n",
      "[47]\tTrain's multi_logloss: 0.141813\tTest's multi_logloss: 0.127794\n",
      "[48]\tTrain's multi_logloss: 0.140189\tTest's multi_logloss: 0.124909\n",
      "[49]\tTrain's multi_logloss: 0.136219\tTest's multi_logloss: 0.123557\n",
      "[50]\tTrain's multi_logloss: 0.133477\tTest's multi_logloss: 0.121607\n",
      "[51]\tTrain's multi_logloss: 0.133103\tTest's multi_logloss: 0.122295\n",
      "[52]\tTrain's multi_logloss: 0.133161\tTest's multi_logloss: 0.123616\n",
      "[53]\tTrain's multi_logloss: 0.133187\tTest's multi_logloss: 0.124833\n",
      "[54]\tTrain's multi_logloss: 0.131397\tTest's multi_logloss: 0.123673\n",
      "[55]\tTrain's multi_logloss: 0.131397\tTest's multi_logloss: 0.123673\n",
      "[56]\tTrain's multi_logloss: 0.126065\tTest's multi_logloss: 0.119374\n",
      "[57]\tTrain's multi_logloss: 0.121288\tTest's multi_logloss: 0.115559\n",
      "[58]\tTrain's multi_logloss: 0.119232\tTest's multi_logloss: 0.112346\n",
      "[59]\tTrain's multi_logloss: 0.116938\tTest's multi_logloss: 0.107557\n",
      "[60]\tTrain's multi_logloss: 0.115371\tTest's multi_logloss: 0.105006\n",
      "[61]\tTrain's multi_logloss: 0.113683\tTest's multi_logloss: 0.101097\n",
      "[62]\tTrain's multi_logloss: 0.110753\tTest's multi_logloss: 0.0998512\n",
      "[63]\tTrain's multi_logloss: 0.108214\tTest's multi_logloss: 0.0996798\n",
      "[64]\tTrain's multi_logloss: 0.107806\tTest's multi_logloss: 0.101055\n",
      "[65]\tTrain's multi_logloss: 0.107061\tTest's multi_logloss: 0.101827\n",
      "[66]\tTrain's multi_logloss: 0.106537\tTest's multi_logloss: 0.101996\n",
      "[67]\tTrain's multi_logloss: 0.105674\tTest's multi_logloss: 0.101774\n",
      "[68]\tTrain's multi_logloss: 0.105674\tTest's multi_logloss: 0.101774\n",
      "[69]\tTrain's multi_logloss: 0.104219\tTest's multi_logloss: 0.100964\n",
      "[70]\tTrain's multi_logloss: 0.104073\tTest's multi_logloss: 0.0984518\n",
      "[71]\tTrain's multi_logloss: 0.10292\tTest's multi_logloss: 0.0976819\n",
      "[72]\tTrain's multi_logloss: 0.101736\tTest's multi_logloss: 0.0977737\n",
      "[73]\tTrain's multi_logloss: 0.101023\tTest's multi_logloss: 0.0972718\n",
      "[74]\tTrain's multi_logloss: 0.100973\tTest's multi_logloss: 0.0955562\n",
      "[75]\tTrain's multi_logloss: 0.097743\tTest's multi_logloss: 0.0979984\n",
      "[76]\tTrain's multi_logloss: 0.093784\tTest's multi_logloss: 0.0985686\n",
      "[77]\tTrain's multi_logloss: 0.0921181\tTest's multi_logloss: 0.10159\n",
      "[78]\tTrain's multi_logloss: 0.0883637\tTest's multi_logloss: 0.101012\n",
      "[79]\tTrain's multi_logloss: 0.0853733\tTest's multi_logloss: 0.102393\n",
      "[80]\tTrain's multi_logloss: 0.0826896\tTest's multi_logloss: 0.104075\n",
      "[81]\tTrain's multi_logloss: 0.0821978\tTest's multi_logloss: 0.10258\n",
      "[82]\tTrain's multi_logloss: 0.082331\tTest's multi_logloss: 0.103365\n",
      "[83]\tTrain's multi_logloss: 0.0825131\tTest's multi_logloss: 0.102371\n",
      "[84]\tTrain's multi_logloss: 0.0829203\tTest's multi_logloss: 0.103182\n",
      "Early stopping, best iteration is:\n",
      "[74]\tTrain's multi_logloss: 0.100973\tTest's multi_logloss: 0.0955562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.093987:  95%|#########5| 19/20 [00:01<00:00, 19.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:45,099]\u001b[0m Trial 62 finished with value: 0.09631274387669923 and parameters: {'lambda_l1': 0.007316824386308599, 'lambda_l2': 0.0907192164240764}. Best is trial 46 with value: 0.0939874474503158.\u001b[0m\n",
      "regularization_factors, val_score: 0.093987: 100%|##########| 20/20 [00:01<00:00, 18.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.984489\tTest's multi_logloss: 1.01922\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.888119\tTest's multi_logloss: 0.925558\n",
      "[3]\tTrain's multi_logloss: 0.808719\tTest's multi_logloss: 0.842644\n",
      "[4]\tTrain's multi_logloss: 0.741143\tTest's multi_logloss: 0.770347\n",
      "[5]\tTrain's multi_logloss: 0.676684\tTest's multi_logloss: 0.702095\n",
      "[6]\tTrain's multi_logloss: 0.621544\tTest's multi_logloss: 0.647431\n",
      "[7]\tTrain's multi_logloss: 0.580491\tTest's multi_logloss: 0.604056\n",
      "[8]\tTrain's multi_logloss: 0.543348\tTest's multi_logloss: 0.562415\n",
      "[9]\tTrain's multi_logloss: 0.510428\tTest's multi_logloss: 0.52513\n",
      "[10]\tTrain's multi_logloss: 0.481409\tTest's multi_logloss: 0.492322\n",
      "[11]\tTrain's multi_logloss: 0.453735\tTest's multi_logloss: 0.460108\n",
      "[12]\tTrain's multi_logloss: 0.428005\tTest's multi_logloss: 0.430267\n",
      "[13]\tTrain's multi_logloss: 0.395058\tTest's multi_logloss: 0.395226\n",
      "[14]\tTrain's multi_logloss: 0.367917\tTest's multi_logloss: 0.36494\n",
      "[15]\tTrain's multi_logloss: 0.343771\tTest's multi_logloss: 0.341458\n",
      "[16]\tTrain's multi_logloss: 0.322459\tTest's multi_logloss: 0.320251\n",
      "[17]\tTrain's multi_logloss: 0.303656\tTest's multi_logloss: 0.3025\n",
      "[18]\tTrain's multi_logloss: 0.286689\tTest's multi_logloss: 0.281955\n",
      "[19]\tTrain's multi_logloss: 0.282137\tTest's multi_logloss: 0.279357\n",
      "[20]\tTrain's multi_logloss: 0.278475\tTest's multi_logloss: 0.277634\n",
      "[21]\tTrain's multi_logloss: 0.275987\tTest's multi_logloss: 0.276498\n",
      "[22]\tTrain's multi_logloss: 0.269876\tTest's multi_logloss: 0.270165\n",
      "[23]\tTrain's multi_logloss: 0.263088\tTest's multi_logloss: 0.264804\n",
      "[24]\tTrain's multi_logloss: 0.257369\tTest's multi_logloss: 0.258831\n",
      "[25]\tTrain's multi_logloss: 0.246533\tTest's multi_logloss: 0.243043\n",
      "[26]\tTrain's multi_logloss: 0.235726\tTest's multi_logloss: 0.228735\n",
      "[27]\tTrain's multi_logloss: 0.22661\tTest's multi_logloss: 0.215036\n",
      "[28]\tTrain's multi_logloss: 0.217241\tTest's multi_logloss: 0.205624\n",
      "[29]\tTrain's multi_logloss: 0.207154\tTest's multi_logloss: 0.195292\n",
      "[30]\tTrain's multi_logloss: 0.201077\tTest's multi_logloss: 0.186652\n",
      "[31]\tTrain's multi_logloss: 0.197417\tTest's multi_logloss: 0.183796\n",
      "[32]\tTrain's multi_logloss: 0.193663\tTest's multi_logloss: 0.18084\n",
      "[33]\tTrain's multi_logloss: 0.185517\tTest's multi_logloss: 0.175194\n",
      "[34]\tTrain's multi_logloss: 0.178222\tTest's multi_logloss: 0.170039\n",
      "[35]\tTrain's multi_logloss: 0.171708\tTest's multi_logloss: 0.165452\n",
      "[36]\tTrain's multi_logloss: 0.168223\tTest's multi_logloss: 0.163743\n",
      "[37]\tTrain's multi_logloss: 0.162518\tTest's multi_logloss: 0.154534\n",
      "[38]\tTrain's multi_logloss: 0.158561\tTest's multi_logloss: 0.150351\n",
      "[39]\tTrain's multi_logloss: 0.155288\tTest's multi_logloss: 0.1469\n",
      "[40]\tTrain's multi_logloss: 0.152682\tTest's multi_logloss: 0.144312\n",
      "[41]\tTrain's multi_logloss: 0.148838\tTest's multi_logloss: 0.137979\n",
      "[42]\tTrain's multi_logloss: 0.145548\tTest's multi_logloss: 0.132592\n",
      "[43]\tTrain's multi_logloss: 0.14439\tTest's multi_logloss: 0.131002\n",
      "[44]\tTrain's multi_logloss: 0.143386\tTest's multi_logloss: 0.129614\n",
      "[45]\tTrain's multi_logloss: 0.143023\tTest's multi_logloss: 0.128885\n",
      "[46]\tTrain's multi_logloss: 0.142749\tTest's multi_logloss: 0.128008\n",
      "[47]\tTrain's multi_logloss: 0.142344\tTest's multi_logloss: 0.127245\n",
      "[48]\tTrain's multi_logloss: 0.141193\tTest's multi_logloss: 0.124795\n",
      "[49]\tTrain's multi_logloss: 0.139255\tTest's multi_logloss: 0.123849\n",
      "[50]\tTrain's multi_logloss: 0.137619\tTest's multi_logloss: 0.123155\n",
      "[51]\tTrain's multi_logloss: 0.134877\tTest's multi_logloss: 0.121167\n",
      "[52]\tTrain's multi_logloss: 0.134725\tTest's multi_logloss: 0.122374\n",
      "[53]\tTrain's multi_logloss: 0.134601\tTest's multi_logloss: 0.123536\n",
      "[54]\tTrain's multi_logloss: 0.133254\tTest's multi_logloss: 0.123055\n",
      "[55]\tTrain's multi_logloss: 0.133254\tTest's multi_logloss: 0.123055\n",
      "[56]\tTrain's multi_logloss: 0.128065\tTest's multi_logloss: 0.118804\n",
      "[57]\tTrain's multi_logloss: 0.126237\tTest's multi_logloss: 0.115772\n",
      "[58]\tTrain's multi_logloss: 0.124033\tTest's multi_logloss: 0.112452\n",
      "[59]\tTrain's multi_logloss: 0.121593\tTest's multi_logloss: 0.107631\n",
      "[60]\tTrain's multi_logloss: 0.119902\tTest's multi_logloss: 0.104991\n",
      "[61]\tTrain's multi_logloss: 0.118091\tTest's multi_logloss: 0.101055\n",
      "[62]\tTrain's multi_logloss: 0.115262\tTest's multi_logloss: 0.100572\n",
      "[63]\tTrain's multi_logloss: 0.112558\tTest's multi_logloss: 0.100125\n",
      "[64]\tTrain's multi_logloss: 0.112151\tTest's multi_logloss: 0.101365\n",
      "[65]\tTrain's multi_logloss: 0.1109\tTest's multi_logloss: 0.100795\n",
      "[66]\tTrain's multi_logloss: 0.110328\tTest's multi_logloss: 0.100878\n",
      "[67]\tTrain's multi_logloss: 0.109303\tTest's multi_logloss: 0.100517\n",
      "[68]\tTrain's multi_logloss: 0.109303\tTest's multi_logloss: 0.100517\n",
      "[69]\tTrain's multi_logloss: 0.107824\tTest's multi_logloss: 0.099729\n",
      "[70]\tTrain's multi_logloss: 0.107684\tTest's multi_logloss: 0.0973732\n",
      "[71]\tTrain's multi_logloss: 0.1066\tTest's multi_logloss: 0.0968599\n",
      "[72]\tTrain's multi_logloss: 0.105285\tTest's multi_logloss: 0.0968843\n",
      "[73]\tTrain's multi_logloss: 0.104508\tTest's multi_logloss: 0.0963127\n",
      "[74]\tTrain's multi_logloss: 0.10359\tTest's multi_logloss: 0.0965143\n",
      "[75]\tTrain's multi_logloss: 0.0999785\tTest's multi_logloss: 0.0986358\n",
      "[76]\tTrain's multi_logloss: 0.0958722\tTest's multi_logloss: 0.0991967\n",
      "[77]\tTrain's multi_logloss: 0.093979\tTest's multi_logloss: 0.102028\n",
      "[78]\tTrain's multi_logloss: 0.0902508\tTest's multi_logloss: 0.101598\n",
      "[79]\tTrain's multi_logloss: 0.0871699\tTest's multi_logloss: 0.103002\n",
      "[80]\tTrain's multi_logloss: 0.0844097\tTest's multi_logloss: 0.104711\n",
      "[81]\tTrain's multi_logloss: 0.0837828\tTest's multi_logloss: 0.102879\n",
      "[82]\tTrain's multi_logloss: 0.0836048\tTest's multi_logloss: 0.102948\n",
      "[83]\tTrain's multi_logloss: 0.0836411\tTest's multi_logloss: 0.10174\n",
      "Early stopping, best iteration is:\n",
      "[73]\tTrain's multi_logloss: 0.104508\tTest's multi_logloss: 0.0963127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tTrain's multi_logloss: 0.925414\tTest's multi_logloss: 0.954674\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:45,149]\u001b[0m Trial 63 finished with value: 0.09725054737256139 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.09725054737256139.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  20%|##        | 1/5 [00:00<00:00, 20.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  20%|##        | 1/5 [00:00<00:00, 18.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:45,157]\u001b[0m Trial 64 finished with value: 1.145060876755944 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.09725054737256139.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  40%|####      | 2/5 [00:00<00:00, 35.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tTrain's multi_logloss: 0.792236\tTest's multi_logloss: 0.814771\n",
      "[3]\tTrain's multi_logloss: 0.68643\tTest's multi_logloss: 0.703539\n",
      "[4]\tTrain's multi_logloss: 0.603166\tTest's multi_logloss: 0.62501\n",
      "[5]\tTrain's multi_logloss: 0.534099\tTest's multi_logloss: 0.559196\n",
      "[6]\tTrain's multi_logloss: 0.477132\tTest's multi_logloss: 0.497631\n",
      "[7]\tTrain's multi_logloss: 0.429357\tTest's multi_logloss: 0.449764\n",
      "[8]\tTrain's multi_logloss: 0.389235\tTest's multi_logloss: 0.410336\n",
      "[9]\tTrain's multi_logloss: 0.351557\tTest's multi_logloss: 0.371885\n",
      "[10]\tTrain's multi_logloss: 0.319222\tTest's multi_logloss: 0.339239\n",
      "[11]\tTrain's multi_logloss: 0.291007\tTest's multi_logloss: 0.305452\n",
      "[12]\tTrain's multi_logloss: 0.265002\tTest's multi_logloss: 0.279277\n",
      "[13]\tTrain's multi_logloss: 0.239208\tTest's multi_logloss: 0.247472\n",
      "[14]\tTrain's multi_logloss: 0.217625\tTest's multi_logloss: 0.226152\n",
      "[15]\tTrain's multi_logloss: 0.199004\tTest's multi_logloss: 0.201411\n",
      "[16]\tTrain's multi_logloss: 0.18467\tTest's multi_logloss: 0.182132\n",
      "[17]\tTrain's multi_logloss: 0.172738\tTest's multi_logloss: 0.168008\n",
      "[18]\tTrain's multi_logloss: 0.162538\tTest's multi_logloss: 0.153651\n",
      "[19]\tTrain's multi_logloss: 0.152316\tTest's multi_logloss: 0.146814\n",
      "[20]\tTrain's multi_logloss: 0.145685\tTest's multi_logloss: 0.140132\n",
      "[21]\tTrain's multi_logloss: 0.136089\tTest's multi_logloss: 0.135735\n",
      "[22]\tTrain's multi_logloss: 0.12521\tTest's multi_logloss: 0.130693\n",
      "[23]\tTrain's multi_logloss: 0.119894\tTest's multi_logloss: 0.127264\n",
      "[24]\tTrain's multi_logloss: 0.113464\tTest's multi_logloss: 0.124003\n",
      "[25]\tTrain's multi_logloss: 0.108084\tTest's multi_logloss: 0.118943\n",
      "[26]\tTrain's multi_logloss: 0.104879\tTest's multi_logloss: 0.115815\n",
      "[27]\tTrain's multi_logloss: 0.101419\tTest's multi_logloss: 0.112607\n",
      "[28]\tTrain's multi_logloss: 0.0947426\tTest's multi_logloss: 0.108597\n",
      "[29]\tTrain's multi_logloss: 0.0878727\tTest's multi_logloss: 0.105186\n",
      "[30]\tTrain's multi_logloss: 0.0850945\tTest's multi_logloss: 0.104449\n",
      "[31]\tTrain's multi_logloss: 0.080943\tTest's multi_logloss: 0.102591\n",
      "[32]\tTrain's multi_logloss: 0.0779614\tTest's multi_logloss: 0.101394\n",
      "[33]\tTrain's multi_logloss: 0.0748873\tTest's multi_logloss: 0.0996374\n",
      "[34]\tTrain's multi_logloss: 0.0721151\tTest's multi_logloss: 0.0986848\n",
      "[35]\tTrain's multi_logloss: 0.0698432\tTest's multi_logloss: 0.0981758\n",
      "[36]\tTrain's multi_logloss: 0.0680802\tTest's multi_logloss: 0.0985149\n",
      "[37]\tTrain's multi_logloss: 0.0661972\tTest's multi_logloss: 0.0982417\n",
      "[38]\tTrain's multi_logloss: 0.0646297\tTest's multi_logloss: 0.10026\n",
      "[39]\tTrain's multi_logloss: 0.0634114\tTest's multi_logloss: 0.0999923\n",
      "[40]\tTrain's multi_logloss: 0.062182\tTest's multi_logloss: 0.0985834\n",
      "[41]\tTrain's multi_logloss: 0.0613623\tTest's multi_logloss: 0.0972505\n",
      "[42]\tTrain's multi_logloss: 0.0598788\tTest's multi_logloss: 0.0973606\n",
      "[43]\tTrain's multi_logloss: 0.0588018\tTest's multi_logloss: 0.0986128\n",
      "[44]\tTrain's multi_logloss: 0.0582471\tTest's multi_logloss: 0.0991243\n",
      "[45]\tTrain's multi_logloss: 0.0581341\tTest's multi_logloss: 0.101575\n",
      "[46]\tTrain's multi_logloss: 0.0579185\tTest's multi_logloss: 0.0995429\n",
      "[47]\tTrain's multi_logloss: 0.0574372\tTest's multi_logloss: 0.09771\n",
      "[48]\tTrain's multi_logloss: 0.0577481\tTest's multi_logloss: 0.0976444\n",
      "[49]\tTrain's multi_logloss: 0.0551834\tTest's multi_logloss: 0.100665\n",
      "[50]\tTrain's multi_logloss: 0.0539811\tTest's multi_logloss: 0.100797\n",
      "[51]\tTrain's multi_logloss: 0.0520995\tTest's multi_logloss: 0.101044\n",
      "Early stopping, best iteration is:\n",
      "[41]\tTrain's multi_logloss: 0.0613623\tTest's multi_logloss: 0.0972505\n",
      "[1]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[3]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[4]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[5]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[6]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[7]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[8]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[9]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[10]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[11]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[1]\tTrain's multi_logloss: 1.01413\tTest's multi_logloss: 1.04709\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.953958\tTest's multi_logloss: 0.999552\n",
      "[3]\tTrain's multi_logloss: 0.898829\tTest's multi_logloss: 0.945587\n",
      "[4]\tTrain's multi_logloss: 0.845933\tTest's multi_logloss: 0.897849\n",
      "[5]\tTrain's multi_logloss: 0.796046\tTest's multi_logloss: 0.854051\n",
      "[6]\tTrain's multi_logloss: 0.74459\tTest's multi_logloss: 0.807796\n",
      "[7]\tTrain's multi_logloss: 0.74459\tTest's multi_logloss: 0.807796\n",
      "[8]\tTrain's multi_logloss: 0.74459\tTest's multi_logloss: 0.807796\n",
      "[9]\tTrain's multi_logloss: 0.74459\tTest's multi_logloss: 0.807796\n",
      "[10]\tTrain's multi_logloss: 0.74459\tTest's multi_logloss: 0.807796\n",
      "[11]\tTrain's multi_logloss: 0.74459\tTest's multi_logloss: 0.807796\n",
      "[12]\tTrain's multi_logloss: 0.716849\tTest's multi_logloss: 0.772987\n",
      "[13]\tTrain's multi_logloss: 0.692737\tTest's multi_logloss: 0.742593\n",
      "[14]\tTrain's multi_logloss: 0.672082\tTest's multi_logloss: 0.717944\n",
      "[15]\tTrain's multi_logloss: 0.640438\tTest's multi_logloss: 0.683379\n",
      "[16]\tTrain's multi_logloss: 0.612471\tTest's multi_logloss: 0.652668\n",
      "[17]\tTrain's multi_logloss: 0.601012\tTest's multi_logloss: 0.640502\n",
      "[18]\tTrain's multi_logloss: 0.601012\tTest's multi_logloss: 0.640502\n",
      "[19]\tTrain's multi_logloss: 0.601012\tTest's multi_logloss: 0.640502\n",
      "[20]\tTrain's multi_logloss: 0.601012\tTest's multi_logloss: 0.640502\n",
      "[21]\tTrain's multi_logloss: 0.566067\tTest's multi_logloss: 0.604856\n",
      "[22]\tTrain's multi_logloss: 0.534818\tTest's multi_logloss: 0.572539\n",
      "[23]\tTrain's multi_logloss: 0.50725\tTest's multi_logloss: 0.543511\n",
      "[24]\tTrain's multi_logloss: 0.483959\tTest's multi_logloss: 0.522681\n",
      "[25]\tTrain's multi_logloss: 0.475218\tTest's multi_logloss: 0.516617\n",
      "[26]\tTrain's multi_logloss: 0.466515\tTest's multi_logloss: 0.51099\n",
      "[27]\tTrain's multi_logloss: 0.466515\tTest's multi_logloss: 0.51099\n",
      "[28]\tTrain's multi_logloss: 0.466515\tTest's multi_logloss: 0.51099\n",
      "[29]\tTrain's multi_logloss: 0.466515\tTest's multi_logloss: 0.51099\n",
      "[30]\tTrain's multi_logloss: 0.466515\tTest's multi_logloss: 0.51099\n",
      "[31]\tTrain's multi_logloss: 0.466515\tTest's multi_logloss: 0.51099\n",
      "[32]\tTrain's multi_logloss: 0.466515\tTest's multi_logloss: 0.51099\n",
      "[33]\tTrain's multi_logloss: 0.444262\tTest's multi_logloss: 0.488325\n",
      "[34]\tTrain's multi_logloss: 0.423451\tTest's multi_logloss: 0.466437\n",
      "[35]\tTrain's multi_logloss: 0.404814\tTest's multi_logloss: 0.446868\n",
      "[36]\tTrain's multi_logloss: 0.390316\tTest's multi_logloss: 0.426921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  40%|####      | 2/5 [00:00<00:00, 18.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  60%|######    | 3/5 [00:00<00:00, 27.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:45,209]\u001b[0m Trial 65 finished with value: 0.1355104386861109 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.09725054737256139.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  60%|######    | 3/5 [00:00<00:00, 27.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37]\tTrain's multi_logloss: 0.37726\tTest's multi_logloss: 0.40875\n",
      "[38]\tTrain's multi_logloss: 0.362817\tTest's multi_logloss: 0.394775\n",
      "[39]\tTrain's multi_logloss: 0.362817\tTest's multi_logloss: 0.394775\n",
      "[40]\tTrain's multi_logloss: 0.362817\tTest's multi_logloss: 0.394775\n",
      "[41]\tTrain's multi_logloss: 0.342638\tTest's multi_logloss: 0.373607\n",
      "[42]\tTrain's multi_logloss: 0.324588\tTest's multi_logloss: 0.354255\n",
      "[43]\tTrain's multi_logloss: 0.307409\tTest's multi_logloss: 0.334977\n",
      "[44]\tTrain's multi_logloss: 0.293324\tTest's multi_logloss: 0.319964\n",
      "[45]\tTrain's multi_logloss: 0.279943\tTest's multi_logloss: 0.302897\n",
      "[46]\tTrain's multi_logloss: 0.26789\tTest's multi_logloss: 0.288061\n",
      "[47]\tTrain's multi_logloss: 0.26789\tTest's multi_logloss: 0.288061\n",
      "[48]\tTrain's multi_logloss: 0.259492\tTest's multi_logloss: 0.276035\n",
      "[49]\tTrain's multi_logloss: 0.255497\tTest's multi_logloss: 0.268724\n",
      "[50]\tTrain's multi_logloss: 0.250862\tTest's multi_logloss: 0.259974\n",
      "[51]\tTrain's multi_logloss: 0.246986\tTest's multi_logloss: 0.252446\n",
      "[52]\tTrain's multi_logloss: 0.246811\tTest's multi_logloss: 0.251243\n",
      "[53]\tTrain's multi_logloss: 0.246736\tTest's multi_logloss: 0.250232\n",
      "[54]\tTrain's multi_logloss: 0.246736\tTest's multi_logloss: 0.250232\n",
      "[55]\tTrain's multi_logloss: 0.246736\tTest's multi_logloss: 0.250232\n",
      "[56]\tTrain's multi_logloss: 0.246736\tTest's multi_logloss: 0.250232\n",
      "[57]\tTrain's multi_logloss: 0.246736\tTest's multi_logloss: 0.250232\n",
      "[58]\tTrain's multi_logloss: 0.246736\tTest's multi_logloss: 0.250232\n",
      "[59]\tTrain's multi_logloss: 0.246736\tTest's multi_logloss: 0.250232\n",
      "[60]\tTrain's multi_logloss: 0.246736\tTest's multi_logloss: 0.250232\n",
      "[61]\tTrain's multi_logloss: 0.242536\tTest's multi_logloss: 0.247773\n",
      "[62]\tTrain's multi_logloss: 0.234115\tTest's multi_logloss: 0.24045\n",
      "[63]\tTrain's multi_logloss: 0.227445\tTest's multi_logloss: 0.235629\n",
      "[64]\tTrain's multi_logloss: 0.222599\tTest's multi_logloss: 0.23113\n",
      "[65]\tTrain's multi_logloss: 0.215666\tTest's multi_logloss: 0.22517\n",
      "[66]\tTrain's multi_logloss: 0.209747\tTest's multi_logloss: 0.220638\n",
      "[67]\tTrain's multi_logloss: 0.209747\tTest's multi_logloss: 0.220638\n",
      "[68]\tTrain's multi_logloss: 0.209747\tTest's multi_logloss: 0.220638\n",
      "[69]\tTrain's multi_logloss: 0.209747\tTest's multi_logloss: 0.220638\n",
      "[70]\tTrain's multi_logloss: 0.209747\tTest's multi_logloss: 0.220638\n",
      "[71]\tTrain's multi_logloss: 0.209747\tTest's multi_logloss: 0.220638\n",
      "[72]\tTrain's multi_logloss: 0.209747\tTest's multi_logloss: 0.220638\n",
      "[73]\tTrain's multi_logloss: 0.209747\tTest's multi_logloss: 0.220638\n",
      "[74]\tTrain's multi_logloss: 0.205961\tTest's multi_logloss: 0.213176\n",
      "[75]\tTrain's multi_logloss: 0.203311\tTest's multi_logloss: 0.207671\n",
      "[76]\tTrain's multi_logloss: 0.199943\tTest's multi_logloss: 0.204385\n",
      "[77]\tTrain's multi_logloss: 0.199735\tTest's multi_logloss: 0.203441\n",
      "[78]\tTrain's multi_logloss: 0.196715\tTest's multi_logloss: 0.200623\n",
      "[79]\tTrain's multi_logloss: 0.193754\tTest's multi_logloss: 0.198915\n",
      "[80]\tTrain's multi_logloss: 0.193754\tTest's multi_logloss: 0.198915\n",
      "[81]\tTrain's multi_logloss: 0.193754\tTest's multi_logloss: 0.198915\n",
      "[82]\tTrain's multi_logloss: 0.193754\tTest's multi_logloss: 0.198915\n",
      "[83]\tTrain's multi_logloss: 0.193754\tTest's multi_logloss: 0.198915\n",
      "[84]\tTrain's multi_logloss: 0.193754\tTest's multi_logloss: 0.198915\n",
      "[85]\tTrain's multi_logloss: 0.193754\tTest's multi_logloss: 0.198915\n",
      "[86]\tTrain's multi_logloss: 0.193754\tTest's multi_logloss: 0.198915\n",
      "[87]\tTrain's multi_logloss: 0.189073\tTest's multi_logloss: 0.193717\n",
      "[88]\tTrain's multi_logloss: 0.185894\tTest's multi_logloss: 0.190121\n",
      "[89]\tTrain's multi_logloss: 0.179166\tTest's multi_logloss: 0.181234\n",
      "[90]\tTrain's multi_logloss: 0.173373\tTest's multi_logloss: 0.174112\n",
      "[91]\tTrain's multi_logloss: 0.16824\tTest's multi_logloss: 0.167624\n",
      "[92]\tTrain's multi_logloss: 0.165441\tTest's multi_logloss: 0.164176\n",
      "[93]\tTrain's multi_logloss: 0.161655\tTest's multi_logloss: 0.157362\n",
      "[94]\tTrain's multi_logloss: 0.158405\tTest's multi_logloss: 0.151167\n",
      "[95]\tTrain's multi_logloss: 0.156005\tTest's multi_logloss: 0.14566\n",
      "[96]\tTrain's multi_logloss: 0.154234\tTest's multi_logloss: 0.141219\n",
      "[97]\tTrain's multi_logloss: 0.153704\tTest's multi_logloss: 0.141175\n",
      "[98]\tTrain's multi_logloss: 0.153151\tTest's multi_logloss: 0.140155\n",
      "[99]\tTrain's multi_logloss: 0.148372\tTest's multi_logloss: 0.137282\n",
      "[100]\tTrain's multi_logloss: 0.145263\tTest's multi_logloss: 0.13551\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's multi_logloss: 0.145263\tTest's multi_logloss: 0.13551\n",
      "[1]\tTrain's multi_logloss: 0.926219\tTest's multi_logloss: 0.956781\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 0.790226\tTest's multi_logloss: 0.816836\n",
      "[3]\tTrain's multi_logloss: 0.682002\tTest's multi_logloss: 0.705705\n",
      "[4]\tTrain's multi_logloss: 0.597136\tTest's multi_logloss: 0.622994\n",
      "[5]\tTrain's multi_logloss: 0.526677\tTest's multi_logloss: 0.55626\n",
      "[6]\tTrain's multi_logloss: 0.466284\tTest's multi_logloss: 0.493336\n",
      "[7]\tTrain's multi_logloss: 0.410565\tTest's multi_logloss: 0.441564\n",
      "[8]\tTrain's multi_logloss: 0.365033\tTest's multi_logloss: 0.39601\n",
      "[9]\tTrain's multi_logloss: 0.324893\tTest's multi_logloss: 0.358584\n",
      "[10]\tTrain's multi_logloss: 0.291221\tTest's multi_logloss: 0.329495\n",
      "[11]\tTrain's multi_logloss: 0.263061\tTest's multi_logloss: 0.298363\n",
      "[12]\tTrain's multi_logloss: 0.240788\tTest's multi_logloss: 0.28015\n",
      "[13]\tTrain's multi_logloss: 0.216104\tTest's multi_logloss: 0.247664\n",
      "[14]\tTrain's multi_logloss: 0.196442\tTest's multi_logloss: 0.228053\n",
      "[15]\tTrain's multi_logloss: 0.178858\tTest's multi_logloss: 0.203302\n",
      "[16]\tTrain's multi_logloss: 0.1643\tTest's multi_logloss: 0.182343\n",
      "[17]\tTrain's multi_logloss: 0.152909\tTest's multi_logloss: 0.168812\n",
      "[18]\tTrain's multi_logloss: 0.142915\tTest's multi_logloss: 0.153143\n",
      "[19]\tTrain's multi_logloss: 0.131677\tTest's multi_logloss: 0.147974\n",
      "[20]\tTrain's multi_logloss: 0.122908\tTest's multi_logloss: 0.141033\n",
      "[21]\tTrain's multi_logloss: 0.112434\tTest's multi_logloss: 0.137129\n",
      "[22]\tTrain's multi_logloss: 0.105378\tTest's multi_logloss: 0.13057\n",
      "[23]\tTrain's multi_logloss: 0.0978069\tTest's multi_logloss: 0.126789\n",
      "[24]\tTrain's multi_logloss: 0.0890268\tTest's multi_logloss: 0.120928\n",
      "[25]\tTrain's multi_logloss: 0.0825668\tTest's multi_logloss: 0.118196\n",
      "[26]\tTrain's multi_logloss: 0.0764216\tTest's multi_logloss: 0.116263\n",
      "[27]\tTrain's multi_logloss: 0.072027\tTest's multi_logloss: 0.114747\n",
      "[28]\tTrain's multi_logloss: 0.0653542\tTest's multi_logloss: 0.113648\n",
      "[29]\tTrain's multi_logloss: 0.0608168\tTest's multi_logloss: 0.113218\n",
      "[30]\tTrain's multi_logloss: 0.0573059\tTest's multi_logloss: 0.11312\n",
      "[31]\tTrain's multi_logloss: 0.0522963\tTest's multi_logloss: 0.110621\n",
      "[32]\tTrain's multi_logloss: 0.0489614\tTest's multi_logloss: 0.10986\n",
      "[33]\tTrain's multi_logloss: 0.0453722\tTest's multi_logloss: 0.108372\n",
      "[34]\tTrain's multi_logloss: 0.0424342\tTest's multi_logloss: 0.106726\n",
      "[35]\tTrain's multi_logloss: 0.0404331\tTest's multi_logloss: 0.106006\n",
      "[36]\tTrain's multi_logloss: 0.0388344\tTest's multi_logloss: 0.106407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  60%|######    | 3/5 [00:00<00:00, 27.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:45,259]\u001b[0m Trial 66 finished with value: 0.1060055700859525 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.09725054737256139.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  80%|########  | 4/5 [00:00<00:00, 27.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/kizawamasakazu/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.093987:  80%|########  | 4/5 [00:00<00:00, 27.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2022-12-05 17:55:45,265]\u001b[0m Trial 67 finished with value: 1.145060876755944 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.09725054737256139.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.093987: 100%|##########| 5/5 [00:00<00:00, 30.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37]\tTrain's multi_logloss: 0.0373429\tTest's multi_logloss: 0.108664\n",
      "[38]\tTrain's multi_logloss: 0.0363236\tTest's multi_logloss: 0.110265\n",
      "[39]\tTrain's multi_logloss: 0.0353857\tTest's multi_logloss: 0.109042\n",
      "[40]\tTrain's multi_logloss: 0.0347524\tTest's multi_logloss: 0.108084\n",
      "[41]\tTrain's multi_logloss: 0.0340317\tTest's multi_logloss: 0.110114\n",
      "[42]\tTrain's multi_logloss: 0.0338006\tTest's multi_logloss: 0.111164\n",
      "[43]\tTrain's multi_logloss: 0.0338437\tTest's multi_logloss: 0.113713\n",
      "[44]\tTrain's multi_logloss: 0.0334183\tTest's multi_logloss: 0.114289\n",
      "[45]\tTrain's multi_logloss: 0.0339038\tTest's multi_logloss: 0.117343\n",
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's multi_logloss: 0.0404331\tTest's multi_logloss: 0.106006\n",
      "[1]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[3]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[4]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[5]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[6]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[7]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[8]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[9]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[10]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "[11]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n",
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's multi_logloss: 1.09867\tTest's multi_logloss: 1.14506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(train_X, train_y, free_raw_data=False)\n",
    "lgb_test = lgb.Dataset(test_X, test_y, free_raw_data=False)\n",
    "\n",
    "model = lgb.train(params=params,\n",
    "                  train_set = lgb_train,\n",
    "                  valid_sets = [lgb_train, lgb_test],\n",
    "                  valid_names = ['Train', 'Test'],\n",
    "                  num_boost_round = 100,\n",
    "                  early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bf56699-290b-4a8c-bc3f-19b95ac277c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multiclass',\n",
       " 'metric': 'multi_logloss',\n",
       " 'num_class': 3,\n",
       " 'verbosity': -1,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 0.03850625556053545,\n",
       " 'lambda_l2': 0.0045965525980078,\n",
       " 'num_leaves': 31,\n",
       " 'feature_fraction': 0.7,\n",
       " 'bagging_fraction': 0.43530149594535855,\n",
       " 'bagging_freq': 6,\n",
       " 'min_child_samples': 20,\n",
       " 'num_iterations': 100,\n",
       " 'early_stopping_round': 10}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b6f905-f00b-4dbf-bc1a-059568a19a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
