{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02-01</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03-01</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04-01</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05-01</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09-01</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10-01</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11-01</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12-01</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month    y\n",
       "0    1949-01-01  112\n",
       "1    1949-02-01  118\n",
       "2    1949-03-01  132\n",
       "3    1949-04-01  129\n",
       "4    1949-05-01  121\n",
       "..          ...  ...\n",
       "139  1960-08-01  606\n",
       "140  1960-09-01  508\n",
       "141  1960-10-01  461\n",
       "142  1960-11-01  390\n",
       "143  1960-12-01  432\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./AirPassengers.csv')\n",
    "df.rename({'Passengers': 'y'}, axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>y</th>\n",
       "      <th>y_lag_1</th>\n",
       "      <th>y_lag_2</th>\n",
       "      <th>y_lag_3</th>\n",
       "      <th>y_lag_4</th>\n",
       "      <th>y_lag_5</th>\n",
       "      <th>y_lag_6</th>\n",
       "      <th>y_lag_7</th>\n",
       "      <th>y_lag_8</th>\n",
       "      <th>y_lag_9</th>\n",
       "      <th>y_lag_10</th>\n",
       "      <th>mean_10</th>\n",
       "      <th>std_10</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02-01</td>\n",
       "      <td>118</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03-01</td>\n",
       "      <td>132</td>\n",
       "      <td>118.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04-01</td>\n",
       "      <td>129</td>\n",
       "      <td>132.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05-01</td>\n",
       "      <td>121</td>\n",
       "      <td>129.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>606</td>\n",
       "      <td>622.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>449.1</td>\n",
       "      <td>77.856635</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09-01</td>\n",
       "      <td>508</td>\n",
       "      <td>606.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>90.332718</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10-01</td>\n",
       "      <td>461</td>\n",
       "      <td>508.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>483.6</td>\n",
       "      <td>82.583560</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11-01</td>\n",
       "      <td>390</td>\n",
       "      <td>461.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>489.2</td>\n",
       "      <td>78.457065</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12-01</td>\n",
       "      <td>432</td>\n",
       "      <td>390.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>486.5</td>\n",
       "      <td>81.618693</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month    y  y_lag_1  y_lag_2  y_lag_3  y_lag_4  y_lag_5  y_lag_6  \\\n",
       "0    1949-01-01  112      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1    1949-02-01  118    112.0      NaN      NaN      NaN      NaN      NaN   \n",
       "2    1949-03-01  132    118.0    112.0      NaN      NaN      NaN      NaN   \n",
       "3    1949-04-01  129    132.0    118.0    112.0      NaN      NaN      NaN   \n",
       "4    1949-05-01  121    129.0    132.0    118.0    112.0      NaN      NaN   \n",
       "..          ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "139  1960-08-01  606    622.0    535.0    472.0    461.0    419.0    391.0   \n",
       "140  1960-09-01  508    606.0    622.0    535.0    472.0    461.0    419.0   \n",
       "141  1960-10-01  461    508.0    606.0    622.0    535.0    472.0    461.0   \n",
       "142  1960-11-01  390    461.0    508.0    606.0    622.0    535.0    472.0   \n",
       "143  1960-12-01  432    390.0    461.0    508.0    606.0    622.0    535.0   \n",
       "\n",
       "     y_lag_7  y_lag_8  y_lag_9  y_lag_10  mean_10     std_10  time  \n",
       "0        NaN      NaN      NaN       NaN      NaN        NaN     0  \n",
       "1        NaN      NaN      NaN       NaN      NaN        NaN     1  \n",
       "2        NaN      NaN      NaN       NaN      NaN        NaN     2  \n",
       "3        NaN      NaN      NaN       NaN      NaN        NaN     3  \n",
       "4        NaN      NaN      NaN       NaN      NaN        NaN     4  \n",
       "..       ...      ...      ...       ...      ...        ...   ...  \n",
       "139    417.0    405.0    362.0     407.0    449.1  77.856635   139  \n",
       "140    391.0    417.0    405.0     362.0    469.0  90.332718   140  \n",
       "141    419.0    391.0    417.0     405.0    483.6  82.583560   141  \n",
       "142    461.0    419.0    391.0     417.0    489.2  78.457065   142  \n",
       "143    472.0    461.0    419.0     391.0    486.5  81.618693   143  \n",
       "\n",
       "[144 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(df: pd.DataFrame):\n",
    "    max_lag = 10\n",
    "    for i in range(1, max_lag+1):\n",
    "        df[f'y_lag_{i}'] = df['y'].shift(i)\n",
    "    \n",
    "    n = 10\n",
    "    df[f'mean_{n}'] = df['y'].rolling(n).mean().shift(1)\n",
    "    df[f'std_{n}'] = df['y'].rolling(n).std().shift(1)\n",
    "    \n",
    "    df['time'] = np.arange(df.shape[0])\n",
    "    \n",
    "    return df\n",
    "\n",
    "preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(df.drop('Month', axis=1).dropna(), test_size=0.2)\n",
    "train, val = train_test_split(train_val, test_size=0.2)\n",
    "X_train, y_train = train.drop('y', axis=1).values, train['y'].values.reshape(-1, 1)\n",
    "X_val, y_val = val.drop('y', axis=1).values, val['y'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 13\n",
      "epoch: 1, loss: -2.04e+05\n",
      "epoch: 2, loss: -2.4e+05\n",
      "epoch: 3, loss: -2.38e+05\n",
      "epoch: 4, loss: -2.41e+05\n",
      "epoch: 5, loss: -2.37e+05\n",
      "epoch: 6, loss: -2.39e+05\n",
      "epoch: 7, loss: -2.4e+05\n",
      "epoch: 8, loss: -2.41e+05\n",
      "epoch: 9, loss: -2.4e+05\n",
      "epoch: 10, loss: -2.39e+05\n",
      "epoch: 11, loss: -2.37e+05\n",
      "epoch: 12, loss: -2.41e+05\n",
      "epoch: 13, loss: -2.39e+05\n",
      "epoch: 14, loss: -2.37e+05\n",
      "epoch: 15, loss: -2.38e+05\n",
      "epoch: 16, loss: -2.35e+05\n",
      "epoch: 17, loss: -2.36e+05\n",
      "epoch: 18, loss: -2.41e+05\n",
      "epoch: 19, loss: -2.36e+05\n",
      "epoch: 20, loss: -2.35e+05\n",
      "epoch: 21, loss: -2.41e+05\n",
      "epoch: 22, loss: -2.4e+05\n",
      "epoch: 23, loss: -2.37e+05\n",
      "epoch: 24, loss: -2.4e+05\n",
      "epoch: 25, loss: -2.35e+05\n",
      "epoch: 26, loss: -2.39e+05\n",
      "epoch: 27, loss: -2.4e+05\n",
      "epoch: 28, loss: -2.46e+05\n",
      "epoch: 29, loss: -2.38e+05\n",
      "epoch: 30, loss: -2.36e+05\n",
      "epoch: 31, loss: -2.37e+05\n",
      "epoch: 32, loss: -2.3e+05\n",
      "epoch: 33, loss: -2.41e+05\n",
      "epoch: 34, loss: -2.41e+05\n",
      "epoch: 35, loss: -2.39e+05\n",
      "epoch: 36, loss: -2.4e+05\n",
      "epoch: 37, loss: -2.42e+05\n",
      "epoch: 38, loss: -2.37e+05\n",
      "epoch: 39, loss: -2.37e+05\n",
      "epoch: 40, loss: -2.34e+05\n",
      "epoch: 41, loss: -2.39e+05\n",
      "epoch: 42, loss: -2.36e+05\n",
      "epoch: 43, loss: -2.4e+05\n",
      "epoch: 44, loss: -2.39e+05\n",
      "epoch: 45, loss: -2.4e+05\n",
      "epoch: 46, loss: -2.42e+05\n",
      "epoch: 47, loss: -2.38e+05\n",
      "epoch: 48, loss: -2.4e+05\n",
      "epoch: 49, loss: -2.4e+05\n",
      "epoch: 50, loss: -2.43e+05\n",
      "epoch: 51, loss: -2.33e+05\n",
      "epoch: 52, loss: -2.38e+05\n",
      "epoch: 53, loss: -2.35e+05\n",
      "epoch: 54, loss: -2.4e+05\n",
      "epoch: 55, loss: -2.33e+05\n",
      "epoch: 56, loss: -2.4e+05\n",
      "epoch: 57, loss: -2.37e+05\n",
      "epoch: 58, loss: -2.43e+05\n",
      "epoch: 59, loss: -2.4e+05\n",
      "epoch: 60, loss: -2.35e+05\n",
      "epoch: 61, loss: -2.39e+05\n",
      "epoch: 62, loss: -2.39e+05\n",
      "epoch: 63, loss: -2.37e+05\n",
      "epoch: 64, loss: -2.41e+05\n",
      "epoch: 65, loss: -2.39e+05\n",
      "epoch: 66, loss: -2.38e+05\n",
      "epoch: 67, loss: -2.39e+05\n",
      "epoch: 68, loss: -2.4e+05\n",
      "epoch: 69, loss: -2.44e+05\n",
      "epoch: 70, loss: -2.38e+05\n",
      "epoch: 71, loss: -2.4e+05\n",
      "epoch: 72, loss: -2.33e+05\n",
      "epoch: 73, loss: -2.4e+05\n",
      "epoch: 74, loss: -2.4e+05\n",
      "epoch: 75, loss: -2.41e+05\n",
      "epoch: 76, loss: -2.34e+05\n",
      "epoch: 77, loss: -2.37e+05\n",
      "epoch: 78, loss: -2.41e+05\n",
      "epoch: 79, loss: -2.44e+05\n",
      "epoch: 80, loss: -2.41e+05\n",
      "epoch: 81, loss: -2.41e+05\n",
      "epoch: 82, loss: -2.41e+05\n",
      "epoch: 83, loss: -2.4e+05\n",
      "epoch: 84, loss: -2.37e+05\n",
      "epoch: 85, loss: -2.4e+05\n",
      "epoch: 86, loss: -2.39e+05\n",
      "epoch: 87, loss: -2.41e+05\n",
      "epoch: 88, loss: -2.34e+05\n",
      "epoch: 89, loss: -2.4e+05\n",
      "epoch: 90, loss: -2.43e+05\n",
      "epoch: 91, loss: -2.34e+05\n",
      "epoch: 92, loss: -2.42e+05\n",
      "epoch: 93, loss: -2.41e+05\n",
      "epoch: 94, loss: -2.4e+05\n",
      "epoch: 95, loss: -2.4e+05\n",
      "epoch: 96, loss: -2.37e+05\n",
      "epoch: 97, loss: -2.37e+05\n",
      "epoch: 98, loss: -2.4e+05\n",
      "epoch: 99, loss: -2.4e+05\n",
      "epoch: 100, loss: -2.39e+05\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    '''多層パーセプトロン'''\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.a1 = nn.Sigmoid()\n",
    "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.a2 = nn.Sigmoid()\n",
    "        \n",
    "        self.layers = [self.l1, self.a1, self.l2, self.a2]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "n_features = df.shape[1] - 2\n",
    "print(f'n_features: {n_features}')\n",
    "model = MLP(input_dim=n_features, hidden_dim=n_features*2, output_dim=1).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optimizers.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def compute_loss(y, yhat):\n",
    "    return criterion(yhat, y)\n",
    "\n",
    "def train_step(x, y):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(y, preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "n_batches = X_train.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    x_, y_ = shuffle(X_train, y_train)\n",
    "    x_ = torch.Tensor(x_).to(device)\n",
    "    y_ = torch.Tensor(y_).to(device)\n",
    "    \n",
    "    for n_batch in range(n_batches):\n",
    "        start = n_batch * batch_size\n",
    "        end = start + batch_size\n",
    "        loss = train_step(x_[start:end], y_[start:end])\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print('epoch: {}, loss: {:.3}'.format(\n",
    "        epoch+1,\n",
    "        train_loss\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_, y_ = shuffle(X_train, y_train)\n",
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/kizawamasakazu/projects/machine_learning/work/time_series/air_passengers/mlp.ipynb セル 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kizawamasakazu/projects/machine_learning/work/time_series/air_passengers/mlp.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m yhat \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39mTensor(x_))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kizawamasakazu/projects/machine_learning/work/time_series/air_passengers/mlp.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m compute_loss(torch\u001b[39m.\u001b[39;49mTensor(y_), yhat)\n",
      "\u001b[1;32m/Users/kizawamasakazu/projects/machine_learning/work/time_series/air_passengers/mlp.ipynb セル 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kizawamasakazu/projects/machine_learning/work/time_series/air_passengers/mlp.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_loss\u001b[39m(y, yhat):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kizawamasakazu/projects/machine_learning/work/time_series/air_passengers/mlp.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m criterion(y, yhat)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/functional.py:3098\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3095\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3096\u001b[0m     weight \u001b[39m=\u001b[39m weight\u001b[39m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3098\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight, reduction_enum)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "yhat = model(torch.Tensor(x_))\n",
    "compute_loss(torch.Tensor(y_), yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
